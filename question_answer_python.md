# Собеседование Python AQA

# Содержание

## Базовые знания

1. [Типы данных](#типы-данных)
2. [*args и **kwargs](#args-и-kwargs)
3. [Хеш-таблица](#хеш-таблица)
4. [Встроенные функции](#встроенные-функции)
5. [Контекстные менеджеры (with)](#контекстные-менеджеры-with)
6. [Генераторы и итераторы](#генераторы-и-итераторы)
7. [Декораторы и замыкания](#декораторы-и-замыкания)
8. [GIL (Global Interpreter Lock)](#gil-global-interpreter-lock)
9. [Изменение списка во время итерации](#изменение-списка-во-время-итерации)
10. [Области видимости (scope)](#области-видимости-scope)
11. [Lambda-функции](#lambda-функции)
12. [Comprehensions и генераторные выражения](#comprehensions-и-генераторные-выражения)
13. [copy() и deepcopy()](#copy-и-deepcopy)
14. [Асинхронность (Async/Await)](#асинхронность-asyncawait)
15. [Dataclass](#dataclass)
16. [Enum](#enum)
17. [Garbage Collector (сборщик мусора)](#garbage-collector-сборщик-мусора)
18. [Виды сложности кода](#виды-сложности-кода)

## ООП

1. [Парадигмы ООП](#парадигмы-ооп)
2. [Абстракция (ООП)](#абстракция-ооп)
3. [Инкапсуляция (ООП)](#инкапсуляция-ооп)
4. [Наследование (ООП)](#наследование-ооп)
5. [Полиморфизм (ООП)](#полиморфизм-ооп)
6. [Магические методы](#магические-методы)
7. [Инвариантность и ковариантность](#инвариантность-и-ковариантность)
8. [Декораторы классов и методов](#декораторы-классов-и-методов)
9. [Множественное наследование и MRO](#множественное-наследование-и-mro)
10. [ABC (Abstract Base Classes)](#abc-abstract-base-classes)
11. [Протокол (Protocol)](#протокол-protocol)
12. [Паттерны проектирования](#паттерны-проектирования)
13. [Композиция и агрегация](#композиция-и-агрегация)
14. [Связность и связанность](#связность-и-связанность)
15. [SOLID](#solid)
16. [Специфика ООП в Python](#специфика-ооп-в-python)
17. [Наследование и композиция](#наследование-и-композиция)
18. [Метапрограммирование](#метапрограммирование)
19. [Подводные камни ООП в Python](#подводные-камни-ооп-в-python)

## Типизация

1. [typing: Optional, Union, TypeVar, Generic](#typing-optional-union-typevar-generic)
2. [Literal, TypedDict, Protocol](#literal-typeddict-protocol)
3. [Covariance/Contravariance](#covariancecontravariance)

## Инструменты

1. [pytest](#pytest)
2. [pytest hooks](#pytest-hooks)
3. [Kubernetes](#kubernetes)

## Теория тестирования

1. [Пирамида тестирования](#пирамида-тестирования)
2. [Виды тестирования](#виды-тестирования)
3. [Метрики](#метрики)
4. [Test Design Techniques](#test-design-techniques)
5. [Автоматизация](#автоматизация)

---

# Типы данных

Отлично, подготовлю ответ на вопрос о типах данных, соответствующий уровню позиции Senior AQA. Понимание внутреннего
устройства языка — это ключ к написанию стабильных, эффективных тестов и анализу сложных дефектов.

### **Типы данных в Python**

**Junior Level**

В Python, как и в любом языке программирования, данные бывают разных видов или «типов». Это базовые кирпичики, с
которыми работает программа. Их можно разделить на две большие категории: изменяемые и неизменяемые.

Простые, или «скалярные» типы — это числа (целые, вещественные, комплексные), строки текста и логические значения (
`True`/`False`). Важное свойство строк и чисел — их **нельзя изменить после создания**. Если ты пишешь `x = "hello"`, а
потом `x = "world"`, ты не меняешь строку "hello", а создаешь новую и даешь ей то же имя `x`.

Более сложные, «коллекционные» типы — это списки, кортежи, словари и множества. Они нужны для хранения набора других
значений. Здесь ключевое различие: **список можно изменить** (добавить или удалить элемент), а **кортеж — нет**. Словарь
хранит данные в парах «ключ-значение», и его тоже можно изменять.

Понимание, какой тип перед тобой и можно ли его изменить, критически важно для избегания ошибок в коде и тестах.

**Middle Level**

На этом уровне мы рассматриваем типы не просто как «коробки для данных», а как объекты со строгой классификацией,
определенным поведением и моделью в памяти.

1. **Классификация по мутабельности (изменяемости):**
    * **Неизменяемые (immutable):** `int`, `float`, `complex`, `str`, `bytes`, `tuple`, `frozenset`, `bool`, `NoneType`.
      Экземпляр такого типа после создания не может быть изменен. Любая операция, выглядящая как изменение, на деле
      создает новый объект. Это имеет глубокие последствия для хэшируемости (объекты этих типов обычно хэшируемы),
      использования в качестве ключей словаря и поведения при передаче в функции (передается ссылка на объект, но так
      как объект нельзя изменить, создается иллюзия передачи «по значению»).
    * **Изменяемые (mutable):** `list`, `dict`, `set`, `bytearray`, пользовательские классы (по умолчанию). Содержимое
      таких объектов можно менять. При передаче в функцию передается ссылка на тот же самый объект, поэтому изменения,
      сделанные внутри функции, видны снаружи. Это частая причина коварных багов в тестах, связанных с непреднамеренным
      изменением фикстур или конфигураций.

2. **Устройство объектов:** В Python всё является объектом. Каждый объект имеет три обязательных атрибута: *
   *идентификатор** (уникальный числовой адрес в памяти, возвращаемый `id()`), **тип** (определяющий возможные операции,
   возвращаемый `type()`) и **значение**. Для неизменяемых типов идентификатор и значение жестко связаны. Для
   изменяемых — объект может менять значение, сохраняя идентификатор.

3. **Специфика типов:**
    * `None` — синглтон, объект, обозначающий отсутствие значения. `id(None)` всегда одинаков.
    * Булевы значения `True` и `False` — также синглтоны и являются подклассами `int`.
    * `tuple` — неизменяем, но если содержит изменяемые элементы (например, списки), то эти внутренние элементы менять
      можно. Это делает кортеж «условно хэшируемым».
    * `dict` начиная с Python 3.7 гарантирует сохранение порядка вставки, а с 3.6 это было особенностью реализации
      CPython. Для AQA это важно при тестировании API, возвращающих JSON.
    * `set` и `frozenset` хранят только уникальные, хэшируемые элементы. Их внутренняя реализация близка к словарю, где
      есть только ключи.

Для AQA middle-уровня важно использовать это понимание для проектирования тестовых данных, предсказания побочных
эффектов в тестируемом коде и грамотного сравнения ожидаемого и фактического результатов (например, понимая, что
сравнение `[1,2,3] == [1,2,3]` дает `True`, но `id()` у этих списков разный).

**Senior Level (Кровь, кишки и CPython)**

Здесь мы спускаемся на уровень байткода, структуры `PyObject` и менеджмента памяти. Senior AQA должен понимать это,
чтобы отлаживать сложнейшие race conditions, утечки памяти в тестируемом приложении или анализировать аномалии
производительности.

1. **Всё есть `PyObject`:** В исходном коде CPython (`Include/object.h`) лежит фундамент — структура `PyObject`. Это
   базовый «контейнер» для любого типа данных.
   ```c
   typedef struct _object {
       Py_ssize_t ob_refcnt;  // Счетчик ссылок — основа механизма GC
       PyTypeObject *ob_type; // Указатель на структуру типа
   } PyObject;
   ```
   Каждый объект в Python начинается с этих двух полей. `ob_refcnt` — счетчик ссылок для сборщика мусора. `ob_type` —
   указатель на другой объект — его тип, который сам является объектом (`PyTypeObject`). Добавление новых полей
   происходит путем «расширения» этой структуры. Например, `PyLongObject` (целое число) добавляет поле для хранения
   цифр.

2. **Неизменяемость и интернирование (interning):** Это не просто договоренность, а оптимизация на уровне
   интерпретатора.
    * **Маленькие целые числа:** Диапазон обычно от -5 до 256. Эти объекты создаются при запуске интерпретатора и
      хранятся в специальном массиве. Операция `a = 10; b = 10` приведет к тому, что `a` и `b` будут указывать на **один
      и тот же** объект в памяти (`id(a) == id(b)`). Проверка делается макросом `PyLong_FromLong`.
    * **Строки (interned strings):** Если строка состоит только из символов ASCII, букв, цифр и подчеркивания, и не
      выглядит как число, она также может быть интернирована. Это особенно важно для имен переменных, атрибутов. Python
      делает это автоматически, но можно принудительно интернировать строку через `sys.intern()`. Это ускоряет сравнение
      строк (достаточно сравнить указатели, `a is b`) и экономит память в случае множества одинаковых строк (например,
      при парсинге больших XML/JSON в тестах).

3. **Мутабельность и байткод:** Рассмотрим операцию `my_list.append(x)`. Байткод инструкция `LIST_APPEND` работает
   непосредственно с внутренним C-массивом структуры `PyListObject`. Объект списка (`list`) хранит указатель (
   `**ob_item`) на этот массив указателей на `PyObject` и его текущую длину (`ob_size`). `LIST_APPEND` увеличивает
   `ob_size`, при необходимости перераспределяет память для `ob_item` (сложность amortized O(1)) и помещает в новый слот
   ссылку на `x`, увеличивая `ob_refcnt` у объекта `x`. Никакого нового `list` не создается, `id(my_list)` остается
   прежним.

4. **Словарь: краеугольный камень языка.** `dict` — не просто тип, это фундаментальная структура, используемая
   повсеместно: пространства имен модулей, атрибуты объектов, передача аргументов в функции (`**kwargs`) реализованы
   через словари. Его внутренности — это хэш-таблица (массив `PyDictKeyEntry`). Ключевая хитрость в том, как разрешаются
   коллизии (метод открытой адресации). При удалении многих элементов словарь может оставаться разреженным, что ведет к
   утечкам памяти. Для AQA это означает, что долгоживущие объекты с большими изменяющимися словарями (например, кэши в
   тестируемом приложении) требуют мониторинга памяти. Словари также резко замедляются при атаках хэш-коллизиями, что
   может быть вектором DoS-атаки — это важно для security-тестирования.

5. **`tuple` vs `list`: Не просто мутабельность.** `tuple` из-за своей неизменности аллоцируется одной непрерывной
   областью памяти. Его `ob_item` — это встроенный массив указателей фиксированного размера. `list` же имеет буфер с
   «запасом» (`allocated`), чтобы не переаллоцировать память при каждом `append`. Сравнение `is` для кортежей,
   содержащих только неизменяемые элементы, может давать `True` благодаря механизму кэширования (`tupleobject.c`):
   Python может переиспользовать только что созданный кортеж, если он пуст или состоит из одного элемента.

6. **Типизация для AQA:** На этом уровне мы понимаем, что система типов Python — динамическая, но сильная (strong).
   «Утиная типизация» реализуется через механизм поиска атрибутов в `__dict__` объекта и далее по MRO (Method Resolution
   Order). Паттерн `isinstance(obj, abc.ABC)` или `hasattr(obj, '__len__')` на байткод-уровне сводится к проверкам
   `PyObject_IsInstance` и `PyObject_HasAttr`, которые проходят по цепочке классов. Для Senior AQA критично понимать эти
   механизмы при тестировании полиморфных компонентов, мокинге и создании сложных фикстур, имитирующих определенные
   интерфейсы.

- [Содержание](#содержание)

---

# *args и **kwargs

### ***args и **kwargs**

**Junior Level**

`*args` и `**kwargs` — это специальные синтаксические конструкции в Python, позволяющие функциям принимать произвольное
количество аргументов.

`*args` (от слова "arguments") собирает все **позиционные аргументы**, переданные функции сверх явно объявленных, в *
*кортеж**. Это полезно, когда вы не знаете заранее, сколько аргументов может понадобиться передать.

`**kwargs` (от "keyword arguments") собирает все **именованные аргументы** (ключ=значение), которые не были явно
перечислены в параметрах функции, в **словарь**. Это часто используется для передачи конфигурационных параметров или для
создания функций-оберток.

Также символы `*` и `**` используются при **вызове** функции для распаковки коллекций в отдельные аргументы. `*`
распаковывает итерируемый объект (список, кортеж) в позиционные аргументы, а `**` распаковывает словарь в именованные
аргументы.

Это фундаментальный механизм для создания гибких API и декораторов.

**Middle Level**

На этом уровне важно понимать **строгие правила порядка параметров** и внутреннее представление:

1. **Строгий порядок в определении функции**:
   ```
   def f(a, b, *args, c=None, d=None, **kwargs)
   ```
   Порядок следования:
    - Позиционные параметры (a, b)
    - `*args` — собирает избыточные позиционные аргументы
    - Keyword-only аргументы (c, d) — могут быть переданы только по имени
    - `**kwargs` — собирает избыточные именованные аргументы

   После `*args` все последующие параметры становятся **keyword-only** (требуют явного указания имени). Это важная фича
   для создания чистого API.

2. **Распаковка на уровне байткода**:
   Когда вы вызываете `func(*[1, 2, 3])`, происходит:
    - Байткод `BUILD_LIST` создает список
    - Байткод `CALL_FUNCTION_EX` с флагом `0x01` (HAVE_ARG_FLAGS) распаковывает итерируемый объект в аргументы
    - Внутри функции эти аргументы доступны через `sys._getframe().f_locals`

3. **`*` и `**` — не магия, а синтаксический сахар**:
   Конструкция `def foo(*args, **kwargs)` компилируется в функцию с двумя специальными параметрами. При компиляции в
   байткод для них создаются отдельные инструкции для упаковки аргументов в кортеж и словарь.

4. **Важные нюансы для AQA**:
    - При передаче словаря в `**kwargs` ключи **должны быть строками**
    - Дублирование имен аргументов при распаковке приводит к `TypeError`
    - `**kwargs` сохраняет порядок аргументов начиная с Python 3.6 (благодаря сохранению порядка вставки в словарях)
    - Метод `__getitem__` объекта используется при распаковке через `**`, что позволяет распаковывать не только словари,
      но и любые mapping-объекты

**Senior Level (Байткод, CPython и грабли производительности)**

1. **Уровень байткода: как работает упаковка аргументов**:

   Рассмотрим функцию:
   ```python
   def func(*args, **kwargs):
       pass
   ```

   Байткод для вызова `func(1, 2, a=3, b=4)`:
   ```
   LOAD_CONST               1 (1)
   LOAD_CONST               2 (2)
   LOAD_CONST               3 (3)
   LOAD_CONST               4 (4)
   LOAD_CONST               5 (('a', 'b'))  # Имена ключей
   CALL_FUNCTION_KW         2           # 2 позиционных + keyword args
   ```

   Байткод внутри `func` для доступа к аргументам:
   ```
   # Для *args
   BUILD_TUPLE              # Собирает позиционные аргументы в кортеж
   STORE_FAST             0 (args)
   
   # Для **kwargs  
   BUILD_MAP                # Собирает именованные аргументы в словарь
   STORE_FAST             1 (kwargs)
   ```

   В CPython 3.10+ используется `CALL` с флагами вместо отдельных `CALL_FUNCTION*` инструкций.

2. **CPython: механизм вызова функций**:

   В `Include/cpython/abstract.h` функция `PyObject_Call` принимает `PyObject *args` (кортеж) и `PyObject *kwargs` (
   словарь). Вся система вызова построена вокруг этих двух структур.

   Когда интерпретатор видит `*args` в вызове, он выполняет:
    - `PySequence_Tuple` для преобразования итерируемого объекта в кортеж
    - `PyTuple_New` для создания нового кортежа аргументов
    - Конкатенацию с существующими позиционными аргументами

3. **Критические оптимизации CPython 3.11+**:

   В Python 3.11 появилась **специализация байткода для вызовов функций** (PEP 659). Интерпретатор создает "
   адаптивные" (adaptive) инструкции вызова, которые кэшируют:
    - Форму вызова (позиционные vs именованные аргументы)
    - Типы передаваемых аргументов
    - Количество аргументов

   Например, вызов `func(*args)` без именованных аргументов компилируется в специализированную версию `CALL`, которая
   пропускает проверки на наличие `kwargs`. Это дает до 50% ускорения для частых вызовов.

   **Но!** Если функция определена как `def f(**kwargs)`, а вызывается как `f(*args)`, происходит деоптимизация — сброс
   кэша и возврат к обобщенному медленному пути.

4. **Frame object и доступ к аргументам**:

   Локальные переменные функции (включая `args` и `kwargs`) хранятся в `frame->f_localsplus` — массиве указателей
   `PyObject*`. `*args` занимает один слот (указатель на кортеж), `**kwargs` — один слот (указатель на словарь).

   Доступ через `sys._getframe()` позволяет инспектировать это в runtime, что используется в продвинутых тестовых
   фреймворках для анализа вызовов.

5. **`inspect.Signature` и валидация аргументов**:

   Модуль `inspect` использует `__code__.co_varnames`, `__code__.co_argcount`, `__code__.co_kwonlyargcount` для
   реконструкции сигнатуры. `*args` соответствует `__code__.co_flags & 0x04` (CO_VARARGS), `**kwargs` — `0x08` (
   CO_VARKEYWORDS).

   Для AQA: это позволяет создавать динамические валидаторы аргументов в тестовых фреймворках.

6. **Производительность и антипаттерны**:

    - **Двойная упаковка/распаковка**: `func(*tuple(args), **dict(kwargs))` создает **новые** кортеж и словарь, копируя
      все элементы. Вместо этого нужно использовать прямое присваивание.

    - **Рекурсивная распаковка в циклах**:
      ```python
      for item in items:
          process(**item)  # Создание нового словаря для каждого вызова!
      ```
      Лучше: `process(key1=item['key1'], key2=item['key2'])` если сигнатура известна.

    - **Большие `*args`**: передача огромного списка через `*` приводит к созданию кортежа из всех элементов на стеке
      вызовов, что может вызвать `RecursionError` при глубокой рекурсии.

7. **Специфика для декораторов (как для AQA)**:

   При написании декораторов для тестов:
   ```python
   def retry(max_attempts):
       def decorator(func):
           def wrapper(*args, **kwargs):
               for attempt in range(max_attempts):
                   try:
                       return func(*args, **kwargs)  # Внимание!
                   except AssertionError:
                       if attempt == max_attempts - 1:
                           raise
           return wrapper
       return decorator
   ```

   **Проблема**: каждый вызов `func(*args, **kwargs)` внутри `wrapper` создает **новые** кортеж и словарь. Для high-load
   тестов это может стать бутылочным горлышком. Решение — использовать `functools.wraps` который кэширует signature.

8. **Интроспекция и мокирование**:

   Для создания умных моков в тестах нужно понимать, как `unittest.mock` работает с `*args`/`**kwargs`:
    - `mock.call_args` хранит `args` как кортеж и `kwargs` как словарь
    - `mock.assert_called_with(*args, **kwargs)` использует ту же семантику распаковки
    - При `side_effect = lambda *a, **k: ...` сигнатура должна точно соответствовать

9. **C-расширения и `PyArg_ParseTupleAndKeywords`**:

   В нативных модулях функция `PyArg_ParseTupleAndKeywords` принимает:
   ```c
   static PyObject* func(PyObject *self, PyObject *args, PyObject *kwargs)
   {
       char *keywords[] = {"param1", "param2", NULL};
       // Парсинг args и kwargs
   }
   ```
   Здесь `args` и `kwargs` — те же PyObject*, что и в Python-функциях. Это знание критично для тестирования нативных
   расширений.

- [Содержание](#содержание)

---

# Хеш-таблица

### **Хеш-таблица в Python**

**Junior Level**

Хеш-таблица — это структура данных, которая позволяет очень быстро находить, добавлять и удалять элементы. В Python
хеш-таблицы лежат в основе двух ключевых типов: **словарей (dict)** и **множеств (set)**.

Представьте себе библиотеку с книгами. Вместо того чтобы искать книгу по названию, перебирая все полки, вы вычисляете
номер полки по названию книги по определенному правилу (например, первая буква). Это правило — **хеш-функция**. Она
преобразует ключ (название книги) в число (номер полки). В идеальном случае вы сразу идете к нужной полке и находите
книгу за O(1) время.

Коллизии (когда две разные книги должны лежать на одной полке) решаются разными способами — например, на полке может
быть несколько книг, и вы тогда ищете среди них уже по полному названию.

В Python словарь — это коллекция пар «ключ-значение», где ключ должен быть **хешируемым** (неизменяемым) объектом.
Множество — это коллекция уникальных хешируемых элементов.

**Middle Level**

В Python хеш-таблицы реализованы через открытую адресацию (open addressing) с двойным хешированием для разрешения
коллизий.

**Ключевые аспекты:**

1. **Хешируемость:** Объект хешируем, если:
    - Имеет метод `__hash__`, возвращающий целое число
    - Имеет метод `__eq__` для сравнения
    - Удовлетворяет условию: `a == b` ⇒ `hash(a) == hash(b)`

   Неизменяемые типы (int, str, tuple, frozenset) хешируемы. Изменяемые (list, dict, set) — нет, но могут стать
   хешируемыми, если реализовать неизменяемую версию.

2. **Размер таблицы:** Всегда является степенью двойки. Это позволяет использовать быструю битовую маску для вычисления
   индекса: `index = hash(key) & (table_size - 1)`.

3. **Коэффициент загрузки (load factor):** При достижении ~2/3 заполнения таблица увеличивается вдвое, происходит *
   *rehashing** — пересчет позиций всех элементов. Это амортизированная операция O(n).

4. **Разрешение коллизий:** Используется **квадратичное зондирование (quadratic probing)** вида
   `index = (5*index + 1 + perturb) & mask`, где `perturb` изначально равен хешу, а затем сдвигается. Это обеспечивает
   хорошее распределение.

5. **Удаление элементов:** При удалении элемент не удаляется физически, а помечается как **dummy** (удаленный слот). Это
   необходимо для сохранения цепочек зондирования.

6. **Порядок элементов:** Начиная с Python 3.7/3.6 (как деталь реализации CPython) порядок вставки сохраняется. Это
   достигается тем, что хеш-таблица хранит индексы в отдельном массиве записей (ключ-значение), который сохраняет
   порядок вставки.

**Senior Level (CPython, память, байткод и темные углы)**

1. **Структура PyDictObject:**

   В `Include/cpython/dictobject.h`:
   ```c
   typedef struct {
       PyObject_HEAD
       Py_ssize_t ma_used;      // Количество активных элементов
       Py_ssize_t ma_version_tag // Уникальная версия для обнаружения изменений
       PyDictKeysObject *ma_keys; // Указатель на ключи
       PyObject **ma_values;      // Указатель на значения (для split-table)
   } PyDictObject;
   ```

   **Эволюция структур:**
    - До Python 3.6: единая хеш-таблица размером 8 строк (indices + entries)
    - Python 3.6+: **split-table layout**: отдельно массив индексов (`dk_indices`) и массив записей (`dk_entries`)
    - Python 3.11+: **компактная модель** с кэшированием хешей

2. **Детали split-table layout:**

   Массив `dk_indices` хранит не записи, а индексы в `dk_entries`:
    - Для таблицы размером 8: `dk_indices[hash & 7] = i` где `i` — индекс в `dk_entries`
    - `dk_entries` — массив структур `PyDictKeyEntry`, хранящих хеш, ключ, значение

   Это дает:
    - Сохранение порядка вставки (массив `dk_entries` заполняется последовательно)
    - Улучшенную локальность памяти при итерации
    - Меньшую фрагментацию памяти

3. **Хеш-атаки и SipHash:**

   До Python 3.4 использовался простой хеш (FNV для строк), что позволяло проводить DoS-атаки через искусственное
   создание коллизий. С Python 3.4 для строк, bytes и datetime используется **SipHash24** — криптографически стойкая
   хеш-функция с ключом, рандомизируемым при запуске интерпретатора.

   Ключ для SipHash хранится в `_Py_HashSecret` (глобальная переменная). Для тестирования можно установить
   `PYTHONHASHSEED=0` для детерминированного поведения.

4. **Байткод операций с dict:**

    - `LOAD_GLOBAL` → `PyDict_GetItem` по ключу-строке
    - `STORE_SUBSCR` для dict → `PyObject_SetItem`
    - `BUILD_MAP` → `_PyDict_NewPresized`

   При компиляции словарных литералов `{k: v}` Python 3.9+ использует `BUILD_MAP` с предвычисленными хешами для
   константных ключей.

5. **Оптимизации CPython 3.10+:**

    - **PEP 603**: Добавлен `dict.__getitem__` с быстрым путем для строковых ключей
    - **PEP 659**: Специализация байткода для операций со словарями:
      ```python
      # Адаптивный (adaptive) байткод для dict[key]
      # Первые несколько выполнений собирают статистику
      # Если ключ всегда строка, генерируется специализированный байткод
      # Который использует быстрый путь поиска в хеш-таблице
      ```

6. **Скрытые структуры для оптимизации:**

    - **Keys-sharing (dict splitting)**: Когда создается много объектов с одинаковыми атрибутами (например, экземпляры
      класса), их `__dict__` могут разделять таблицу ключей (`ma_keys`), храня только значения в `ma_values`. Это
      экономит память.

    - **Compact dict (Python 3.11)**: Запись `PyDictKeyEntry` уменьшена с 24 до 8 байт за счет выноса хеша в отдельный
      массив.

7. **Сборка мусора и weakref:**

   Словари участвуют в циклическом GC через `Py_TPFLAGS_HAVE_GC`. Weakref-словари (`weakref.WeakKeyDictionary`,
   `WeakValueDictionary`) используют специальные прокси-объекты, которые не увеличивают счетчик ссылок.

   Важно: обычные словари хранят **сильные ссылки** на ключи и значения, что может приводить к утечкам памяти в циклах.

8. **Производительность и антипаттерны:**

    - **Изменение ключа-объекта после вставки:** Если объект-ключ изменяется так, что меняется его хеш, он становится *
      *невозможным для нахождения**. Это коварный баг.

    - **Частые resizing:** При добавлении N элементов в пустой словарь происходит ~log₂(N) ресайзов. Решение:
      `dict.fromkeys()` или предвыделение через `dict(initial_size)`.

    - **Итерация с изменением:** Изменение размера словаря во время итерации вызывает `RuntimeError`. Но изменение
      значений (не ключей) безопасно.

    - **Memory overhead:** Пустой словарь занимает ~72 байта (Python 3.11), каждая запись — дополнительно 8-32 байта в
      зависимости от размера.

9. **Интроспекция через CPython API:**

   Для тестирования можно использовать:
   ```python
   import sys
   d = {}
   sys.getsizeof(d)  # Размер всей структуры
   d.__sizeof__()    # Тоже
   
   # Просмотр внутренних структур (CPython specific)
   d.__dictoffset__  # Смещение для __dict__ в объектах
   ```

10. **Для множеств (set):**

    Используется та же хеш-таблица, но без значений (только ключи). Особенности:
    - `set` хранит только хеш и ключ
    - `frozenset` — неизменяемая версия, кэширует хеш самого множества
    - Операции вроде `union`, `intersection` используют оптимизированные C-реализации

11. **Специфика тестирования хеш-таблиц:**

    - **Тестирование коллизий:** Создание объектов с одинаковым хешем для проверки деградации производительности
    - **Тестирование rehashing:** Измерение времени вставки при достижении порогов заполнения
    - **Проверка сохранения порядка:** Гарантия, что `list(dict.keys())` соответствует порядку вставки
    - **Тестирование memory leaks:** Убедиться, что удаление элементов освобождает память (но помнить про dummy-слоты)
    - **Конкурентность:** Dict не потокобезопасен. Тестирование race conditions при одновременном чтении/записи.

---

# Встроенные функции

### **Встроенные функции Python (Built-in Functions)**

**Junior Level**

Встроенные функции — это функции, которые доступны в Python по умолчанию, без необходимости импорта каких-либо модулей.
Они представляют собой базовый инструментарий языка и всегда находятся в глобальной области видимости.

Эти функции охватывают основные операции: работу с типами данных (`str()`, `int()`, `list()`), математические
вычисления (`abs()`, `round()`, `sum()`), преобразования (`len()`, `sorted()`, `reversed()`), ввод-вывод (`print()`,
`input()`), итерации (`range()`, `enumerate()`, `zip()`), проверки (`isinstance()`, `hasattr()`), и другие
фундаментальные операции.

Важно понимать, что это не просто функции, а часть ядра языка. Они реализованы максимально эффективно и их поведение
стандартизировано.

**Middle Level**

1. **Пространство имен `builtins`**: Все встроенные функции находятся в модуле `builtins`, который автоматически
   импортируется при запуске интерпретатора. Можно получить прямой доступ через `import builtins`. Переопределение
   функций в этом модуле (что крайне не рекомендуется) повлияет на всю программу.

2. **Категории встроенных функций**:
    - **Конструкторы типов**: `int()`, `str()`, `list()`, `dict()`, `set()`, `tuple()`, `bytes()`, `bytearray()`,
      `memoryview()`, `frozenset()`
    - **Математические**: `abs()`, `divmod()`, `pow()`, `round()`, `sum()`, `min()`, `max()`
    - **Преобразования и проверки**: `bool()`, `complex()`, `float()`, `hash()`, `id()`, `isinstance()`, `issubclass()`,
      `callable()`
    - **Работа с последовательностями**: `len()`, `sorted()`, `reversed()`, `enumerate()`, `zip()`, `filter()`, `map()`,
      `all()`, `any()`, `slice()`
    - **Итераторы и генераторы**: `iter()`, `next()`, `range()`
    - **Ввод-вывод**: `print()`, `input()`, `open()`
    - **Компиляция и выполнение**: `eval()`, `exec()`, `compile()`
    - **Отражение (introspection)**: `dir()`, `globals()`, `locals()`, `vars()`, `getattr()`, `setattr()`, `delattr()`,
      `hasattr()`, `property()`, `classmethod()`, `staticmethod()`, `super()`
    - **Разное**: `breakpoint()`, `__import__()`, `format()`, `repr()`, `ascii()`, `chr()`, `ord()`, `bin()`, `oct()`,
      `hex()`

3. **Особенности поведения**:
    - `sorted()` всегда возвращает новый список, тогда как метод `list.sort()` изменяет список на месте
    - `reversed()` возвращает итератор, а не список
    - `map()` и `filter()` в Python 3 возвращают итераторы, а не списки (как было в Python 2)
    - `range()` тоже возвращает специальный объект, а не список
    - `open()` является фабрикой, возвращающей файловый объект с разным поведением в зависимости от режима

4. **Функции высшего порядка**: `map()`, `filter()`, `sorted()` принимают функции в качестве аргументов. Это делает их
   мощным инструментом для функционального программирования.

**Senior Level (CPython, байткод и системные вызовы)**

1. **Реализация в CPython**:

   Встроенные функции реализованы в C в файлах CPython:
    - `Python/bltinmodule.c` — основные встроенные функции
    - `Objects/` — конструкторы типов (`listobject.c`, `dictobject.c` и т.д.)
    - `Python/` — специализированные функции (`pythonrun.c` для `exec()`)

   Каждая функция представлена структурой `PyMethodDef`:
   ```c
   static PyMethodDef builtin_methods[] = {
       {"abs",       builtin_abs,       METH_O,  abs_doc},
       {"all",       builtin_all,       METH_O,  all_doc},
       // ...
       {NULL,        NULL}  /* Sentinel */
   };
   ```

   Флаг `METH_O` означает, что функция принимает один объект (позиционный аргумент). Есть также `METH_VARARGS`,
   `METH_KEYWORDS` и их комбинации.

2. **Байткод и вызов встроенных функций**:

   При вызове `len(obj)` генерируется байткод:
   ```
   LOAD_NAME                0 (len)
   LOAD_NAME                1 (obj)
   CALL_FUNCTION            1
   ```

   Но для некоторых часто используемых функций есть специализированные инструкции:
    - `BUILD_LIST`, `BUILD_TUPLE`, `BUILD_SET`, `BUILD_MAP` — вместо вызова конструкторов
    - `UNPACK_SEQUENCE`, `UNPACK_EX` — для распаковки
    - `COMPARE_OP` — вместо вызова `cmp()` (удалена в Python 3)

3. **Оптимизации CPython 3.11+**:

   **PEP 659 (специализация байткода)** добавила адаптивные инструкции для встроенных функций:
    - `CALL` с кэшированием типа результата и побочных эффектов
    - Для `len()`, `sum()`, `range()` создаются специализированные быстрые пути
    - При частом вызове `len(list)` байткод заменяется на инструкцию, которая напрямую обращается к `PyList_GET_SIZE`

4. **`__builtins__` vs `builtins`**:

    - `__builtins__` — это псевдомодуль, который есть в каждом модуле. В `__main__` это ссылка на модуль `builtins`, а в
      импортированных модулях — на его словарь `builtins.__dict__`
    - `builtins` — реальный модуль, который можно импортировать
    - Это различие важно для тестирования, так как переопределение в `__builtins__` влияет только на текущий модуль

5. **Опасные функции: `eval()`, `exec()`, `compile()`**:

    - `eval()` принимает выражение и возвращает его значение. Работает в текущем пространстве имен
    - `exec()` выполняет код (может быть многострочным). Возвращает `None`
    - `compile()` преобразует строку в объект кода, который потом можно выполнить

   **Безопасность**: Эти функции выполняют произвольный код. В production-коде нужно:
    - Ограничивать глобальные и локальные пространства имен
    - Использовать `ast.literal_eval()` для безопасного вычисления литералов
    - В тестах — быть осторожным при тестировании кода, использующего эти функции

6. **`property()`, `classmethod()`, `staticmethod()` как дескрипторы**:

   Эти функции не просто возвращают декорированные методы — они создают объекты-дескрипторы:
   ```c
   // property() в CPython
   property_new(PyTypeObject *type, PyObject *args, PyObject *kwds) {
       // Создает property object с слотами для getter, setter, deleter, doc
   }
   ```

   При доступе к свойству через экземпляр класса срабатывает протокол дескриптора (`__get__`, `__set__`, `__delete__`).

7. **`super()` — магия на уровне C**:

   `super()` не просто возвращает родительский класс. Она:
    - Динамически вычисляет MRO (Method Resolution Order)
    - Использует `__class__` и `self` из фрейма вызова
    - В CPython: `super_new()` в `Objects/typeobject.c` анализирует стек вызовов через `PyThreadState_GET()->frame`

8. **`range()` — не просто функция, а фабрика объектов**:

   В Python 3 `range()` возвращает объект типа `range`, который:
    - Реализует `__len__`, `__getitem__`, `__contains__`
    - Поддерживает слайсинг: `range(10)[2:5]` возвращает новый `range`
    - Имеет постоянную память O(1) независимо от размера
    - В CPython вычисляет элементы на лету через формулу: `start + i*step`

9. **`print()` и системные вызовы**:

   Реализация `print()` в `builtin_print()`:
    - Парсит аргументы: `sep`, `end`, `file`, `flush`
    - По умолчанию `file=sys.stdout` (объект `PyTextIOWrapper`)
    - Вызывает `PyFile_WriteObject()` для каждого аргумента
    - При `flush=True` вызывает `PyObject_CallMethod(file, "flush", NULL)`
    - В тестах можно перехватывать вывод через `io.StringIO` или мокать `sys.stdout`

10. **`open()` и файловые дескрипторы**:

    `open()` — это фабрика, которая возвращает разные типы в зависимости от режима:
    - Текстовый режим: `_io.TextIOWrapper`
    - Бинарный: `_io.BufferedReader` или `_io.BufferedWriter`
    - Режим 'x' (эксклюзивное создание): проверка через `os.O_EXCL`

    На уровне системы вызывает `open()` из libc с флагами `O_RDONLY`, `O_WRONLY`, `O_CREAT` и т.д.

11. **`__import__()` — основа импорта**:

    Эта функция:
    - Вызывается оператором `import`
    - Проходит через `importlib` и sys.meta_path
    - Кэширует загруженные модули в `sys.modules`
    - В тестах можно мокать для изоляции модулей

12. **Производительность и микрооптимизации**:

    - `len()` для встроенных типов — O(1), так как обращается к полю `ob_size` в `PyObject`
    - `sum()` использует быстрый путь для чисел, но медленный для других типов (из-за создания промежуточных объектов)
    - `min()`/`max()` для отсортированных данных могут быть оптимизированы, но в общем случае — O(n)
    - `sorted()` использует Timsort (гибрид сортировки слиянием и вставками)

13. **Для AQA: тестирование встроенных функций**:

    - **Мокирование**: `unittest.mock.patch('builtins.open')` для тестирования работы с файлами
    - **Перехват ввода-вывода**: `io.StringIO` для `input()`/`print()`
    - **Изоляция**: временное изменение `sys.path` для тестирования импорта
    - **Безопасность**: тестирование `eval()`/`exec()` на уязвимости инъекции кода
    - **Производительность**: бенчмаркинг встроенных функций vs кастомных реализаций
    - **Поведение при ошибках**: как функции реагируют на некорректные аргументы

14. **Диагностика через байткод**:

    Можно анализировать, как используются встроенные функции в тестируемом коде:
    ```python
    import dis
    dis.dis(some_function)  # Показывает CALL_FUNCTION для встроенных функций
    ```

================================================================================================================================

### Контекстные менеджеры

#### **Определение**

Контекстные менеджеры — это объекты Python, которые определяют контекст выполнения блока кода с помощью оператора
`with`. Они обеспечивают корректное управление ресурсами: гарантируют выполнение начальных действий при входе в
контекст (setup) и завершающих действий при выходе (teardown), даже если в контексте возникло исключение. Этот паттерн
часто называют RAII (Resource Acquisition Is Initialization) и он применяется для работы с файлами, сетевыми
соединениями, транзакциями БД, блокировками и другими ресурсами, требующими явного освобождения.

#### **Внутренняя реализация (под капотом)**

1. **Протокол контекстного менеджера**:
    - Контекстный менеджер должен реализовать два специальных метода: `__enter__()` и `__exit__()`.
    - При входе в блок `with` вызывается `__enter__()`. Его возвращаемое значение (часто сам объект или другой ресурс)
      присваивается переменной после `as`.
    - При выходе из блока вызывается `__exit__(exc_type, exc_value, traceback)`, куда передаётся информация об
      исключении (или `None`, если исключения не было).

2. **Компиляция оператора `with`**:
    - Оператор `with` компилируется в байт-код, который гарантирует вызов `__exit__()` при любом исходе. В CPython это
      реализовано через инструкции `SETUP_WITH` и `WITH_CLEANUP_START`.
    - Даже при возникновении исключения интерпретатор вызывает `__exit__()` перед распространением исключения дальше по
      стеку.

3. **Дескрипторы и менеджеры контекста**:
    - Для функций-генераторов, обёрнутых в `contextlib.contextmanager`, создаётся специальный объект-обёртка,
      реализующий протокол.
    - Декоратор `@contextmanager` преобразует генератор в контекстный менеджер: код до `yield` выполняется в
      `__enter__()`, значение после `yield` возвращается, а код после `yield` выполняется в `__exit__()`.

4. **Асинхронные контекстные менеджеры**:
    - Для асинхронного кода существует аналогичный протокол с методами `__aenter__()` и `__aexit__()`, используемый с
      конструкцией `async with`.
    - Реализация в CPython включает отдельные инструкции для асинхронного контекста.

5. **Множественные контекстные менеджеры**:
    - Конструкция `with cm1() as x, cm2() as y:` компилируется как вложенные вызовы. Порядок вызова `__enter__()` —
      прямой, `__exit__()` — обратный (как в стеке).

6. **Исключения и их подавление**:
    - Если `__exit__()` возвращает `True`, исключение считается обработанным и не распространяется. Если `False` или
      `None` — исключение пробрасывается дальше.
    - При возникновении исключения внутри `__exit__()` оно имеет приоритет над исходным исключением (в Python 3.5+ это
      приводит к `RuntimeWarning`).

#### **Особенности**

1. **Гарантированное освобождение ресурсов**:
    - Контекстные менеджеры обеспечивают детерминированное освобождение ресурсов, что критично для избежания утечек
      памяти, дескрипторов файлов, блокировок.

2. **Универсальность применения**:
    - Помимо управления ресурсами, контекстные менеджеры используются для временного изменения состояния: модификации
      переменных окружения, перенаправления вывода (`sys.stdout`), изменения текущей директории, установки временных
      таймаутов.

3. **Производительность**:
    - Использование `with` добавляет минимальные накладные расходы (вызов двух методов). Однако это окупается
      безопасностью и читаемостью.

4. **Вложенность и композиция**:
    - Контекстные менеджеры можно комбинировать. Если один из них в цепочке вызывает исключение, все предыдущие успешно
      созданные контексты корректно завершатся.

5. **Контекстные менеджеры в стандартной библиотеке**:
    - Многие модули предоставляют встроенные контекстные менеджеры: `open()` для файлов, `threading.Lock()` для
      блокировок, `unittest.mock.patch()` для мокирования, `sqlite3` для транзакций.

6. **Неявное использование**:
    - Некоторые конструкции (например, `@contextmanager`) скрывают явную реализацию `__enter__`/`__exit__`, что может
      затруднять отладку.

#### **Лучшие практики**

1. **Использование для тестовых ресурсов**:
    - В AQA контекстные менеджеры идеальны для управления тестовыми данными: временные файлы/БД, изоляция тестовых
      окружений, захват и освобождение внешних сервисов.
    - Используйте `tempfile.TemporaryDirectory` и `TemporaryFile` для работы с временными данными.

2. **Создание кастомных контекстных менеджеров**:
    - При частом повторении setup/teardown логики в тестах выносите её в контекстный менеджер. Например, для авторизации
      в системе, переключения конфигураций, эмуляции сетевых сбоев.
    - Предпочитайте `@contextmanager` для простых сценариев и классы с `__enter__`/`__exit__` для сложных (когда нужно
      хранить состояние).

3. **Безопасная работа с исключениями**:
    - В `__exit__()` всегда логируйте или обрабатывайте исключения. Возвращайте `False`, если не можете гарантировать
      корректную обработку ошибки.
    - Используйте `contextlib.suppress()` для временного игнорирования определённых исключений внутри блока.

4. **Интеграция с фреймворками тестирования**:
    - В pytest используйте фикстуры (fixtures) с `yield` для управления контекстом (это аналог контекстных менеджеров на
      уровне фикстур).
    - Для unittest создавайте контекстные менеджеры для `setUp` и `tearDown` методов.

5. **Тестирование контекстных менеджеров**:
    - Убедитесь, что контекстные менеджеры корректно работают как при нормальном выполнении, так и при исключениях.
    - Проверяйте, что ресурсы действительно освобождаются: например, файл закрывается, соединение возвращается в пул.

6. **Асинхронные тесты**:
    - Для асинхронного тестирования используйте `async with`. Например, для управления асинхронными клиентами БД или
      HTTP-сессиями.
    - Помните, что `__aenter__` и `__aexit__` — корутины, и их нужно вызывать с `await`.

7. **Контекстные менеджеры для мокирования**:
    - `unittest.mock.patch` часто используется как контекстный менеджер для временной подмены объектов в тестах. Это
      позволяет изолировать тест от внешних зависимостей.
    - При мокировании нескольких объектов используйте вложенные `with` или `patch.multiple`.

8. **Измерение производительности**:
    - Создавайте контекстные менеджеры для замеров времени выполнения блоков кода в тестах производительности.
      Используйте `time.perf_counter()` в `__enter__` и `__exit__`.

9. **Работа с транзакциями**:
    - В интеграционных тестах с БД оборачивайте тестовые операции в контекстный менеджер транзакции с последующим
      откатом (`ROLLBACK`), чтобы не засорять базу.

10. **Документирование контекстных менеджеров**:
    - Чётко документируйте, какие ресурсы захватываются, какие гарантии предоставляются и какие исключения могут
      возникнуть.

================================================================================================================================

# Генераторы и итераторы

#### **Определение**

**Итератор** — это объект, реализующий протокол итерации через методы `__iter__()` и `__next__()`. Он предоставляет
последовательный доступ к элементам коллекции или вычисляемым значениям, сохраняя текущее состояние итерации. *
*Генератор** — это частный случай итератора, создаваемый с помощью функции с ключевым словом `yield` или генераторного
выражения. Генераторы позволяют лениво (lazy) вычислять значения по мере необходимости, что особенно полезно для работы
с большими или бесконечными последовательностями данных.

#### **Внутренняя реализация (под капотом)**

1. **Протокол итератора в CPython**:
    - Итератор должен иметь метод `__iter__()`, возвращающий сам объект, и метод `__next__()`, возвращающий следующий
      элемент или выбрасывающий `StopIteration`.
    - В CPython вызов `iter(obj)` приводит к поиску метода `__iter__`. Если его нет, но есть `__getitem__`, создаётся
      итератор по умолчанию.
    - Метод `__next__` реализуется на уровне C-структур (`PyTypeObject.tp_iternext`), что обеспечивает минимальные
      накладные расходы.

2. **Генераторы как stackless-корутины**:
    - Генераторная функция при компиляции помечается флагом `CO_GENERATOR` в её кодовом объекте (`code.co_flags`).
    - При вызове такой функции возвращается объект-генератор типа `PyGenObject`, содержащий:
        - **Фрейм выполнения** (`PyFrameObject`): хранит локальные переменные, стек вызовов и указатель на последнюю
          выполненную инструкцию.
        - **Состояние**: `GEN_CREATED`, `GEN_RUNNING`, `GEN_SUSPENDED`, `GEN_CLOSED`.
    - Ключевое слово `yield` компилируется в инструкцию `YIELD_VALUE`, которая приостанавливает генератор, сохраняет
      состояние фрейма и возвращает значение.

3. **Генераторные выражения**:
    - Выражения вида `(x for x in iterable)` создают анонимный генератор. Компилятор преобразует их в скрытую
      генераторную функцию с тем же механизмом `YIELD_VALUE`.

4. **Связь с циклом for**:
    - Цикл `for` неявно вызывает `iter()` для объекта, затем в цикле вызывает `next()` до получения `StopIteration`. Для
      генераторов это происходит без создания промежуточных списков.

5. **Методы генераторов**:
    - `generator.send(value)`: отправляет значение в генератор, которое становится результатом `yield`. Реализуется
      через инструкцию `YIELD_VALUE`, которая может принимать значение из стека.
    - `generator.throw(exc)`: бросает исключение внутри генератора в точке приостановки.
    - `generator.close()`: вызывает `GeneratorExit` внутри генератора, приводя к его завершению.

6. **Асинхронные генераторы** (Python 3.6+):
    - Используют `async def` и `await yield`. Имеют методы `__aiter__` и `__anext__`, возвращающие awaitable-объекты.
    - Реализованы через структуру `PyAsyncGenObject`, аналогичную `PyGenObject`, но с поддержкой асинхронного
      выполнения.

7. **Оптимизация памяти**:
    - Генераторы не хранят все элементы в памяти, а вычисляют их по одному. Фрейм генератора занимает фиксированную
      память (обычно несколько килобайт), независимо от размера последовательности.

#### **Особенности**

1. **Ленивые вычисления**: Генераторы вычисляют значения только при вызове `next()`, что экономит память и CPU при
   работе с большими данными.

2. **Однопроходность**: Большинство итераторов и генераторов одноразовые — после исчерпания (`StopIteration`) их нельзя
   переиспользовать без повторного создания.

3. **Состояние приостановки**: Генераторы сохраняют состояние локальных переменных между вызовами, что позволяет
   создавать сложные конечные автоматы без явного хранения состояния в классе.

4. **Взаимодействие с исключениями**: Исключения, брошенные в генератор, могут быть обработаны внутри него с помощью
   `try/except`, что позволяет реализовать отказоустойчивые конвейеры обработки данных.

5. **Делегирование генерации**: `yield from` (Python 3.3+) позволяет делегировать генерацию подгенератору, упрощая
   композицию генераторов и создание рекурсивных генераторов.

6. **Генераторы vs. итераторы**: Любой генератор является итератором, но не наоборот. Итераторы могут быть реализованы
   через классы, что полезно для сложной логики, но менее лаконично.

7. **Производительность**: Генераторы имеют небольшие накладные расходы на приостановку и возобновление, но выигрывают в
   памяти. Для простых итераций по коллекциям встроенные итераторы (`list_iterator`, `tuple_iterator`) быстрее.

#### **Лучшие практики**

1. **Обработка больших данных в тестах**:
    - Используйте генераторы для чтения больших логов, CSV-файлов или потоковых ответов API в тестах. Это предотвращает
      `MemoryError` и ускоряет начало тестирования.
    - Например, построчное чтение файла с помощью генератора вместо `readlines()`.

2. **Создание тестовых данных**:
    - Генераторы идеальны для генерации динамических тестовых данных (например, `(f"user_{i}" for i in range(100000))`).
    - В pytest используйте `@pytest.fixture` с `yield` для setup/teardown (фикстуры-генераторы).

3. **Параметризация тестов**:
    - Используйте генераторы для создания параметров в `@pytest.mark.parametrize`, если данные вычисляются лениво или
      читаются из внешнего источника.

4. **Мокирование и симуляция потоков**:
    - Создавайте генераторы для симуляции потоковых данных (например, пакетов сети) в интеграционных тестах.
    - Мокируйте методы, возвращающие итераторы, с помощью `unittest.mock.Mock(return_value=iter([...]))`.

5. **Тестирование самих генераторов**:
    - Убедитесь, что генераторы корректно выбрасывают `StopIteration`. Используйте `list(gen)` для конвертации в список,
      если нужно проверить все значения.
    - Тестируйте реакцию на `send()`, `throw()` и `close()` для генераторов с двусторонней связью.

6. **Использование `itertools`**:
    - Модуль `itertools` содержит оптимизированные итераторы и генераторы для комбинаторики, группировки и фильтрации.
      Используйте их вместо самописных циклов.

7. **Закрытие ресурсов**:
    - Если генератор использует ресурсы (файлы, соединения), гарантируйте их освобождение с помощью `try/finally` внутри
      генератора или контекстных менеджеров.

8. **Асинхронное тестирование**:
    - Для асинхронных тестов используйте асинхронные генераторы и `async for`. В pytest применяйте `pytest-asyncio` и
      асинхронные фикстуры.
    - Тестируйте асинхронные генераторы с помощью `async with` и `async for`.

9. **Избегание распространённых ошибок**:
    - Не используйте генераторы, если нужен многократный обход данных — преобразуйте в список или реализуйте `__iter__`,
      возвращающий новый генератор.
    - Помните, что генераторное выражение `(...)` возвращает генератор, а не список. Для списка используйте `[...]`.

10. **Профилирование и оптимизация**:
    - При профилировании тестов обратите внимание на время, проведённое в генераторах. Для CPU-интенсивных операций
      рассмотрите использование `map` или `asyncio`.
    - Используйте `yield from` для уплощения вложенных генераторов и улучшения читаемости.

================================================================================================================================

# Декораторы и замыкания

================================================================================================================================

# GIL (Global Interpreter Lock)

#### **Определение**

GIL (Global Interpreter Lock) — это глобальная блокировка интерпретатора, механизм в реализации CPython, который
предотвращает одновременное выполнение байт-кода Python несколькими потоками в рамках одного процесса. GIL гарантирует,
что в любой момент времени только один поток выполняет Python-байткод, что упрощает управление памятью и интеграцию с
C-расширениями, но ограничивает истинную многопоточность для CPU-интенсивных задач.

#### **Внутренняя реализация (под капотом)**

1. **Архитектура GIL в CPython**:
    - GIL реализован как глобальная переменная типа `PyThread_type_lock` в ядре CPython. Это взаимное исключение (
      mutex), защищающее доступ к структурам интерпретатора.
    - Каждый поток перед выполнением Python-кода должен захватить GIL. В CPython реализован циклический алгоритм: поток
      удерживает GIL в течение фиксированного интервала (по умолчанию 5 мс) или пока не выполнит определённое количество
      байт-код инструкций.

2. **Управление переключениями потоков**:
    - В Python 3.9+ используется улучшенный алгоритм на основе временных срезов. Поток добровольно освобождает GIL по
      истечении кванта времени или при блокирующих операциях (I/O, sleep, синхронизация).
    - Механизм "отложенных вызовов" (pending calls) позволяет потоку запросить GIL для выполнения асинхронных операций.

3. **Взаимодействие с памятью**:
    - GIL защищает механизм подсчёта ссылок (reference counting). Без GIL одновременное изменение счётчиков ссылок из
      нескольких потоков привело бы к повреждению памяти.
    - Сборщик мусора также полагается на GIL для безопасного обнаружения циклических ссылок.

4. **Байт-код и интерпретатор**:
    - Виртуальная машина CPython (цикл интерпретации `ceval.c`) проверяет наличие GIL перед выполнением каждой
      инструкции байт-кода через макрос `PyGILState_Ensure()`.
    - Некоторые "опасные" операции (например, вызовы системных функций) явно отпускают GIL через
      `Py_BEGIN_ALLOW_THREADS`.

5. **GIL и подпроцессы**:
    - GIL существует только в рамках одного процесса. Мультипроцессинг (модуль `multiprocessing`) создаёт отдельные
      процессы с собственными GIL, что позволяет использовать несколько ядер CPU.

6. **Альтернативные реализации**:
    - Проект "nogil" (Python 3.11+) экспериментирует с удалением GIL через более сложные механизмы синхронизации (RCU,
      hazard pointers).
    - Другие реализации Python (Jython, IronPython) не имеют GIL, так как используют управляемую память (JVM, .NET).

7. **GIL в асинхронном коде**:
    - Асинхронные задачи (asyncio) выполняются в одном потоке, поэтому GIL не ограничивает параллелизм для I/O-операций.
      Однако при использовании `run_in_executor()` с потоками GIL снова становится фактором.

#### **Особенности**

1. **Влияние на производительность**:
    - GIL практически не влияет на I/O-интенсивные приложения (веб-серверы, сети), так как потоки освобождают GIL во
      время ожидания.
    - Для CPU-интенсивных задач (вычисления, обработка данных) GIL превращает многопоточность в псевдопараллелизм,
      ограничивая использование многоядерных систем.

2. **Преимущества GIL**:
    - Упрощает реализацию CPython и снижает накладные расходы на синхронизацию.
    - Обеспечивает безопасность для C-расширений, которые не являются потокобезопасными.
    - Ускоряет однопоточные приложения за счёт отсутствия конкуренции за блокировки.

3. **GIL и конкурентность**:
    - Не защищает от состояния гонки (race conditions) для пользовательских структур данных. Необходимо использовать
      примитивы синхронизации (`threading.Lock`, `RLock`).
    - Потоки всё равно могут переключаться между операциями байт-кода, что приводит к интерливингу (interleaving) и
      потенциальным гонкам.

4. **Освобождение GIL в C-расширениях**:
    - Нативные модули (NumPy, cryptography) могут освобождать GIL для длительных вычислений на C, позволяя другим
      потокам выполняться.
    - Используются макросы `Py_BEGIN_ALLOW_THREADS` и `Py_END_ALLOW_THREADS`.

5. **GIL в современных версиях Python**:
    - Начиная с Python 3.9, улучшен алгоритм планирования потоков для уменьшения задержек.
    - В Python 3.10+ добавлены детекторы deadlock для GIL в отладочных сборках.

#### **Лучшие практики для AQA**

1. **Тестирование многопоточных приложений**:
    - При тестировании многопоточного кода необходимо учитывать, что GIL не устраняет race conditions. Используйте
      стресс-тесты с большим количеством итераций и принудительным переключением потоков (например, `time.sleep(0)`).
    - Применяйте детерминированные инструменты тестирования, такие как `threading` с фиксированным порядком выполнения
      или специализированные библиотеки (например, `hypothesis` для генерации сценариев).

2. **Производительность и нагрузочное тестирование**:
    - Для CPU-интенсивных операций не полагайтесь на многопоточность для увеличения производительности. Вместо этого
      используйте мультипроцессинг или асинхронные вычислительные пулы (`concurrent.futures.ProcessPoolExecutor`).
    - При нагрузочном тестировании веб-приложений учитывайте, что GIL может стать узким местом при высокой концентрации
      рабочих потоков. Мониторьте утилизацию CPU: если одно ядро загружено на 100%, а остальные простаивают — это
      признак ограничения GIL.

3. **Тестирование C-расширений**:
    - При тестировании нативных модулей проверяйте, корректно ли они освобождают GIL. Используйте профайлеры (например,
      `py-spy`) для анализа одновременной работы потоков.
    - Имитируйте высокую конкурентность, чтобы убедиться, что расширения не держат GIL слишком долго.

4. **Использование альтернатив потокам**:
    - Для параллельной обработки данных в тестах используйте `multiprocessing` или `asyncio`. Например, при тестировании
      API с множеством одновременных запросов используйте асинхронные клиенты (aiohttp).
    - В интеграционных тестах с базой данных применяйте пулы соединений, которые обычно реализованы с учётом GIL.

5. **Диагностика проблем с GIL**:
    - Используйте `sys.setcheckinterval()` (устарел) и `sys.setswitchinterval()` для настройки частоты переключения
      потоков в тестах.
    - Для отладки взаимных блокировок применяйте инструменты типа `faulthandler` или отладочные сборки Python.

6. **Тестирование асинхронного кода**:
    - Асинхронные фреймворки (asyncio) не страдают от GIL при правильном использовании. Однако убедитесь, что в коде нет
      блокирующих вызовов, которые захватывают GIL надолго.
    - Используйте `asyncio.sleep(0)` для принудительного переключения контекста в тестах.

7. **Бенчмаркинг и метрики**:
    - При сравнении производительности разных подходов (потоки vs процессы) учитывайте накладные расходы на создание
      потоков/процессов и IPC (inter-process communication).
    - Измеряйте не только общее время выполнения, но и утилизацию CPU по ядрам.

8. **Тестирование с альтернативными интерпретаторами**:
    - Для проектов, где многопоточность критична, рассмотрите тестирование на PyPy (который имеет GIL, но с другими
      характеристиками) или экспериментальных сборках CPython без GIL.
    - Учитывайте, что поведение может отличаться, особенно для C-расширений.

9. **Документирование ограничений**:
    - В отчётах о производительности явно указывайте, когда ограничение связано с GIL. Предлагайте архитектурные
      изменения (например, переход на микросервисы с отдельными процессами).

================================================================================================================================

### Изменение списка во время итерации

#### **Определение**

Изменение списка во время итерации — это модификация структуры или содержимого списка (добавление, удаление или
изменение элементов) в процессе его обхода с помощью цикла. В Python это считается опасной операцией, которая может
привести к неопределённому поведению, пропуску элементов, бесконечным циклам или ошибкам времени выполнения, поскольку
нарушает инварианты итератора.

#### **Внутренняя реализация (под капотом)**

1. **Механизм итерации списка**:
    - При выполнении `for x in lst:` интерпретатор вызывает `iter(lst)`, который возвращает объект-итератор типа
      `list_iterator`.
    - Этот итератор хранит ссылку на исходный список и текущий индекс (целое число, начинающееся с 0).
    - Каждый вызов `__next__()` возвращает элемент `lst[index]` и увеличивает индекс на 1.

2. **Структура list_iterator в CPython**:
    - Итератор списка представлен структурой `listiterobject` в C, содержащей:
        - Указатель на исходный список (`it_seq`)
        - Текущий индекс (`it_index`)
        - Длину списка на момент создания итератора (`it_len`)
    - При создании итератора длина фиксируется для оптимизации, но при модификации списка эта длина может стать
      неактуальной.

3. **Влияние удаления элементов**:
    - При удалении элемента по текущему индексу или до него, все последующие элементы сдвигаются влево, но индекс
      итератора продолжает увеличиваться линейно.
    - Это приводит к пропуску элемента, который переместился на позицию текущего индекса.
    - Например, при удалении элемента `i`, элемент `i+1` становится на позицию `i`, но итератор уже перейдёт к индексу
      `i+1`, пропустив его.

4. **Влияние добавления элементов**:
    - Добавление элементов в начало или середину списка сдвигает существующие элементы вправо.
    - Итератор продолжает движение по исходным индексам, что может привести к повторной обработке элементов или выходу
      за границы.

5. **Изменение размера списка и realloc**:
    - Списки в Python — это динамические массивы. При добавлении элементов может происходить перераспределение памяти (
      realloc).
    - Если во время итерации происходит realloc, итератор может сохранить указатель на старую область памяти, что
      приведёт к чтению неактуальных данных или segfault (в CPython есть защита от этого, но логика итерации
      нарушается).

6. **Безопасные операции**:
    - Изменение значения элемента по текущему индексу (`lst[i] = new_value`) безопасно, так как не изменяет структуру
      списка.
    - Модификация вложенных объектов (если список содержит mutable элементы) также безопасна для итератора.

7. **Внутренние проверки в CPython**:
    - В некоторых случаях Python может обнаружить изменение списка во время итерации и выбросить
      `RuntimeError: dictionary changed size during iteration` (для словарей), но для списков такой проверки нет —
      поведение просто становится некорректным.

#### **Особенности**

1. **Непредсказуемость поведения**:
    - Результат зависит от типа модификации (добавление/удаление), позиции изменения и текущего индекса.
    - Ошибки могут проявляться не всегда, что делает их особенно опасными — они могут оставаться незамеченными до
      продакшена.

2. **Разница между for и while**:
    - Цикл `while i < len(lst):` с ручным управлением индексом также подвержен проблемам, так как `len(lst)` вычисляется
      на каждой итерации, и при удалении элементов индекс может выйти за границы.

3. **Итерация по срезу или копии**:
    - Итерация по срезу `lst[:]` создаёт копию списка, поэтому модификации оригинала не влияют на итерацию. Однако это
      требует O(N) дополнительной памяти.

4. **Глубокие vs поверхностные копии**:
    - Если список содержит mutable объекты, поверхностная копия не защищает от изменения этих объектов во время
      итерации.

5. **Влияние на производительность**:
    - Частое изменение размера списка во время итерации приводит к многократным realloc, что деградирует
      производительность.

#### **Лучшие практики для AQA**

1. **Стратегии безопасной модификации**:
    - **Итерация по копии, модификация оригинала**: Создавайте копию списка для итерации (`for item in lst.copy():`), а
      изменения вносите в исходный список. Это безопасно, но требует дополнительной памяти.
    - **Сбор элементов для удаления**: Аккумулируйте элементы для удаления в отдельный список, а после итерации
      выполните удаление (например, с помощью list comprehension: `lst = [x for x in lst if condition]`).
    - **Обратная итерация**: При удалении элементов итерируйтесь с конца (`for i in range(len(lst)-1, -1, -1):`). Это
      предотвращает сдвиг индексов для ещё не обработанных элементов.

2. **Тестирование кода с модификацией списков**:
    - Включайте в тестовые сценарии случаи модификации списков во время итерации. Проверяйте, что код либо корректно
      обрабатывает эти ситуации, либо явно запрещает их (документацией или исключениями).
    - Используйте property-based тестирование (Hypothesis) для генерации списков и операций модификации, чтобы выявить
      скрытые ошибки.

3. **Статический анализ**:
    - Настройте линтеры (flake8, pylint) для обнаружения потенциально опасных паттернов. Некоторые линтеры могут
      предупреждать о модификации итерируемого объекта.
    - Используйте type hints и mypy для выявления операций, которые могут изменить структуру списка.

4. **Атомарные операции**:
    - При работе с многопоточными или асинхронными тестами используйте потокобезопасные структуры (`queue.Queue`,
      `collections.deque` с блокировками) вместо списков, если возможна конкурентная модификация.

5. **Тестирование граничных случаев**:
    - Создавайте тесты, где список изменяется на каждой итерации, увеличивается/уменьшается, становится пустым.
    - Проверяйте поведение при исключениях во время модификации списка — гарантирует ли код целостность данных.

6. **Использование специализированных структур данных**:
    - Если логика требует частой вставки/удаления во время итерации, рассмотрите `collections.deque` (двусторонняя
      очередь) или связанные списки. Однако для тестового кода это редко требуется.

7. **Документирование поведения**:
    - Если в тестовом фреймворке или утилитах допускается модификация списков во время итерации, это должно быть явно
      задокументировано с примерами безопасного использования.

8. **Производительность в тестах**:
    - В нагрузочных тестах избегайте паттернов, которые ведут к квадратичной сложности из-за частых изменений списков (
      например, удаление элементов из начала списка в цикле — O(N²)).
    - Используйте `collections.deque` для операций с обоих концов (O(1)).

9. **Анализ покрытия**:
    - Убедитесь, что тесты покрывают ветки кода, связанные с модификацией коллекций. Инструменты вроде coverage.py могут
      помочь выявить непокрытые строки.

================================================================================================================================

### Области видимости (scope)

#### **Определение**

Область видимости (scope) — это контекст в программе Python, где определено имя (переменная, функция, класс) и где это
имя может быть использовано. Python использует правила разрешения имён, определяющие, в каком порядке искать имя при его
использовании. Области видимости создают изоляцию между разными частями программы, предотвращая нежелательные
взаимодействия и обеспечивая инкапсуляцию.

#### **Внутренняя реализация (под капотом)**

1. **Пространства имён (namespaces)**:
    - Каждая область видимости реализована как пространство имён — словарь (или его оптимизированная версия), который
      связывает имена с объектами.
    - В CPython локальные переменные функций хранятся в массиве фиксированного размера (fast locals), а не в словаре,
      для ускорения доступа.
    - Глобальные переменные хранятся в словаре модуля (`module.__dict__`).

2. **Иерархия областей видимости (LEGB)**:
    - **L (Local)**: Локальная область внутри функции. Реализована через фрейм выполнения функции (`PyFrameObject`),
      содержащий массив локальных переменных и стек.
    - **E (Enclosing)**: Область охватывающих (внешних) функций для замыканий. Каждый уровень вложенности имеет свой
      фрейм, и доступ к внешним переменным осуществляется через cell-объекты в атрибуте `__closure__`.
    - **G (Global)**: Глобальная область модуля. Реализована как словарь `globals()`, который ссылается на
      `module.__dict__`.
    - **B (Built-in)**: Встроенная область, содержащая имена встроенных функций и исключений. Реализована через модуль
      `builtins` (`__builtins__`).

3. **Компиляция и байт-код**:
    - При компиляции Python определяет, к какой области видимости относится каждое имя, и генерирует соответствующие
      инструкции байт-кода:
        - `LOAD_FAST`: доступ к локальной переменной (по индексу в массиве).
        - `LOAD_GLOBAL`: доступ к глобальной или встроенной переменной.
        - `LOAD_DEREF`: доступ к переменной из охватывающей области (через cell-объект).
    - Ключевые слова `global` и `nonlocal` изменяют привязку имени на этапе компиляции, заставляя использовать
      `LOAD_GLOBAL` или `LOAD_DEREF` вместо `LOAD_FAST`.

4. **Фреймы выполнения (frames)**:
    - При вызове функции создаётся объект фрейма (`PyFrameObject`), содержащий:
        - Локальные переменные.
        - Ссылку на глобальное пространство имён.
        - Ссылку на пространство имён внешней функции (для замыканий).
        - Стек значений.
    - Фреймы организованы в стек вызовов, и каждый фрейм изолирует свою локальную область видимости.

5. **Замыкания (closures)**:
    - Если внутренняя функция использует переменную из внешней функции, эта переменная сохраняется в cell-объекте,
      который живёт дольше, чем время выполнения внешней функции.
    - Cell-объекты (`PyCellObject`) позволяют нескольким вложенным функциям разделять одну и ту же переменную.

6. **Классы и области видимости**:
    - Тело класса выполняется в новой временной области видимости (namespace), которая затем становится `__dict__`
      класса.
    - Методы класса имеют собственную локальную область, но могут обращаться к атрибутам класса через `self` или имя
      класса.

7. **Comprehensions и генераторы**:
    - Начиная с Python 3.x, comprehensions (списковые, словарные и т.д.) и выражения-генераторы имеют собственную
      изолированную область видимости, подобную функции.

#### **Особенности**

1. **Динамическое определение области**:
    - Область видимости определяется во время выполнения, но привязка имён фиксируется при компиляции. Однако с помощью
      `exec()` или `eval()` можно динамически изменять пространства имён.

2. **Отсутствие блочной области видимости**:
    - В Python нет области видимости на уровне блоков (if, for, while). Переменные, определённые внутри блока, видны во
      всей функции.

3. **Глобальные переменные**:
    - Глобальные переменные доступны для чтения из любой функции, но для записи требуется ключевое слово `global`.
    - Модуль — это синглтон, поэтому его глобальные переменные разделяются всеми импортёрами.

4. **Нелокальные переменные (nonlocal)**:
    - Ключевое слово `nonlocal` (появилось в Python 3) позволяет изменять переменные из ближайшей охватывающей области,
      но не глобальной.

5. **Встроенная область**:
    - Встроенные имена (print, len и т.д.) загружаются последними, что позволяет их переопределять на глобальном или
      локальном уровне (хотя это антипаттерн).

6. **Пространство имён модуля**:
    - При импорте модуля создаётся его глобальное пространство имён, которое сохраняется в `sys.modules`. Повторный
      импорт возвращает тот же объект модуля.

#### **Лучшие практики для AQA**

1. **Изоляция тестовых данных**:
    - Используйте локальные переменные в тестовых функциях, чтобы избежать случайного влияния между тестами.
    - Глобальные переменные в тестовых модулях допустимы только для конфигураций, которые не изменяются во время
      выполнения тестов.

2. **Использование фикстур (fixtures)**:
    - В pytest используйте фикстуры для инкапсуляции setup/teardown. Фикстуры создают изолированные контексты для
      каждого теста, предотвращая утечку состояния.

3. **Мокирование и патчинг**:
    - При использовании `unittest.mock.patch` понимайте область действия патчей:
        - `patch` как декоратор применяется к области видимости функции.
        - `patch` как контекстный менеджер — к блоку `with`.
    - Патчинг глобальных переменных модуля требует осторожности в параллельных тестах.

4. **Избегание побочных эффектов**:
    - Не изменяйте глобальное состояние в тестах без необходимости. Если нужно, используйте `setup_module` и
      `teardown_module` для управления глобальным контекстом.

5. **Тестирование замыканий**:
    - При тестировании функций с замыканиями проверяйте, что они корректно захватывают и используют внешние переменные.
    - Используйте `inspect.getclosurevars()` для анализа захваченных переменных.

6. **Динамическое создание тестов**:
    - При динамической генерации тестов (например, в цикле) убедитесь, что каждая тестовая функция получает уникальное
      пространство имён. Используйте замыкания или `lambda` с аргументами для привязки значений.

7. **Работа с пространствами имён в отладке**:
    - При отладке сложных тестов используйте `locals()` и `globals()` для проверки текущего состояния.
    - В отчетах об ошибках фиксируйте значения переменных из соответствующей области видимости.

8. **Конфликты имён**:
    - Избегайте переопределения встроенных имён (например, `list`, `dict`) даже в локальной области, так как это снижает
      читаемость и может привести к ошибкам.

9. **Использование `nonlocal` в тестовых помощниках**:
    - При создании сложных помощников (helpers) с вложенными функциями, которые должны изменять состояние, используйте
      `nonlocal` вместо глобальных переменных.

10. **Область видимости в параметризованных тестах**:
    - В `pytest.mark.parametrize` параметры становятся локальными переменными тестовой функции. Убедитесь, что имена не
      конфликтуют с другими локальными переменными.

11. **Асинхронные тесты**:
    - В асинхронных тестах каждая корутина имеет свою собственную область видимости, но разделяет глобальное состояние.
      Используйте локальные переменные в `async def` функциях.

12. **Статический анализ**:
    - Используйте линтеры (pylint, flake8) для обнаружения неиспользуемых переменных, переопределений имён и других
      проблем с областями видимости.

================================================================================================================================

### Lambda-функции

#### **Определение**

Lambda-функции — это анонимные (безымянные) функции, которые создаются с использованием ключевого слова `lambda`. Они
представляют собой компактный способ определения простых функций в одну строку и могут содержать только одно выражение,
результат которого автоматически возвращается без использования `return`. Lambda-функции являются вызываемыми объектами
и обычно используются там, где требуется небольшая функция на короткое время, особенно в сочетании с функциями высшего
порядка.

#### **Внутренняя реализация (под капотом)**

1. **Компиляция lambda-выражений**:
    - Lambda-выражения компилируются в байт-код аналогично обычным функциям, но с флагом `CO_NESTED` и именем
      `"<lambda>"`.
    - При компиляции создаётся объект кода (`code object`), содержащий:
        - Аргументы (формальные параметры)
        - Тело lambda (единственное выражение)
        - Флаги, указывающие на захват переменных из внешних областей видимости

2. **Создание объекта функции**:
    - Во время выполнения при встрече lambda-выражения интерпретатор создаёт объект функции (`PyFunctionObject`) на
      основе скомпилированного объекта кода.
    - Lambda-функция является полноправным объектом типа `function`, с атрибутами `__code__`, `__name__` (равным
      `"<lambda>"`), `__defaults__` и `__closure__`.

3. **Замыкания и cell-объекты**:
    - Как и обычные функции, lambda могут захватывать переменные из внешних областей видимости, формируя замыкания.
    - Захваченные переменные хранятся в cell-объектах (`PyCellObject`) в атрибуте `__closure__` функции.

4. **Оптимизации в CPython**:
    - Lambda-функции используют тот же механизм вызова, что и обычные функции: вызов `PyFunction_Call` с передачей
      фрейма выполнения.
    - В Python 3.11+ добавлены оптимизации для быстрого создания и вызова lambda через специализированные
      байткод-инструкции.

5. **Отличие от def-функций**:
    - Основное внутреннее отличие — отсутствие имени в пространстве имён модуля. Lambda создаётся "на лету" и не требует
      присваивания имени.
    - Lambda не может содержать аннотации типов, декораторы или docstrings на уровне синтаксиса.

6. **Семантика байт-кода**:
    - Инструкция `MAKE_FUNCTION` используется как для обычных функций, так и для lambda, но с разными флагами.
    - Для lambda, используемых сразу в вызове, возможна дополнительная оптимизация "inline".

#### **Особенности**

1. **Ограничение на одно выражение**:
    - Lambda может содержать только одно выражение, что исключает возможность использования операторов (`if`, `for`,
      `while`), кроме тернарного оператора.
    - Это ограничение является синтаксическим, а не семантическим — компилятор отвергает многострочные lambda.

2. **Автоматический возврат результата**:
    - Результат вычисления выражения автоматически становится возвращаемым значением. Ключевое слово `return` не
      допускается.

3. **Замыкания и позднее связывание**:
    - Lambda, определённые внутри циклов или условий, захватывают переменные по ссылке, что может привести к известной
      проблеме "позднего связывания", когда все lambda используют одно и то же конечное значение переменной цикла.

4. **Производительность**:
    - Создание lambda незначительно быстрее, чем создание функции через `def`, так как требует меньше операций на этапе
      компиляции.
    - Вызов lambda и обычной функции имеет одинаковую производительность, так как оба являются объектами `function`.

5. **Отладка и трассировка**:
    - Из-за имени `"<lambda>"` отладка может быть сложнее — в трейсбеках не отображается содержательное имя функции.
    - Инструменты профилирования (cProfile) также показывают lambda как `"<lambda>"`, что затрудняет анализ.

6. **Совместимость с типами**:
    - Python 3.9+ поддерживает аннотации типов для параметров lambda (синтаксис `lambda x: int: x * 2`), но это редко
      используется на практике.

#### **Лучшие практики для AQA**

1. **Использование в функциях высшего порядка**:
    - Lambda идеально подходят для кратких преобразований в `map()`, `filter()`, `sorted()` с ключом `key`.
    - В тестовых сценариях используйте lambda для быстрых преобразований данных:
      `sorted(test_cases, key=lambda tc: tc.priority)`

2. **Избегание сложных lambda**:
    - Если lambda превышает одну строку или становится трудночитаемой, замените её на обычную функцию с `def`.
    - Помните: читаемость тестового кода критически важна для поддержки.

3. **Проблема захвата переменных в циклах**:
    - При создании lambda внутри циклов для использования позже, фиксируйте значения через аргументы по умолчанию:
      `lambda x=i: x*2` вместо `lambda: i*2`.
    - Это особенно важно в параметризованных тестах и фабриках тестовых данных.

4. **Lambda в асинхронном контексте**:
    - Lambda не могут быть асинхронными (`async lambda` не поддерживается). Для асинхронных операций используйте обычные
      `async def` функции.

5. **Тестирование кода с lambda**:
    - При тестировании функций, принимающих lambda как аргументы, убедитесь, что тестируются различные edge-cases для
      этих lambda.
    - Используйте property-based тестирование (Hypothesis) для проверки корректности работы с пользовательскими lambda.

6. **Мокирование lambda**:
    - Lambda сложно мокировать напрямую. Вместо этого мокируйте функцию, которая использует lambda, или заменяйте lambda
      на callable-объект в тестах.

7. **Производительность в тестах**:
    - Избегайте создания lambda в интенсивных циклах в тестах производительности — выносите их определение наружу.
    - При нагрузочном тестировании API с кастомизацией через lambda убедитесь, что создание lambda не становится
      bottleneck.

8. **Документирование намерений**:
    - Если lambda выполняет нетривиальную логику, добавьте комментарий, поясняющий её назначение.
    - В тестовом коде предпочтительнее явная функция с говорящим именем, если логика не очевидна.

9. **Использование с functools**:
    - Модуль `functools` предоставляет функции, которые хорошо сочетаются с lambda: `partial()`, `reduce()`.
    - Однако в Python 3.9+ `reduce()` менее читаем, чем явные циклы, особенно в тестах.

10. **Альтернативы в современных Python**:
    - Во многих случаях генераторные выражения или списковые включения более читаемы, чем `map()`/`filter()` с lambda.
    - Для сортировки с ключом может быть лучше вынести логику в отдельную функцию, если она используется многократно.

11. **Безопасность**:
    - Избегайте использования lambda с `eval()` или `exec()` в тестовом коде — это создаёт риски безопасности и
      затрудняет статический анализ.

================================================================================================================================

### Списковые выражения (List Comprehension)

#### **Определение**

Списковые выражения (List Comprehension) — это синтаксическая конструкция Python, предоставляющая компактный и
выразительный способ создания списков. Они позволяют генерировать новый список путём применения выражения к каждому
элементу итерируемого объекта с возможностью фильтрации элементов через условие. Списковые выражения являются
декларативной конструкцией, описывающей преобразование данных, и обычно заменяют традиционные циклы `for` с `append()`
при создании списков.

#### **Внутренняя реализация (под капотом)**

1. **Компиляция в байт-код**:
    - Списковые выражения компилируются в специализированный байт-код с использованием инструкции `LIST_APPEND` (в более
      старых версиях) или `BUILD_LIST` с последующим заполнением.
    - В Python 3.9+ компилятор преобразует списковое выражение в скрытую временную функцию, которая выполняется в
      отдельном пространстве имён для избежания утечек переменных.

2. **Создание и заполнение списка**:
    - Интерпретатор предварительно выделяет память для списка на основе оценки размера (если возможно) или использует
      динамическое расширение.
    - Для каждого элемента итерируемого объекта:
        1. Вычисляется условие (если оно есть)
        2. Если условие истинно, вычисляется выражение и результат добавляется в список
    - Внутренний цикл выполняется на уровне C, что обеспечивает значительное ускорение по сравнению с Python-циклом.

3. **Оптимизации памяти и производительности**:
    - CPython использует предварительное выделение памяти, когда может определить размер результата (например, при
      отсутствии фильтрации).
    - Для больших списков происходит поэтапное увеличение размера (realloc) с коэффициентом роста ~1.125.

4. **Вложенные списковые выражения**:
    - Конструкции вида `[expr for x in iter1 for y in iter2]` компилируются во вложенные циклы, где самый правый цикл
      становится самым внутренним.
    - Порядок выполнения соответствует вложенным циклам `for`, но с сохранением преимуществ выполнения на уровне C.

5. **Сравнение с генераторными выражениями**:
    - Списковые выражения создают весь список сразу в памяти, тогда как генераторные выражения (
      `(expr for x in iterable)`) создают генератор, который лениво вычисляет значения.
    - Байт-код генераторных выражений использует инструкцию `YIELD_VALUE` вместо `LIST_APPEND`.

6. **Изоляция области видимости**:
    - Начиная с Python 3, переменные, используемые в списковых выражениях (переменная цикла), не утекают во внешнюю
      область видимости. Это достигается выполнением выражения в отдельном контексте.

#### **Особенности**

1. **Производительность**:
    - Списковые выражения обычно выполняются быстрее эквивалентных циклов `for` с `append()`, так как основной цикл
      выполняется на уровне C в интерпретаторе.
    - Однако для очень простых операций разница может быть незначительной, а в некоторых случаях (сложные условия) цикл
      `for` может быть более читаемым.

2. **Потребление памяти**:
    - Весь результирующий список создаётся сразу в памяти, что может быть проблематично при обработке больших данных. В
      таких случаях лучше использовать генераторы.

3. **Читаемость**:
    - Для простых преобразований списковые выражения более компактны и выразительны.
    - Для сложных многоступенчатых преобразований с несколькими условиями они могут стать трудночитаемыми.

4. **Побочные эффекты**:
    - Использование функций с побочными эффектами в списковых выражениях возможно, но не рекомендуется, так как может
      затруднить понимание кода.

5. **Ограничения синтаксиса**:
    - Списковые выражения не могут содержать операторы `try/except`, `if-elif-else` (только простое `if` в конце или
      тернарный оператор в выражении), `break`, `continue`.
    - Не поддерживают присваивание внутри выражения (кроме переменной итерации).

6. **Расширяемость до других типов**:
    - Аналогичный синтаксис используется для генераторных выражений, множеств (`{x for x in iterable}`) и словарей (
      `{k: v for k, v in iterable}`).

#### **Лучшие практики для AQA**

1. **Создание тестовых данных**:
    - Используйте списковые выражения для генерации тестовых данных: `test_ids = [f"test_{i}" for i in range(100)]`.
    - Они особенно полезны при параметризации тестов в pytest, где можно динамически создавать наборы данных.

2. **Фильтрация результатов тестов**:
    - При анализе результатов выполнения тестов можно использовать списковые выражения для фильтрации:
      `failed_tests = [test for test in results if test.status == "FAILED"]`.

3. **Преобразование данных в тестах**:
    - Используйте для быстрого преобразования форматов данных: `int_values = [int(x) for x in string_values]`.
    - При работе с API-ответами: `user_names = [user["name"] for user in response.json()["users"]]`.

4. **Избегание сложных выражений**:
    - Если списковое выражение становится длинным или содержит вложенные циклы с условиями, вынесите логику в отдельную
      функцию или используйте обычный цикл для сохранения читаемости.
    - Помните, что тестовый код должен быть в первую очередь понятным, а не кратким.

5. **Обработка исключений**:
    - Для обработки возможных исключений при преобразовании данных используйте цикл `for` с `try/except` или создайте
      вспомогательную функцию-обёртку.

6. **Память в нагрузочных тестах**:
    - При написании нагрузочных тестов, которые могут генерировать большие объёмы данных, избегайте списковых выражений
      в пользу генераторов для экономии памяти.

7. **Тестирование кода со списковыми выражениями**:
    - При тестировании функций, использующих списковые выражения, убедитесь, что покрыты все ветвления условий.
    - Проверяйте edge cases: пустые итерируемые объекты, условия, которые никогда не выполняются, очень большие
      коллекции.

8. **Производительность в тестах**:
    - Не используйте списковые выражения для операций, которые можно выполнить более эффективно (например, использование
      `map()` с функцией на C или встроенных методов списков).
    - В критичных к производительности тестах замеряйте время выполнения разных подходов.

9. **Совместимость с типами**:
    - В Python 3.9+ используйте аннотации типов для ясности, даже если списковое выражение находится внутри функции с
      аннотацией возвращаемого типа: `-> List[str]`.

10. **Альтернативы для словарей и множеств**:
    - Используйте словарные и множественные выражения для создания тестовых фикстур сложной структуры.

11. **Отладка**:
    - При отладке сложных списковых выражений можно временно заменить их на цикл для пошагового выполнения или добавить
      отладочный вывод через вспомогательную функцию.

12. **Статический анализ**:
    - Настройте линтеры для проверки сложности списковых выражений (например, правило `C416` в `pylint` или
      `flake8-comprehensions`).

================================================================================================================================

### copy() и deepcopy()

#### **Определение**

`copy()` (поверхностное копирование) и глубокое копирование — это два подхода к созданию копий объектов в Python.
Поверхностное копирование создаёт новый контейнерный объект, но наполняет его ссылками на те же вложенные объекты, что и
оригинал. Глубокое копирование рекурсивно создаёт новые копии всех объектов в иерархии, полностью отделяя копию от
оригинала. Эти механизмы реализованы в модуле `copy` и критически важны для работы с изменяемыми объектами, содержащими
другие изменяемые объекты.

#### **Внутренняя реализация (под капотом)**

1. **Поверхностное копирование (`copy.copy()`)**:
    - Использует метод `__copy__()` объекта, если он определён. Для встроенных коллекций (list, dict, set) этот метод
      реализован на C.
    - Для списков и словарей создаётся новый объект того же типа, но элементы остаются теми же объектами (копируются
      только ссылки).
    - В CPython для списков `list.copy()` или `[:]` вызывают функцию `list_copy()`, которая копирует указатели на
      элементы в новый массив.

2. **Глубокое копирование (`copy.deepcopy()`)**:
    - Использует метод `__deepcopy__(memo)`, если он определён. Иначе применяет рекурсивный алгоритм.
    - Модуль `copy` поддерживает внутренний словарь `memo` (идентификатор объекта → копия) для:
        - Избежания бесконечной рекурсии при циклических ссылках
        - Оптимизации — не копирует один и тот же объект несколько раз
    - Алгоритм обходит все атрибуты и элементы объекта рекурсивно:
        - Для неизменяемых типов (int, str, tuple неизменяемых элементов) возвращает тот же объект
        - Для изменяемых создаёт новые экземпляры

3. **Обработка различных типов**:
    - **Неизменяемые типы** (числа, строки, frozenset, tuple неизменяемых элементов): никогда не копируются,
      возвращается тот же объект.
    - **Кортежи с изменяемыми элементами**: `deepcopy()` создаёт новый кортеж, но с копиями элементов.
    - **Пользовательские классы**: по умолчанию копируются через `__dict__` и `__slots__`.

4. **Циклические ссылки**:
    - `deepcopy()` корректно обрабатывает циклические ссылки благодаря словарю `memo`.
    - При обнаружении объекта, который уже копировался, возвращается существующая копия.

5. **Производительность и память**:
    - `deepcopy()` использует рекурсию и может быть экспоненциально медленнее для сложных структур.
    - Потребление памяти `deepcopy()` пропорционально размеру всей иерархии объектов.

6. **Специальные случаи**:
    - Модули, классы, функции, трассировки стека, фреймы выполнения не копируются — возвращаются как есть.
    - Для `list`, `dict`, `set` есть оптимизированные пути в коде CPython.

#### **Особенности**

1. **Разделение состояния**:
    - После поверхностного копирования изменение вложенных объектов затрагивает и оригинал, и копию.
    - После глубокого копирования объекты полностью независимы.

2. **Глубина рекурсии**:
    - `deepcopy()` может вызывать `RecursionError` для очень глубоких структур (лимит рекурсии Python).
    - Можно настроить максимальную глубину через кастомную функцию.

3. **Производительность**:
    - `copy()` работает за O(N) по количеству элементов верхнего уровня.
    - `deepcopy()` работает минимум за O(N+M), где N — элементы верхнего уровня, M — общее число объектов в иерархии.

4. **Поведение с неизменяемыми типами**:
    - `deepcopy()` "ленит" для неизменяемых объектов — это безопасно и экономит память.
    - Но кортеж с изменяемыми элементами требует особого внимания.

5. **Пользовательские классы**:
    - По умолчанию `copy()` вызывает конструктор `cls.__new__(cls)` и копирует `__dict__`.
    - `deepcopy()` рекурсивно копирует все атрибуты.

6. **Слоты**:
    - Классы с `__slots__` корректно обрабатываются обеими функциями.

#### **Лучшие практики для AQA**

1. **Тестовые данные и изоляция**:
    - Всегда используйте глубокое копирование для тестовых данных, которые будут модифицироваться в тестах. Это
      гарантирует изоляцию тестов.
    - Для фикстур pytest, возвращающих изменяемые объекты, используйте `copy.deepcopy()` или создавайте новые объекты
      для каждого теста.

2. **Оптимизация производительности тестов**:
    - Если тест не модифицирует вложенные объекты, используйте `copy()` для экономии времени и памяти.
    - Для больших структур данных в интеграционных тестах рассмотрите альтернативы: генерацию данных на лету или
      использование неизменяемых структур.

3. **Тестирование копирования**:
    - При тестировании функций, которые работают с изменяемыми структурами, проверяйте, не возникает ли нежелательного
      мутирования оригинальных данных.
    - Используйте `assert obj is not original` для проверки поверхностного копирования и
      `assert obj[0] is not original[0]` для глубокого.

4. **Мокирование и патчинг**:
    - При использовании `unittest.mock` для мокирования объектов, которые могут копироваться, учитывайте, что
      mock-объекты могут вести себя нестандартно при копировании.
    - Тестируйте сценарии, где мокируемые объекты передаются в функции, которые их копируют.

5. **Сериализация и десериализация**:
    - В тестах API часто требуется сравнение объектов после сериализации/десериализации. `deepcopy()` может помочь
      создать эталонные копии для сравнения.
    - Для JSON-структур иногда достаточно поверхностного копирования, если все элементы неизменяемы.

6. **Параметризация тестов**:
    - При передаче изменяемых объектов в параметризованные тесты (`@pytest.mark.parametrize`) явно копируйте данные для
      каждого случая, иначе изменения в одном тесте повлияют на другие.

7. **Тестирование stateful-объектов**:
    - При тестировании объектов с состоянием (например, кэшей, коннектов) используйте копирование для проверки изоляции
      операций.
    - Убедитесь, что глубокое копирование корректно работает с пользовательскими классами в проекте.

8. **Обработка исключительных ситуаций**:
    - Тестируйте `deepcopy()` на структурах с циклическими ссылками и рекурсивными структурами.
    - Проверяйте поведение при копировании объектов, содержащих несериализуемые атрибуты (файлы, сокеты).

9. **Интеграция с ORM и базами данных**:
    - Объекты SQLAlchemy и другие ORM-модели могут иметь сложные внутренние связи. Глубокое копирование может быть
      некорректным — используйте специальные методы ORM для копирования.

10. **Профилирование тестов**:
    - Если тесты с `deepcopy()` работают медленно, рассмотрите:
        - Использование `copy()` с последующим ручным копированием только изменяемых частей
        - Переход на immutable структуры данных (dataclasses с `frozen=True`, namedtuples)
        - Ленивую генерацию тестовых данных

11. **Кастомные реализации копирования**:
    - Для сложных объектов проекта реализуйте методы `__copy__()` и `__deepcopy__()` для контроля над процессом.
    - Тестируйте эти методы на корректность и производительность.

================================================================================================================================

### Асинхронность (Async/Await)

#### **Определение**

Асинхронность в Python — это парадигма программирования, позволяющая выполнять ввод-вывод (I/O) и другие операции, не
блокируя основной поток выполнения, через кооперативную многозадачность. Реализуется с помощью ключевых слов `async` и
`await`, цикла событий (event loop) и асинхронных функций (coroutines). Асинхронный код особенно эффективен для
I/O-интенсивных приложений (сетевые запросы, работа с базами данных, файловые операции), где позволяет обрабатывать
тысячи одновременных соединений без создания большого количества потоков.

#### **Внутренняя реализация (под капотом)**

1. **Корутины и объекты-ожидания (awaitables)**:
    - Функция, объявленная с `async def`, возвращает объект-корутину (coroutine object), который является наследником
      `types.CoroutineType`.
    - Корутина не выполняется сразу при вызове — она требует явного запуска через цикл событий или `await`.
    - Все awaitable-объекты реализуют метод `__await__()`.

2. **Цикл событий (event loop)**:
    - Реализован в модуле `asyncio` через класс `BaseEventLoop` (конкретные реализации: `SelectorEventLoop`,
      `ProactorEventLoop`).
    - Цикл событий управляет выполнением корутин, обрабатывает системные события (I/O, таймеры) и планирует задачи (
      Tasks).
    - В основе лежит системный вызов `select()` (или `epoll`, `kqueue`) для мониторинга файловых дескрипторов.

3. **Задачи (Tasks) и планировщик**:
    - `asyncio.create_task()` оборачивает корутину в объект `Task`, который является подклассом `Future`.
    - `Future` представляет отложенное вычисление и хранит состояние (`pending`, `cancelled`, `finished`).
    - Когда корутина `await`-ит другую корутину или `Future`, текущая задача приостанавливается, и цикл событий
      переключается на другую задачу.

4. **Генераторы под капотом**:
    - Корутины исторически построены на генераторах. В CPython корутина использует фрейм с флагом `COROUTINE`.
    - Инструкция `await` компилируется в `GET_AWAITABLE` и вызов `__await__()`.

5. **Транспорт и протоколы**:
    - Низкоуровневый API `asyncio` предоставляет абстракции транспорта (канал связи) и протокола (обработчик данных),
      реализованные на C для производительности.

6. **Асинхронные контекстные менеджеры и итераторы**:
    - `async with` вызывает `__aenter__()` и `__aexit__()`, которые должны быть корутинами.
    - `async for` использует `__aiter__()` и `__anext__()`.

7. **GIL и асинхронность**:
    - Поскольку асинхронные задачи выполняются в одном потоке, GIL не является проблемой для I/O-операций.
    - Для CPU-интенсивных операций в асинхронном коде используется `run_in_executor()` с пулом потоков/процессов.

#### **Особенности**

1. **Кооперативная многозадачность**:
    - Задачи должны явно "уступать" контроль через `await`. Если задача выполняет CPU-интенсивную операцию без `await`,
      она блокирует весь цикл событий.
    - Это требует дисциплины при написании кода и понимания, какие операции являются блокирующими.

2. **Отмена задач и таймауты**:
    - Задачи могут быть отменены через `task.cancel()`, что вызывает `CancelledError` внутри корутины.
    - `asyncio.wait_for()` позволяет устанавливать таймауты на выполнение корутин.

3. **Синхронизация**:
    - Предоставляются примитивы синхронизации: `Lock`, `Semaphore`, `Event`, `Condition` — аналоги `threading`, но для
      асинхронного кода.

4. **Обработка исключений**:
    - Исключения в асинхронных задачах не пробрасываются автоматически — их нужно обрабатывать через `task.exception()`
      или `await` с `try/except`.

5. **Производительность**:
    - Асинхронный код может обрабатывать десятки тысяч одновременных соединений в одном потоке, экономя память на
      создание потоков и избегая накладных расходов на переключение контекста.

6. **Совместимость с синхронным кодом**:
    - Запуск синхронного блокирующего кода в асинхронном приложении разрушает его преимущества — требуется использовать
      `run_in_executor()`.

#### **Лучшие практики для AQA**

1. **Тестирование асинхронного кода**:
    - Используйте `pytest-asyncio` или `pytest-aiohttp` для написания асинхронных тестов.
    - Тестовые функции должны быть объявлены с `async def`, а фикстуры могут быть асинхронными.
    - Для мокирования асинхронных функций используйте `unittest.mock.AsyncMock` или `asynctest`.

2. **Нагрузочное тестирование асинхронных сервисов**:
    - Для тестирования асинхронных API используйте асинхронные клиенты (aiohttp, httpx) с высокой конкурентностью.
    - Создавайте тысячи одновременных запросов из одного потока, измеряя latency и throughput.

3. **Изоляция тестов**:
    - Каждый тест должен запускаться в свежем цикле событий или использовать изолированный event loop per test.
    - Убедитесь, что задачи корректно завершаются после каждого теста, чтобы избежать утечек.

4. **Тестирование таймаутов и отмены**:
    - Создавайте тесты для проверки поведения системы при отмене операций и таймаутах.
    - Используйте `asyncio.wait_for` с маленьким таймаутом для проверки быстрых ответов.

5. **Мокирование внешних вызовов**:
    - При тестировании асинхронных функций, которые делают сетевые запросы, мокируйте их с помощью `AsyncMock`, чтобы
      тесты были быстрыми и стабильными.
    - Настраивайте моки на выброс исключений (например, `ConnectionError`) для проверки обработки ошибок.

6. **Интеграционные тесты с реальными сервисами**:
    - Для интеграционных тестов используйте тестовые контейнеры (Docker) с асинхронными клиентами.
    - Учитывайте, что асинхронные клиенты могут создавать большое количество одновременных подключений — настраивайте
      лимиты соответствующим образом.

7. **Отладка асинхронного кода**:
    - Используйте `asyncio.debug = True` для отслеживания незавершённых задач.
    - Включайте логирование с контекстом задачи (task ID) для трассировки выполнения.

8. **Тестирование конкурентных сценариев**:
    - Создавайте тесты на состояние гонки (race conditions) в асинхронном коде, используя `asyncio.sleep(0)` для
      принудительного переключения контекста.
    - Проверяйте корректность работы асинхронных примитивов синхронизации (Lock, Semaphore).

9. **Производительность тестов**:
    - Асинхронные тесты могут выполняться быстрее синхронных для I/O-интенсивных операций благодаря параллельному
      выполнению.
    - Измеряйте время выполнения отдельных асинхронных операций с помощью `asyncio.wait_for` и сравнивайте с ожидаемыми
      таймаутами.

10. **Обработка исключений в тестах**:
    - Используйте `pytest.raises()` с асинхронными исключениями.
    - Проверяйте, что исключения правильно пробрасываются через `await`.

11. **Использование `async` фикстур в pytest**:
    - Фикстуры могут быть асинхронными и использовать `yield` для setup/teardown.
    - Убедитесь, что фикстуры корректно очищают ресурсы (например, закрывают соединения с БД).

12. **Тестирование WebSocket и long-polling соединений**:
    - Асинхронные тесты хорошо подходят для тестирования реального времени.
    - Используйте `asyncio.wait()` с таймаутами для ожидания сообщений.

13. **Совместимость с синхронными тестами**:
    - В проектах со смешанным кодом (синхронным и асинхронным) используйте `asyncio.run()` для запуска асинхронных
      тестов из синхронного контекста.
    - Избегайте смешивания синхронных и асинхронных вызовов без необходимости.

================================================================================================================================

### Dataclass

#### **Определение**

`@dataclass` — это декоратор из модуля `dataclasses` (появился в Python 3.7, улучшен в 3.9+), который автоматически
генерирует специальные методы для классов, содержащих в основном данные (data-oriented classes). Dataclass преобразует
аннотации полей класса в код, генерируя методы `__init__()`, `__repr__()`, `__eq__()`, `__hash__()` и другие, что
устраняет шаблонный код и делает классы более читабельными и удобными для работы с данными.

#### **Внутренняя реализация (под капотом)**

1. **Процесс декорирования**:
    - При применении `@dataclass` происходит метапрограммирование: декоратор анализирует аннотации и переменные класса,
      создавая скрытые поля (`Field` объекты).
    - На этапе выполнения генерируется новый класс с добавленными методами.

2. **Генерация методов**:
    - `__init__()`: создаётся на основе аннотаций полей; каждое поле становится параметром метода и присваивается
      атрибуту экземпляра.
    - `__repr__()`: форматирует строку как `ClassName(field1=value1, field2=value2)`.
    - `__eq__()`: сравнивает все поля (кроме исключённых) через сравнение кортежей значений.
    - `__hash__()`: генерируется только если `frozen=True` и `eq=True`, вычисляет хэш на основе кортежа значений полей.

3. **Объекты Field**:
    - Каждое поле становится экземпляром `dataclasses.Field`, хранящим метаданные: `default`, `default_factory`, `init`,
      `repr`, `compare`, `hash`, `metadata`.
    - Эти объекты хранятся в скрытом атрибуте `__dataclass_fields__`.

4. **Обработка значений по умолчанию**:
    - Значения по умолчанию обрабатываются особым образом: для изменяемых объектов (списки, словари) используется
      `default_factory` (функция-фабрика) во избежание разделения состояния между экземплярами.
    - В Python 3.11+ добавлена поддержка `KW_ONLY` для разделения позиционных и ключевых аргументов.

5. **Наследование и порядок разрешения полей**:
    - Поля наследуются от родительских классов, причём порядок определяется MRO (Method Resolution Order).
    - Поля с значениями по умолчанию должны идти после полей без значений по умолчанию — это проверяется на этапе
      создания класса.

6. **Слоты (__slots__)**:
    - При использовании `@dataclass(slots=True)` (Python 3.10+) генерируется класс со `__slots__`, что улучшает
      производительность и уменьшает потребление памяти.
    - Слоты создаются динамически на основе полей dataclass.

7. **Пост-инициализация**:
    - Метод `__post_init__()` вызывается после `__init__()` и позволяет выполнить дополнительную валидацию или
      вычисление производных полей.

#### **Особенности**

1. **Автоматизация и читаемость**:
    - Устраняет ~90% шаблонного кода в data-классах.
    - Аннотации типов становятся обязательными (кроме использования `field()` без типа).

2. **Неизменяемость (frozen)**:
    - При `frozen=True` экземпляры становятся неизменяемыми (как namedtuple), что позволяет использовать их в качестве
      ключей словаря.
    - Попытка изменения поля вызывает `FrozenInstanceError`.

3. **Сравнение и сортировка**:
    - При `order=True` генерируются методы `__lt__()`, `__le__()`, `__gt__()`, `__ge__()` для сравнения объектов как
      кортежей полей.
    - Сравнение работает рекурсивно для вложенных dataclass.

4. **Наследование**:
    - Dataclass корректно работает с наследованием, но требует аккуратного использования значений по умолчанию.
    - Нельзя смешивать в наследнике поля с и без значений по умолчанию, если в родителе есть поля с значениями по
      умолчанию.

5. **Производительность**:
    - Сгенерированные методы написаны на Python, но оптимизированы и обычно быстрее ручной реализации.
    - Использование `slots=True` ускоряет доступ к атрибутам и уменьшает память.

6. **Интеграция с typing**:
    - Полностью поддерживает аннотации типов, включая `Generic`, `Optional`, `Union`.
    - Можно использовать `ClassVar` для исключения полей из dataclass.

#### **Лучшие практики для AQA**

1. **Тестовые данные и фикстуры**:
    - Используйте dataclass для представления тестовых данных (параметры тестов, ожидаемые результаты, конфигурации).
    - Это улучшает читаемость и обеспечивает типобезопасность: `@dataclass class TestCase: input: str; expected: int`.

2. **Фикстуры pytest с dataclass**:
    - Создавайте фикстуры, возвращающие экземпляры dataclass — они неизменяемы по желанию и легко копируются.
    - Используйте `dataclasses.replace()` для создания модифицированных копий в тестах.

3. **Сравнение объектов в тестах**:
    - Автоматически сгенерированный `__eq__()` упрощает проверки: `assert actual == expected`.
    - Для частичного сравнения используйте `dataclasses.asdict()` и сравнение словарей.

4. **Валидация данных**:
    - Используйте `__post_init__()` для валидации полей и вычисления производных значений.
    - В тестах проверяйте, что валидация работает корректно (позитивные и негативные сценарии).

5. **Тестирование dataclass в проекте**:
    - Убедитесь, что dataclass проекта корректно сериализуются/десериализуются (JSON, YAML).
    - Проверяйте edge cases: наследование, значения по умолчанию с `default_factory`, frozen-классы.

6. **Использование в параметризованных тестах**:
    - Dataclass идеально подходят для `@pytest.mark.parametrize`: создавайте список экземпляров dataclass как аргументы.
    - Имена полей делают тестовые случаи самодокументируемыми.

7. **Производительность тестов**:
    - При создании тысяч экземпляров в нагрузочных тестах используйте `slots=True` для экономии памяти.
    - Замеряйте время инициализации и сравнения больших наборов данных.

8. **Мокирование dataclass**:
    - При мокировании объектов, которые являются dataclass, учитывайте, что они могут иметь нестандартные методы.
    - Используйте `unittest.mock.patch.object` для подмены отдельных методов.

9. **Сериализация в отчетах**:
    - Используйте `dataclasses.asdict()` для преобразования объектов в словари при генерации JSON-отчетов.
    - `__repr__()` dataclass даёт понятное представление в логах тестов.

10. **Неизменяемость для безопасности тестов**:
    - Используйте `frozen=True` для тестовых конфигураций, чтобы гарантировать, что они не изменятся случайно во время
      выполнения теста.

11. **Интеграция с ORM и API**:
    - Dataclass могут служить DTO (Data Transfer Object) для данных API. Тестируйте преобразование между dataclass и
      моделями БД/JSON.

12. **Тестирование наследования dataclass**:
    - Создавайте тесты для проверки корректности наследования полей и методов в иерархии dataclass.
    - Проверяйте, что порядок полей соответствует ожиданиям при использовании `dataclasses.fields()`.

13. **Использование metadata**:
    - Поле `metadata` в `field()` позволяет хранить дополнительную информацию (валидаторы, описание) — используйте её
      для расширенных сценариев тестирования.

================================================================================================================================

### Enum

#### **Определение**

Enum (перечисление) — это класс в Python, который предоставляет способ создания именованных константных значений,
объединенных в логическую группу. Перечисления делают код более читаемым, поддерживаемым и типобезопасным, заменяя "
магические числа" и строки на понятные имена. Классы перечислений наследуются от базового класса `Enum` из модуля `enum`
и содержат набор атрибутов-членов, каждый из которых является уникальным экземпляром класса перечисления.

#### **Внутренняя реализация (под капотом)**

1. **Метакласс `EnumMeta`**:
    - Все Enum-классы создаются метаклассом `EnumMeta`, который контролирует процесс создания членов перечисления.
    - Метакласс перехватывает определение атрибутов класса и преобразует их в экземпляры Enum-класса.

2. **Создание членов перечисления**:
    - Каждый член перечисления — это экземпляр Enum-класса с двумя основными атрибутами: `name` (имя атрибута) и
      `value` (присвоенное значение).
    - Члены создаются на этапе создания класса (при его загрузке), а не при инстанциировании.

3. **Синглтон-природа членов**:
    - Каждый член перечисления является синглтоном. При попытке создать новый экземпляр с тем же значением возвращается
      существующий член.
    - Это достигается через кэш в метаклассе: `_member_map_` и `_value2member_map_`.

4. **Структура данных в памяти**:
    - Enum-класс хранит:
        - `_member_names_`: список имен членов
        - `_member_map_`: словарь {имя: член}
        - `_value2member_map_`: словарь {значение: член}
        - `_member_type_`: тип значений членов

5. **IntEnum и Flag**:
    - `IntEnum` наследует и `int`, и `Enum`, что позволяет членам вести себя как целые числа.
    - `Flag` и `IntFlag` используют побитовые операции и хранят значение как битовую маску.

6. **Автоматические значения (`auto()`)**:
    - Функция `auto()` использует генератор `_generate_next_value_`, который по умолчанию возвращает последовательные
      целые числа.
    - Можно переопределить `_generate_next_value_` для кастомной логики генерации.

7. **Пространство имён и дескрипторы**:
    - Члены перечисления добавляются в пространство имён класса как дескрипторы, предотвращая случайное переопределение.

8. **Сравнение и хэширование**:
    - Члены сравниваются по идентичности (`is`), а не по значению (кроме `IntEnum`).
    - Все члены хэшируемы и могут использоваться как ключи словаря.

#### **Особенности**

1. **Иммутабельность**:
    - Члены перечисления неизменяемы. Нельзя изменить их `name` или `value` после создания.
    - Нельзя добавлять или удалять члены динамически после создания класса.

2. **Итерация и доступ**:
    - По Enum можно итерироваться, получая все члены в порядке определения.
    - Доступ к членам возможен по имени (`EnumClass.MEMBER`), по значению (`EnumClass(value)`) или по имени строки (
      `EnumClass['NAME']`).

3. **Типизация**:
    - `Enum` поддерживает аннотации типов. Члены имеют тип самого Enum-класса, а не их значений.
    - Это позволяет статическим анализаторам проверять корректность использования.

4. **Наследование**:
    - Обычные Enum-классы не могут наследоваться, кроме случаев создания "пустого" Enum для расширения.
    - `IntEnum`, `Flag` и `IntFlag` имеют свои правила наследования.

5. **Сериализация**:
    - При сериализации в JSON члены Enum по умолчанию не сериализуемы — нужно явно указывать `.value` или `.name`.
    - Многие фреймворки (например, pydantic) имеют встроенную поддержку сериализации Enum.

6. **Производительность**:
    - Доступ к членам через `.value` быстрее, чем через `EnumClass(value)`.
    - Enum добавляет минимальные накладные расходы по сравнению с использованием простых констант.

#### **Лучшие практики для AQA**

1. **Тестовые статусы и коды**:
    - Используйте Enum для представления статусов тестов, кодов ответов API, типов ошибок.
    - Пример: `class TestStatus(Enum): PASSED = "passed"; FAILED = "failed"; SKIPPED = "skipped"`

2. **Параметризация тестов**:
    - При параметризации тестов с помощью `@pytest.mark.parametrize` используйте Enum для явного указания допустимых
      значений.
    - Это делает тесты самодокументируемыми и предотвращает опечатки.

3. **Конфигурации тестовых окружений**:
    - Описывайте окружения через Enum: `class Environment(Enum): DEV = "dev"; STAGING = "staging"; PROD = "prod"`.
    - Упрощает валидацию конфигурационных файлов.

4. **Тестирование Enum в коде приложения**:
    - При тестировании функций, принимающих Enum-параметры, проверяйте обработку как валидных, так и невалидных
      значений.
    - Убедитесь, что сравнение членов Enum происходит через `is`, а не через `==` (кроме `IntEnum`).

5. **Сериализация в тестах API**:
    - При тестировании API, которое использует Enum, проверяйте корректность сериализации/десериализации.
    - Используйте `.value` для отправки данных в API и сравнения с ожидаемым результатом.

6. **Фикстуры с Enum**:
    - Создавайте фикстуры, возвращающие Enum-значения, для обеспечения типобезопасности в тестах.
    - Пример: `@pytest.fixture(params=list(TestScenario))`

7. **Валидация тестовых данных**:
    - Используйте Enum для валидации входных данных в тестах. Например, проверяйте, что статус заказа может быть только
      одним из предопределённых значений.

8. **Логирование и отчеты**:
    - Используйте Enum в логах тестов и отчетах для консистентного представления состояний.
    - Имя члена (`member.name`) обычно читаемее, чем его значение.

9. **Тестирование граничных случаев**:
    - Тестируйте поведение Enum при:
        - Несуществующем значении: `EnumClass(999)` должно вызывать `ValueError`
        - Несуществующем имени: `EnumClass['INVALID']` вызывает `KeyError`
        - Сериализации в строку: `str(member)` и `repr(member)`

10. **IntFlag для комбинированных состояний**:
    - Используйте `IntFlag` для тестирования функций, работающих с битовыми масками (права доступа, флаги настроек).

11. **Автоматические значения в тестах**:
    - В тестах, где конкретные значения не важны, используйте `auto()` для генерации уникальных значений.
    - Переопределяйте `_generate_next_value_` для специфичных нужд (например, строковые идентификаторы).

12. **Сравнение производительности**:
    - В нагрузочных тестах сравнивайте производительность использования Enum vs. констант vs. строк.
    - Обычно разница минимальна, но для очень горячих путей может быть значима.

13. **Интеграция с базами данных**:
    - При тестировании ORM, хранящей Enum в БД, проверяйте корректность маппинга между значениями БД и членами Enum.

14. **Миграции и обратная совместимость**:
    - Если Enum в API изменяется (добавляются/удаляются члены), создавайте тесты на обратную совместимость.

================================================================================================================================

### Garbage Collector (сборщик мусора)

#### **Определение**

Garbage Collector (GC, сборщик мусора) — это механизм автоматического управления памятью в Python, который отслеживает и
освобождает объекты, ставшие недостижимыми (мусор). В Python используется комбинированный подход: **подсчёт ссылок (
reference counting)** для немедленного освобождения памяти и **циклический сборщик мусора (cyclic GC)** для обнаружения
и удаления циклических ссылок. GC работает прозрачно для программиста, но его поведение можно настраивать и
контролировать.

#### **Внутренняя реализация (под капотом)**

1. **Подсчёт ссылок (Reference Counting)**:
    - Каждый объект в CPython содержит счётчик ссылок `ob_refcnt` в заголовке `PyObject`.
    - При создании ссылки (`a = b`) счётчик увеличивается, при удалении — уменьшается.
    - Когда `ob_refcnt` достигает 0, память объекта немедленно освобождается через вызов деструктора `__del__()` и
      освобождение памяти.
    - Преимущество: предсказуемое и немедленное освобождение ресурсов.

2. **Циклический сборщик мусора**:
    - Реализован в модуле `gc` как дополнительный механизм для обнаружения циклов ссылок (когда объекты ссылаются друг
      на друга, но недостижимы извне).
    - Использует алгоритм **поколений (generational GC)** с тремя поколениями (0, 1, 2). Новые объекты попадают в
      поколение 0.
    - Каждое поколение имеет пороговое значение (threshold), при превышении которого запускается сборка.

3. **Алгоритм обнаружения циклов**:
    - Использует алгоритм **трехцветной маркировки (tri-color marking)**:
        - **Белые**: непосещённые объекты (потенциальный мусор)
        - **Серые**: посещённые, но не обработанные
        - **Чёрные**: обработанные, достижимые объекты
    - Начинает с корневых объектов (global, stack, registers) и помечает все достижимые объекты.
    - Объекты, оставшиеся белыми, считаются мусором и удаляются.

4. **Структуры данных GC**:
    - `_PyGC_Head`: дополнительный заголовок для объектов, отслеживаемых GC (содержит флаги, указатель на следующий
      объект в списке поколения).
    - Три двусвязных списка (по одному на каждое поколение) для отслеживания объектов.
    - Флаги состояния: `GC_UNTRACKED`, `GC_REACHABLE`, `GC_TENTATIVELY_UNREACHABLE`.

5. **Обработка финализаторов (`__del__`)**:
    - Объекты с методом `__del__` требуют особой обработки, так как финализатор может создать новые ссылки.
    - Такие объекты помещаются в список `gc.garbage` при обнаружении в цикле, чтобы избежать неопределённого поведения.

6. **Модуль `weakref` и слабые ссылки**:
    - Слабые ссылки не увеличивают счётчик ссылок и не препятствуют сборке мусора.
    - Реализованы через отдельную структуру `PyWeakReference`.

7. **Оптимизации**:
    - **Молодое поколение (generation 0)**: проверяется чаще, так как большинство объектов умирают молодыми.
    - **Пропуск неизменяемых типов**: кортежи, строки, числа обычно не отслеживаются GC, если не содержат ссылок на
      отслеживаемые объекты.

#### **Особенности**

1. **Немедленное vs отложенное освобождение**:
    - Подсчёт ссылок освобождает память сразу, циклический GC — по расписанию.
    - Это может вызывать задержки (паузы) при выполнении программы.

2. **Настраиваемость**:
    - Можно отключать GC (`gc.disable()`), настраивать пороги поколений, принудительно запускать сборку.
    - Для real-time систем можно использовать отключение GC для предсказуемости.

3. **Производительность**:
    - Подсчёт ссылок добавляет накладные расходы на каждую операцию с ссылками.
    - Циклический GC потребляет CPU и память для отслеживания объектов.

4. **Циклические ссылки с финализаторами**:
    - Объекты с `__del__`, образующие циклы, никогда не удаляются автоматически — остаются в `gc.garbage`.
    - Требуется ручная обработка таких случаев.

5. **Разница с другими языками**:
    - В отличие от JVM/CLR, Python не использует компактирующий GC — память фрагментируется.
    - Нет перемещения объектов в памяти.

6. **Интерпретатор PyPy**:
    - Использует совершенно другой GC (incinering, mark-sweep), более производительный для некоторых workloads.

#### **Лучшие практики для AQA**

1. **Тестирование на утечки памяти**:
    - Используйте `gc.collect()` перед измерениями памяти для чистоты эксперимента.
    - Инструменты: `tracemalloc` (Python 3.4+), `objgraph`, `pympler`, `memory_profiler`.
    - В тестах проверяйте, что память возвращается к базовому уровню после операций.

2. **Нагрузочное тестирование и долгие сессии**:
    - При долгих тестах (нагрузочное тестирование, тесты на выносливость) мониторьте рост памяти.
    - Устанавливайте разумные пороги GC через `gc.set_threshold()` для баланса между производительностью и потреблением
      памяти.

3. **Тестирование с отключённым GC**:
    - Для тестов производительности можно временно отключать GC (`gc.disable()`), но обязательно включать обратно и
      вызывать `gc.collect()`.
    - Учитывайте, что в production GC включён, поэтому результаты могут отличаться.

4. **Обработка циклических ссылок в тестовом коде**:
    - Избегайте создания циклических ссылок в фикстурах и тестовых данных.
    - Используйте `weakref` для кэшей и долгоживущих структур.
    - Особое внимание — моки и патчи: `unittest.mock` может создавать циклы.

5. **Тестирование `__del__` методов**:
    - При тестировании классов с финализаторами проверяйте, что они не создают проблем для GC.
    - Убедитесь, что объекты с `__del__` не образуют циклов.

6. **Асинхронные тесты и GC**:
    - В асинхронном коде задачи могут удерживать ссылки дольше ожидаемого. Используйте `weakref` для ссылок на задачи.
    - Проверяйте, что event loop не удерживает ненужные объекты после завершения тестов.

7. **Интеграционные тесты с внешними ресурсами**:
    - Для тестов с БД, файлами, сетевыми соединениями убедитесь, что ресурсы освобождаются даже при исключениях.
    - Используйте контекстные менеджеры вместо `__del__` для гарантированного освобождения.

8. **Профилирование памяти в тестах**:
    - Добавляйте профилирование памяти в CI для критичных компонентов.
    - Сравнивайте потребление памяти между коммитами.

9. **Тестирование кастомных контейнеров и структур данных**:
    - При тестировании собственных структур данных проверяйте, что они не создают непреднамеренных циклических ссылок.
    - Используйте `gc.get_referents()` и `gc.get_referrers()` для отладки.

10. **Настройка GC для специфичных тестов**:
    - Для тестов, создающих много временных объектов, можно увеличить порог поколения 0, чтобы уменьшить частоту сборок.
    - Для тестов, чувствительных к latency, можно уменьшить пороги для более частой сборки.

11. **Мониторинг `gc.garbage`**:
    - В тестах можно проверять, что `gc.garbage` пуст после сборки. Если нет — это указывает на проблему с `__del__`.
    - Автоматически очищайте `gc.garbage` в teardown.

12. **Тестирование с разными реализациями Python**:
    - Поведение GC может отличаться в CPython, PyPy, Jython. Учитывайте это при кросс-платформенном тестировании.

13. **Образовательные тесты для разработчиков**:
    - Создавайте тесты, демонстрирующие утечки памяти из-за циклических ссылок, чтобы обучать команду.

================================================================================================================================

### Виды сложности кода

#### **1. Асимптотическая сложность (Asymptotic Complexity)**

**Определение**
Асимптотическая сложность — это математическая оценка роста ресурсопотребления (времени выполнения или объема памяти)
алгоритма при неограниченном увеличении размера входных данных. Выражается через O-нотацию (Big-O), Ω-нотацию (Omega) и
Θ-нотацию (Theta). Для анализа производительности кода наиболее часто используется O-нотация, которая определяет верхнюю
границу роста.

**Внутренняя реализация (под капотом)**

1. **Модель вычислений Python**:
    - Python — интерпретируемый язык с динамической типизацией, где каждая операция имеет фиксированные накладные
      расходы.
    - Байт-код выполняется виртуальной машиной CPython, где каждая инструкция (LOAD, STORE, CALL и др.) имеет свою
      стоимость, но для асимптотического анализа мы обычно абстрагируемся до уровня операций.

2. **Стоимость операций в CPython**:
    - Арифметические операции, доступ к локальным переменным — O(1)
    - Вызов функции — O(1) плюс стоимость выполнения тела
    - Доступ к элементу списка/словаря — O(1) в среднем, O(n) в худшем для словаря
    - Поиск в неотсортированном списке — O(n)
    - Сортировка — O(n log n) (используется Timsort)

3. **Структуры данных и их сложность**:
    - Список: append/pop в конце — O(1), insert/delete — O(n)
    - Словарь/множество: поиск, вставка, удаление — O(1) в среднем
    - collections.deque: операции с концами — O(1)
    - heapq: push/pop — O(log n)

4. **Особенности реализации Python**:
    - Динамическое увеличение списков: при переполнении выделяется новый массив в 1.125 раза больше
    - Хэш-таблицы словарей используют открытую адресацию с квадратичным пробированием
    - GIL (Global Interpreter Lock) влияет на параллельные вычисления

**Особенности**

- **Амортизированная сложность**: некоторые операции могут быть дорогими в редких случаях (рехеширование словаря — O(n))
- **Константные множители** важны на практике, но игнорируются в асимптотическом анализе
- **Пространственная сложность** часто упускается, но критична для больших данных

**Лучшие практики для AQA**

1. **Профилирование и бенчмаркинг**: используйте cProfile, line_profiler для измерения реальной производительности
2. **Тестирование на больших данных**: проверяйте поведение алгоритмов при увеличении объема данных в 10, 100, 1000 раз
3. **Выявление узких мест**: находите операции O(n²) или O(n³) в коде с помощью статического анализа
4. **Нагрузочное тестирование**: моделируйте рост данных для проверки масштабируемости
5. **Сравнение алгоритмов**: создавайте тесты, сравнивающие разные реализации одной задачи

---

#### **2. Цикломатическая сложность (Cyclomatic Complexity)**

**Определение**
Цикломатическая сложность — это метрика, измеряющая количество линейно независимых путей в графе потока управления
программы. Рассчитывается как M = E - N + 2P, где E — количество рёбер, N — количество узлов, P — количество компонент
связности. На практике вычисляется как количество ветвлений (if, for, while, and/or в условиях) + 1.

**Внутренняя реализация (под капотом)**

1. **Анализ байт-кода**:
    - Инструменты анализа (pylint, flake8) используют абстрактное синтаксическое дерево (AST) для подсчета точек
      ветвления
    - Каждое условное выражение увеличивает сложность на 1, логические операторы `and`/`or` также учитываются

2. **Граф потока управления в CPython**:
    - Компилятор Python строит граф потока управления для оптимизации
    - Базовые блоки байт-кода соединяются переходами (JUMP_IF_FALSE и др.)
    - Цикломатическая сложность коррелирует с количеством тестовых случаев, необходимых для полного покрытия путей

3. **Инструменты измерения**:
    - `mccabe` — стандартная библиотека Python для расчета цикломатической сложности
    - Интегрируется в линтеры (pylint, flake8) для автоматической проверки

**Особенности**

- **Пороговые значения**: обычно рекомендуемая максимальная сложность — 10-15
- **Ложные срабатывания**: простые but большие операторы `match` (Python 3.10+) могут иметь высокую сложность
- **Вложенность**: глубокая вложенность условий резко увеличивает сложность

**Лучшие практики для AQA**

1. **Интеграция в CI/CD**: настройте линтеры для проверки цикломатической сложности
2. **Рефакторинг сложных методов**: выделяйте части сложных функций в отдельные методы
3. **Тестирование покрытия путей**: используйте инструменты покрытия (coverage.py) для проверки всех независимых путей
4. **Анализ сложности тестового кода**: тестовый код тоже должен быть простым для понимания
5. **Планирование тестирования**: сложность помогает оценить необходимое количество тестовых случаев

---

#### **3. Сложность поддержки (Maintainability Complexity)**

**Определение**
Сложность поддержки — это комплексная метрика, оценивающая, насколько легко понимать, модифицировать и расширять код.
Обычно рассчитывается как комбинация других метрик: цикломатической сложности, количества строк кода, глубины
наследования, связности и др.

**Внутренняя реализация (под капотом)**

1. **Индекс поддерживаемости (MI)**:
    - Рассчитывается по формуле: MI = 171 - 5.2 * ln(HV) - 0.23 * (CC) - 16.2 * ln(LOC)
    - HV — объем Холстеда (метрика операторов и операндов)
    - CC — цикломатическая сложность
    - LOC — количество строк кода

2. **Анализ кодовой базы**:
    - Инструменты (radon, sonarcloud) анализируют AST и строят граф вызовов
    - Учитывают дублирование кода, длину методов, количество параметров, комментарии

3. **Динамический анализ**:
    - Инструменты профилирования помогают понять реальное использование кода
    - Анализ покрытия тестами — хорошо покрытый код обычно проще поддерживать

**Особенности**

- **Субъективность**: метрики не всегда отражают реальную сложность поддержки
- **Контекстная зависимость**: сложность поддержки зависит от опыта команды и доменной области
- **Эволюция кода**: метрики ухудшаются со временем без регулярного рефакторинга

**Лучшие практики для AQA**

1. **Регулярный мониторинг метрик**: включите проверку поддерживаемости в CI/CD pipeline
2. **Технический долг**: документируйте участки с низкой поддерживаемостью
3. **Регрессионное тестирование**: изменения в сложных модулях требуют тщательного тестирования
4. **Автоматизированный рефакторинг**: используйте инструменты для автоматического улучшения кода
5. **Документация и комментарии**: код с хорошими комментариями легче поддерживать

---

#### **4. Когнитивная сложность (Cognitive Complexity)**

**Определение**
Когнитивная сложность — это метрика, разработанная SonarSource, которая оценивает, насколько трудно понять поток
выполнения кода. В отличие от цикломатической сложности, она учитывает вложенность конструкций и логические операторы,
делая акцент на человеческое восприятие.

**Внутренняя реализация (под капотом)**

1. **Алгоритм расчета**:
    - Увеличивается за каждый раз, когда код нарушает линейный поток (ветвления, циклы)
    - Вложенные структуры увеличивают сложность экспоненциально
    - Логические операторы в условиях увеличивают сложность

2. **Анализ AST**:
    - Инструменты обходят абстрактное синтаксическое дерево, подсчитывая:
        - Вложенность конструкций
        - Количество операторов ветвления и циклов
        - Цепочки методов и условия

3. **Инструменты**:
    - `cognitive_complexity` для Python
    - Интеграция в SonarQube/SonarCloud
    - Плагины для IDE

**Особенности**

- **Человеко-ориентированность**: лучше отражает трудность понимания кода, чем цикломатическая сложность
- **Не учитывает семантику**: не различает простые и сложные условия
- **Пороговые значения**: обычно рекомендуется 15-20 для метода

**Лучшие практики для AQA**

1. **Тестирование читаемости кода**: сложные методы труднее тестировать
2. **Рефакторинг глубокой вложенности**: заменяйте вложенные условия на guard clauses
3. **Именование и структурирование**: хорошие имена уменьшают когнитивную нагрузку
4. **Тестовые сценарии**: для когнитивно сложного кода требуется больше тестовых случаев
5. **Парное программирование и ревью**: сложный код требует дополнительного внимания

---

#### **5. Сложность связей (Coupling Complexity)**

**Определение**
Сложность связей — это мера взаимозависимости между модулями, классами или компонентами системы. Высокая связность (
coupling) означает, что изменения в одном модуле требуют изменений в других. Низкая связанность и высокая связность (
cohesion) — признаки хорошей архитектуры.

**Внутренняя реализация (под капотом)**

1. **Анализ импортов и зависимостей**:
    - Инструменты (pydeps, snakefood) строят граф импортов между модулями
    - Анализируются директивы `import`, `from ... import`

2. **Объектная модель Python**:
    - Связи через наследование, композицию, агрегацию
    - Динамическая природа Python (метаклассы, декораторы, monkey patching) усложняет статический анализ

3. **Метрики связанности**:
    - **Афферентная связность (Ca)**: количество модулей, зависящих от данного
    - **Эфферентная связность (Ce)**: количество модулей, от которых зависит данный
    - **Нестабильность**: I = Ce / (Ca + Ce)

**Особенности**

- **Динамическая природа Python**: импорты могут быть динамическими (`__import__()`)
- **Циклические зависимости**: Python позволяет циклические импорты, но они усложняют поддержку
- **Скрытые зависимости**: через глобальные переменные, синглтоны, брокеры сообщений

**Лучшие практики для AQA**

1. **Тестирование изоляции модулей**: модули с высокой связанностью труднее тестировать изолированно
2. **Mocking и стабинг**: для модулей с внешними зависимостями
3. **Интеграционные тесты**: для проверки взаимодействия связанных модулей
4. **Анализ влияния изменений**: при изменении высокосвязанного модуля необходимо перетестировать зависимые
5. **Архитектурное тестирование**: используйте инструменты для проверки архитектурных ограничений

---

### **Общие лучшие практики для Senior Python AQA**

1. **Интеграция метрик в процесс разработки**:
    - Настройте pre-commit хуки для проверки сложности
    - Включите метрики в CI/CD pipeline с пороговыми значениями
    - Используйте dashboards для визуализации тенденций

2. **Профилирование и оптимизация**:
    - Сначала измеряйте, потом оптимизируйте
    - Фокус на bottleneck'ах, а не на микрооптимизациях
    - Учитывайте компромисс между производительностью и читаемостью

3. **Тестирование сложного кода**:
    - Для алгоритмов с высокой асимптотической сложностью — нагрузочное тестирование
    - Для кода с высокой цикломатической сложностью — покрытие всех путей
    - Для связанных модулей — интеграционное и контрактное тестирование

4. **Документация и знания**:
    - Документируйте причины сложных решений
    - Проводите регулярные обзоры сложного кода
    - Создавайте обучающие тестовые сценарии

5. **Автоматизация анализа**:
    - Используйте инструменты статического анализа (pylint, mypy, bandit)
    - Настройте автоматические отчеты о качестве кода
    - Интегрируйте с системами отслеживания технического долга

================================================================================================================================

### Парадигмы ООП

#### **Определение**

ООП (Объектно-ориентированное программирование) — это парадигма программирования, основанная на концепции объектов,
которые объединяют данные (атрибуты) и поведение (методы). Основные парадигмы ООП в Python включают **инкапсуляцию** (
скрытие внутренней реализации), **наследование** (создание иерархий классов), **полиморфизм** (разное поведение объектов
с одинаковым интерфейсом) и **абстракцию** (выделение существенных характеристик). Python реализует ООП через классы,
объекты, метаклассы и специальные методы (dunder methods), поддерживая как классическое, так и протокольное
программирование.

#### **Внутренняя реализация (под капотом)**

1. **Объектная модель CPython**:
    - Каждый объект в Python — это структура C (`PyObject`), содержащая:
        - `ob_refcnt`: счётчик ссылок для сборки мусора
        - `ob_type`: указатель на тип объекта (класс)
    - Классы — это объекты типа `type`, который сам является своим метаклассом (рекурсивно).
    - Экземпляры классов хранят атрибуты в словаре `__dict__` (если не используется `__slots__`).

2. **Механизм наследования**:
    - Python использует **C3 linearization** (алгоритм MRO — Method Resolution Order) для построения цепочки
      наследования.
    - MRO хранится в атрибуте `__mro__` класса и определяет порядок поиска методов.
    - При вызове метода интерпретатор ищет его в MRO через функцию `_PyType_Lookup()`.

3. **Инкапсуляция и доступ к атрибутам**:
    - Специальные методы `__getattribute__()` и `__getattr__()` управляют доступом к атрибутам.
    - Имена с двойным подчёркиванием (`__private`) искажаются (name mangling) на этапе компиляции:
      `_ClassName__private`.
    - Property-дескрипторы (`@property`) используют протокол дескрипторов.

4. **Полиморфизм и виртуальная таблица**:
    - Python использует **duck typing**: объекты рассматриваются по их поведению, а не типу.
    - Вызов метода происходит через поиск в словаре класса (`tp_dict`), затем в MRO.
    - Для оптимизации Python 3.11+ использует **inline caching** и **adaptive interpreter**.

5. **Дескрипторы и property**:
    - Дескрипторы (`__get__`, `__set__`, `__delete__`) лежат в основе property, staticmethod, classmethod.
    - При доступе к атрибуту сначала проверяется, является ли он дескриптором в классе.

6. **Метаклассы**:
    - Метакласс `type` контролирует создание классов.
    - Процесс создания класса: `__prepare__()` → тело класса → `__new__()` → `__init__()`.
    - Метаклассы позволяют модифицировать классы на этапе создания.

7. **Абстрактные классы (ABC)**:
    - Модуль `abc` предоставляет декораторы `@abstractmethod` и метакласс `ABCMeta`.
    - Абстрактные методы проверяются при создании экземпляра через `__instancecheck__`.

#### **Особенности**

1. **Динамическая природа**:
    - Классы и объекты можно изменять в runtime (добавлять/удалять методы и атрибуты).
    - Это позволяет monkey patching, но усложняет статический анализ.

2. **Множественное наследование**:
    - Python поддерживает множественное наследование с разрешением конфликтов через MRO.
    - Mixins — распространённый паттерн для добавления функциональности.

3. **Протоколы и интерфейсы**:
    - Вместо формальных интерфейсов используются **протоколы** (например, итераторный протокол: `__iter__`, `__next__`).
    - **Structural subtyping** (PEP 544) позволяет определять интерфейсы через `typing.Protocol`.

4. **Сравнение с другими языками**:
    - Нет модификаторов доступа (public/private/protected) на уровне языка.
    - Все методы виртуальные по умолчанию.
    - Нет перегрузки методов (кроме перегрузки операторов через специальные методы).

5. **Производительность**:
    - Вызов метода медленнее, чем вызов функции, из-за динамического поиска.
    - `__slots__` ускоряет доступ к атрибутам и экономит память.

6. **Data model и специальные методы**:
    - Полиморфизм операторов реализован через `__add__`, `__len__` и другие dunder methods.
    - Контекстные менеджеры (`__enter__`, `__exit__`) и итераторы — примеры полиморфизма.

#### **Лучшие практики для AQA**

1. **Тестирование инкапсуляции**:
    - Не тестируйте приватные методы (`_protected` и `__private`) напрямую — они являются деталями реализации.
    - Используйте публичный API для тестирования. Если нужно протестировать приватную логику, возможно, её стоит вынести
      в отдельный компонент.
    - Для тестирования property используйте прямой доступ к атрибутам или мокирование.

2. **Тестирование наследования и полиморфизма**:
    - При тестировании иерархии классов используйте абстрактные базовые классы для определения контрактов.
    - Проверяйте, что подклассы корректно реализуют поведение родителя (Liskov Substitution Principle).
    - Создавайте тесты для миксинов отдельно от основных классов.

3. **Mocking и патчинг в ООП**:
    - Используйте `unittest.mock.patch.object` для подмены методов конкретных экземпляров.
    - Для мокирования целых иерархий классов используйте `patch()` с путем к классу.
    - Помните о MRO при мокировании наследования: патч должен применяться к правильному классу в цепочке.

4. **Тестирование абстрактных классов**:
    - Создавайте конкретные классы-заглушки для тестирования абстрактных классов.
    - Используйте `pytest.raises(TypeError)` при попытке инстанциирования абстрактного класса.
    - Проверяйте, что все абстрактные методы реализованы в наследниках.

5. **Тестирование специальных методов**:
    - Проверяйте корректность работы операторов (`==`, `+`, `len()` и т.д.) через юнит-тесты.
    - Для контекстных менеджеров используйте `with` в тестах и проверяйте выполнение `__enter__`/`__exit__`.

6. **Интеграционное тестирование полиморфизма**:
    - В интеграционных тестах проверяйте, что код корректно работает с разными реализациями интерфейса.
    - Используйте dependency injection для подмены реализаций в тестах.

7. **Тестирование метаклассов**:
    - Метаклассы сложно тестировать из-за их выполнения на этапе создания класса.
    - Используйте изолированные тесты, которые создают временные классы.
    - Проверяйте, что метаклассы корректно модифицируют атрибуты класса.

8. **Производительность ООП-кода**:
    - В нагрузочных тестах измеряйте производительность вызовов методов, особенно в глубоких иерархиях.
    - Сравнивайте `__slots__` vs `__dict__` для классов, создаваемых в больших количествах.

9. **Тестирование дескрипторов**:
    - Property, staticmethod, classmethod должны быть протестированы как обычные методы.
    - Проверяйте side effects при доступе к property.

10. **Наследование в тестовых классах**:
    - Используйте наследование для тестовых классов осторожно: общие setup/teardown могут иметь неожиданные эффекты.
    - Предпочитайте композицию (фикстуры) наследованию в тестовом коде.

11. **Тестирование исключений в ООП**:
    - Проверяйте, что методы выбрасывают правильные исключения при нарушении контракта.
    - Тестируйте обработку исключений в цепочках вызовов.

12. **Использование typing для тестирования**:
    - Аннотации типов (`typing.Protocol`, `abc.ABC`) помогают статическим анализаторам находить ошибки.
    - Используйте `mypy` в CI для проверки соответствия типов в тестах и коде.

13. **Тестирование сериализации объектов**:
    - Объекты с сложной иерархией наследования должны корректно сериализоваться (pickle, JSON).
    - Проверяйте сохранение состояния при копировании (`copy.deepcopy()`).

14. **Избегание антипаттернов**:
    - Не тестируйте тривиальные getter/setter.
    - Избегайте чрезмерного наследования в тестовом коде (более 2-3 уровней).
    - Не злоупотребляйте monkey patching в тестах — это усложняет их понимание.

================================================================================================================================

### Магические о методы

#### **Определение**

`__init__`, `__new__` и `__call__` — это специальные методы (dunder methods) Python, которые определяют различные
аспекты жизненного цикла объектов.

- **`__new__`** — статический метод, создающий новый экземпляр класса (конструктор). Вызывается до `__init__` и
  возвращает новый объект.
- **`__init__`** — метод инициализации, который настраивает созданный объект (инициализатор). Вызывается после `__new__`
  и возвращает `None`.
- **`__call__** — позволяет экземплярам класса быть вызываемыми как функции. Делает объект callable.

#### **Внутренняя реализация (под капотом)**

1. **`__new__` — создание объекта на уровне C**:
    - В CPython при вызове класса `MyClass()` интерпретатор сначала ищет `__new__` в классе (или в его родителях).
    - Если `__new__` не определён, вызывается `object.__new__`, который выделяет память через `PyType_GenericNew`.
    - `__new__` получает класс как первый аргумент (`cls`) и должен вернуть экземпляр (обычно этого класса).
    - На уровне C это соответствует вызову `tp_new` слота в структуре `PyTypeObject`.

2. **`__init__` — инициализация объекта**:
    - Если `__new__` вернул экземпляр того же класса (или подкласса), автоматически вызывается `__init__`.
    - `__init__` получает созданный объект как `self` и выполняет начальную настройку.
    - В CPython это соответствует слоту `tp_init`. Если `__init__` возвращает не `None`, возникает `TypeError`.

3. **`__call__` — делаем объект вызываемым**:
    - Определяет поведение при вызове объекта как функции: `obj()`.
    - На уровне C устанавливает слот `tp_call` в структуре типа.
    - Метаклассы также могут иметь `__call__`, который контролирует создание экземпляров.

4. **Последовательность вызовов при создании объекта**:
   ```
   1. MyClass.__new__(cls, ...) → возвращает объект
   2. Если тип объекта совпадает с cls → MyClass.__init__(self, ...)
   3. MyClass.__call__() вызывается при obj()
   ```

5. **Разделение ответственности в CPython**:
    - `__new__` управляет выделением памяти (аналог `malloc` в C).
    - `__init__` управляет инициализацией полей (аналог конструктора в C++).
    - `__call__` позволяет объекту эмулировать функциональность (функторы).

6. **Неизменяемые типы и `__new__`**:
    - Для неизменяемых типов (int, tuple, str) `__new__` часто переопределяется, а `__init__` не используется или
      запрещён.
    - В CPython `tuple.__new__` создаёт объект с фиксированным размером.

7. **Метаклассы и создание классов**:
    - Метакласс `type` имеет свой `__new__` и `__init__` для создания классов.
    - `type.__call__()` вызывает `__new__` и `__init__` при инстанциировании класса.

#### **Особенности**

1. **`__new__` для синглтонов и пулов объектов**:
    - Можно переопределить `__new__` для реализации паттернов: синглтон (всегда возвращать один экземпляр), пул
      объектов, кэширование.
    - Важно: если `__new__` возвращает объект другого типа, `__init__` не вызывается.

2. **Наследование от неизменяемых типов**:
    - При наследовании от tuple, int, str нужно переопределять `__new__`, а не `__init__`.
    - `__init__` в неизменяемых типах игнорируется или вызывает ошибку.

3. **`__call__` для функциональных объектов**:
    - Позволяет создавать объекты, которые ведут себя как функции, но с состоянием (функторы).
    - Используется в декораторах, контекстных менеджерах, callback-ах.

4. **Производительность**:
    - `__new__` и `__init__` вызываются для каждого нового объекта.
    - `__call__` добавляет накладные расходы на вызов (дополнительный уровень косвенности).

5. **Совместное использование с метаклассами**:
    - Метакласс может переопределять `__call__`, чтобы изменить процесс создания экземпляра.
    - Это позволяет реализовать валидацию, регистрацию, кэширование при создании объектов.

6. **Ограничения `__init__`**:
    - Не может возвращать значение (кроме `None`).
    - Вызывается только если `__new__` вернул объект правильного типа.

#### **Лучшие практики для AQA**

1. **Тестирование `__init__`**:
    - Проверяйте корректную инициализацию атрибутов при разных входных данных.
    - Тестируйте обработку неверных аргументов (должны выбрасываться исключения).
    - Проверяйте side effects в `__init__` (например, регистрация объекта в глобальном реестре).

2. **Тестирование `__new__`**:
    - Если `__new__` переопределён, тестируйте все возможные возвращаемые значения.
    - Проверяйте, что `__init__` вызывается/не вызывается соответствующим образом.
    - Для синглтонов: убедитесь, что всегда возвращается один и тот же объект.
    - Для пулов объектов: проверяйте повторное использование объектов.

3. **Тестирование `__call__`**:
    - Проверяйте поведение объекта при вызове с разными аргументами.
    - Убедитесь, что объект сохраняет состояние между вызовами (если это требуется).
    - Тестируйте взаимодействие с другими протоколами (например, может ли вызываемый объект быть декоратором).

4. **Тестирование наследования**:
    - При наследовании проверяйте цепочку вызовов `super().__new__` и `super().__init__`.
    - Для классов, наследующих от неизменяемых типов, тестируйте корректность переопределения `__new__`.

5. **Мокирование и патчинг**:
    - При мокировании `__init__` используйте `unittest.mock.patch.object` для замены инициализации.
    - Для тестирования `__call__` можно использовать `Mock` с `side_effect`.
    - Избегайте мокирования `__new__` в тестах, если это не необходимо — это может нарушить создание объектов.

6. **Интеграционное тестирование**:
    - Проверяйте, что объекты корректно создаются и инициализируются в контексте всего приложения.
    - Для фабрик и пулов объектов тестируйте многопоточное создание (race conditions).

7. **Производительность создания объектов**:
    - В нагрузочных тестах измеряйте время создания множества объектов.
    - Если `__new__`/`__init__` выполняют тяжёлые операции, проверяйте возможность ленивой инициализации.

8. **Тестирование неизменяемых объектов**:
    - Для классов с переопределённым `__new__` (наследники tuple и т.д.) проверяйте, что объекты действительно
      неизменяемы.
    - Тестируйте хэшируемость таких объектов и использование в качестве ключей словаря.

9. **Исключительные ситуации**:
    - Проверяйте поведение при исключениях в `__new__` (объект не должен быть создан).
    - Проверяйте обработку исключений в `__init__` (частично инициализированный объект может требовать cleanup).
    - Для `__call__` тестируйте исключения при неверных аргументах.

10. **Сериализация**:
    - Объекты с переопределёнными `__new__`/`__init__` могут требовать специальной обработки при pickle/unpickle.
    - Тестируйте сохранение состояния при сериализации.

11. **Использование в фреймворках**:
    - В Django, SQLAlchemy и других фреймворках `__init__` может быть переопределён. Тестируйте совместимость с
      фреймворком.
    - Проверяйте, что кастомные `__new__`/`__call__` не нарушают работу фреймворка.

12. **Документация и контракты**:
    - Для классов с нестандартным поведением этих методов документируйте ожидания.
    - В тестах проверяйте соблюдение контрактов (например, что `__init__` не возвращает значение).

================================================================================================================================

### Декораторы классов и методов

#### **Определение**

`@property`, `@staticmethod`, и `@classmethod` — это встроенные декораторы Python, которые модифицируют поведение
методов в классах, превращая их в дескрипторы (descriptors).

- **`@property`** — преобразует метод в атрибут только для чтения (getter), но также позволяет определять setter и
  deleter для управления доступом к атрибутам.
- **`@staticmethod`** — определяет статический метод, который не получает ни неявной ссылки на экземпляр (`self`), ни на
  класс (`cls`). Это обычная функция, но принадлежащая пространству имён класса.
- **`@classmethod`** — определяет метод класса, который получает класс в качестве первого аргумента (`cls`), а не
  экземпляр. Позволяет работать с классом как с объектом.

#### **Внутренняя реализация (под капотом)**

1. **Механизм дескрипторов**:
    - Все три декоратора реализованы как **дескрипторы** — классы с методами `__get__()`, `__set__()` и/или
      `__delete__()`.
    - При доступе к атрибуту объекта Python проверяет, является ли атрибут дескриптором в классе, и вызывает
      соответствующие методы дескриптора.

2. **`@property`**:
    - Реализован классом `property` в C (`PyProperty_Type`).
    - Содержит методы-дескрипторы: `fget`, `fset`, `fdel` и `__doc__`.
    - При чтении атрибута вызывается `property.__get__()`, который вызывает исходную функцию-getter.
    - При присваивании — `property.__set__()`, который вызывает setter, если он определён.

3. **`@staticmethod`**:
    - Реализован классом `staticmethod` (`PyStaticMethod_Type`).
    - Метод `__get__()` возвращает исходную функцию без привязки (не превращает в bound method).
    - В CPython это достигается тем, что `__get__()` игнорирует и экземпляр, и класс, возвращая непосредственно
      обёрнутую функцию.

4. **`@classmethod`**:
    - Реализован классом `classmethod` (`PyClassMethod_Type`).
    - Метод `__get__()` связывает функцию с классом (не с экземпляром), возвращая bound method, где первый аргумент —
      класс.
    - При вызове из экземпляра передаёт класс экземпляра, при вызове из класса — сам класс.

5. **Разрешение атрибутов в CPython**:
    - Процесс поиска атрибута: `object.__getattribute__()` → поиск в `__dict__` класса → проверка дескрипторов.
    - Для property, staticmethod, classmethod поиск происходит в `type(obj).__dict__`, где они хранятся как дескрипторы.

6. **Иерархия наследования**:
    - Все три являются подклассами `object` в C-реализации.
    - Они переопределяют только метод `__get__`, а `property` также переопределяет `__set__` и `__delete__`.

7. **Кэширование и производительность**:
    - В CPython 3.9+ используется кэширование результатов `__get__` для ускорения повторных обращений.
    - Property не кэширует значение по умолчанию — каждый вызов вычисляет значение заново (но можно реализовать
      кэширование через `@property` с `@functools.lru_cache`).

#### **Особенности**

1. **Property как инструмент инкапсуляции**:
    - Позволяет изменить внутреннюю реализацию без изменения публичного API.
    - Может выполнять валидацию в setter, ленивые вычисления в getter.
    - При отсутствии setter свойство становится read-only.

2. **Отличие staticmethod от classmethod**:
    - `staticmethod` — это просто функция внутри класса, не имеющая доступа к состоянию класса/экземпляра.
    - `classmethod` — получает класс, может обращаться к атрибутам класса и модифицировать их.

3. **Наследование и полиморфизм**:
    - Property наследуется и может быть переопределено в подклассах.
    - Classmethod при вызове из подкласса получает подкласс как `cls`, что позволяет реализовать фабричные методы.

4. **Производительность**:
    - Вызов property медленнее, чем доступ к обычному атрибуту, из-за накладных расходов на вызов функции.
    - Staticmethod и classmethod медленнее обычных функций, но быстрее property.

5. **Совместимость с декораторами**:
    - Порядок декораторов важен: `@property` должен быть самым верхним, если комбинируется с другими декораторами.
    - `@classmethod` и `@staticmethod` нельзя использовать вместе — они взаимоисключающие.

6. **Динамическое создание**:
    - Property можно создавать динамически через конструктор `property(fget, fset, fdel, doc)`.
    - Аналогично для `classmethod` и `staticmethod`.

#### **Лучшие практики для AQA**

1. **Тестирование property**:
    - Тестируйте getter, setter и deleter как отдельные функции, проверяя их возвращаемые значения и side effects.
    - Для property с валидацией проверяйте корректное поведение при валидных и невалидных значениях.
    - Убедитесь, что property read-only действительно не позволяет запись (выбрасывает `AttributeError`).

2. **Тестирование classmethod**:
    - Проверяйте, что метод корректно работает при вызове как из класса, так и из экземпляра.
    - Для фабричных методов тестируйте создание объектов разных типов при наследовании.
    - Убедитесь, что метод использует именно атрибуты класса, а не экземпляра.

3. **Тестирование staticmethod**:
    - Тестируйте как обычную функцию, поскольку она не зависит от состояния класса/экземпляра.
    - Проверяйте, что метод действительно не имеет доступа к `self` или `cls`.

4. **Мокирование и патчинг**:
    - При мокировании property используйте `@property` на Mock-объекте или патчите конкретный getter/setter.
    - Для classmethod и staticmethod можно патчить непосредственно в классе с помощью `unittest.mock.patch.object`.
    - Учитывайте, что property, classmethod, staticmethod — это дескрипторы на уровне класса, поэтому патчить нужно в
      классе, а не в экземпляре.

5. **Интеграционное тестирование**:
    - Проверяйте, что property корректно взаимодействует с сериализацией (pickle, JSON).
    - Для classmethod, изменяющих состояние класса, проверяйте влияние на все экземпляры.

6. **Наследование и переопределение**:
    - При тестировании иерархии классов проверяйте, что переопределение property в подклассах работает корректно.
    - Для classmethod убедитесь, что вызов из подкласса передаёт правильный `cls`.

7. **Производительность в тестах**:
    - В нагрузочных тестах измеряйте производительность property при частом доступе.
    - Рассмотрите замену property на обычные атрибуты для hot paths, если это критично.

8. **Тестирование декораторов в комбинации**:
    - Если property комбинируется с другими декораторами (например, `@lru_cache`), тестируйте кэширование и инвалидацию
      кэша.
    - Проверяйте порядок декораторов, если используются `@property` и `@classmethod` вместе (это обычно невозможно, но
      есть workarounds).

9. **Использование в тестовом коде**:
    - Используйте property для ленивых вычислений в тестовых данных.
    - Применяйте classmethod как фабрики для создания тестовых фикстур.
    - Используйте staticmethod для хелпер-функций, логически связанных с тестовым классом.

10. **Проверка контрактов**:
    - Убедитесь, что setter property сохраняет инварианты класса.
    - Проверяйте, что classmethod не полагается на состояние экземпляра.

11. **Документация и сообщения об ошибках**:
    - Тестируйте сообщения об ошибках в property setter при невалидных данных.
    - Проверяйте наличие docstring у property (он наследуется от getter).

12. **Обработка исключений**:
    - Property должно корректно пробрасывать исключения из getter/setter.
    - Проверяйте, что исключения в classmethod не нарушают состояние класса.

13. **Тестирование с метаклассами**:
    - Если класс создаётся с помощью метакласса, property, classmethod, staticmethod должны корректно разрешаться.
    - Особенно важно для динамически создаваемых классов.

================================================================================================================================

### Множественное наследование и MRO

#### **Определение**

**Множественное наследование** — это возможность класса в Python наследовать атрибуты и методы от нескольких
родительских классов. Это создаёт иерархию в виде направленного ациклического графа (DAG). **MRO (Method Resolution
Order)** — это порядок, в котором Python ищет методы и атрибуты в иерархии классов при множественном наследовании. MRO
гарантирует, что каждый класс в иерархии обрабатывается ровно один раз, и определяет последовательность, соответствующую
ожиданиям программиста (например, соблюдение принципа подстановки Лисков).

#### **Внутренняя реализация (под капотом)**

1. **Алгоритм C3 linearization**:
    - Начиная с Python 2.3, для расчёта MRO используется алгоритм **C3 linearization**.
    - Алгоритм строит линейный порядок классов, удовлетворяющий двум условиям:
        1. **Consistency with inheritance** (Согласованность с наследованием): если класс A является предком класса B,
           то в MRO класс A должен идти после класса B (то есть поиск идёт от потомка к предку).
        2. **Monotonicity** (Монотонность): порядок классов в MRO каждого родителя должен сохраняться в MRO потомка.

2. **Вычисление MRO**:
    - MRO вычисляется на этапе создания класса (при выполнении определения класса) и сохраняется в атрибуте `__mro__` (
      кортеж) и `mro()` (метод).
    - Алгоритм C3 обрабатывает список родителей в порядке их указания в определении класса.
    - Формально, для класса C с родителями B1, B2, ..., Bn, MRO(C) = [C] + merge(MRO(B1), MRO(B2), ..., MRO(
      Bn), [B1, B2, ..., Bn]), где merge объединяет списки, выбирая первый элемент, который не встречается ни в каком
      другом списке на позиции, отличной от первой.

3. **Структуры данных CPython**:
    - В CPython каждый класс (тип) имеет поле `tp_mro` — кортеж классов, представляющий MRO.
    - При создании класса через метакласс `type` вызывается функция `mro_internal()`, которая вычисляет MRO с помощью
      C3.
    - Поиск атрибута осуществляется функцией `_PyType_Lookup()`, которая проходит по `tp_mro` и проверяет `tp_dict`
      каждого класса.

4. **Поиск методов**:
    - При вызове метода у экземпляра интерпретатор ищет метод в MRO класса экземпляра.
    - Если метод не найден, вызывается исключение `AttributeError`.
    - Для каждого класса в MRO проверяется словарь атрибутов (`__dict__`), и если атрибут является дескриптором, то
      вызывается его метод `__get__`.

5. **Супер (super)**:
    - `super()` использует MRO для определения следующего класса в цепочке.
    - Внутри метода `super().__init__` вызывает `__init__` следующего класса в MRO текущего класса (того, в контексте
      которого вызван `super`).
    - Реализация `super` хранит ссылку на текущий класс и экземпляр (или класс для classmethod) и вычисляет индекс
      текущего класса в MRO.

6. **Динамическое изменение MRO**:
    - MRO фиксируется при создании класса и не может быть изменён динамически (за исключением изменения с помощью
      метаклассов при создании класса).
    - Однако можно изменить MRO подкласса, переопределив порядок родителей.

#### **Особенности**

1. **Алмазная проблема (diamond problem)**:
    - Python решает алмазную проблему (когда два родителя наследуются от одного общего предка) с помощью MRO,
      гарантируя, что общий предок обрабатывается только один раз.
    - Порядок определяется C3: например, для D(B, C), где B и C наследуют от A, MRO будет D -> B -> C -> A (если B
      указан перед C).

2. **Непоследовательность MRO**:
    - Если порядок родителей не может быть разрешён алгоритмом C3 (например, из-за конфликтующих требований), Python
      выбрасывает `TypeError` при создании класса.
    - Это происходит, например, при циклических зависимостях или нарушении монотонности.

3. **Различие между классическими и новыми стилями классов**:
    - В Python 3 все классы являются классами «нового стиля» (наследуют от `object`), и MRO работает на основе C3.
    - В Python 2 для классов «старого стиля» (которые не наследуют от `object`) использовался глубинный поиск (DFS), что
      могло приводить к неинтуитивному поведению.

4. **Влияние на вызов `super`**:
    - `super()` не всегда вызывает метод непосредственного родителя, а следующий класс в MRO.
    - Это позволяет кооперативному множественному наследованию (cooperative multiple inheritance), когда несколько
      классов в иерархии могут участвовать в вызове метода.

5. **Производительность**:
    - Поиск атрибутов в MRO имеет линейную сложность O(n) по количеству классов в MRO.
    - CPython оптимизирует поиск, кэшируя результаты в словарях (например, для преобразования методов в bound methods).

6. **Абстрактные базовые классы (ABC)**:
    - Модуль `abc` использует MRO для проверки реализации абстрактных методов: если абстрактный метод не переопределён в
      цепочке наследования, класс не может быть инстанциирован.

#### **Лучшие практики для AQA**

1. **Тестирование порядка разрешения методов**:
    - При тестировании классов с множественным наследованием проверяйте, что методы вызываются в ожидаемом порядке.
    - Используйте атрибут `__mro__` для проверки порядка разрешения.
    - Создавайте тесты, которые проверяют корректность работы `super()` в цепочке вызовов.

2. **Тестирование алмазной проблемы**:
    - Убедитесь, что общий предок в алмазной иерархии инициализируется только один раз.
    - Проверяйте, что состояние общего предка корректно наследуется всеми ветвями.

3. **Мокирование и патчинг в MRO**:
    - При мокировании методов в иерархии с множественным наследованием патчите метод в правильном классе (учитывая MRO).
    - Используйте `unittest.mock.patch.object` с конкретным классом из MRO.

4. **Тестирование абстрактных классов**:
    - Для классов, наследующих от нескольких абстрактных классов, проверяйте, что все абстрактные методы реализованы.
    - Используйте `pytest.raises(TypeError)` при попытке создать экземпляр класса с неправильной MRO (например, если
      конфликт C3).

5. **Интеграционное тестирование `super`**:
    - Проверяйте, что вызовы `super()` в классах с множественным наследованием корректно передают управление.
    - Тестируйте цепочки вызовов `__init__`, `__enter__`, `__exit__` и других методов, которые используют `super`.

6. **Тестирование миксинов (mixins)**:
    - Миксины (классы, предназначенные для множественного наследования) должны быть протестированы изолированно и в
      комбинации с другими классами.
    - Проверяйте, что миксины не ломают MRO основного класса.

7. **Нагрузочное тестирование**:
    - Для глубоких и широких иерархий наследования проверяйте производительность поиска атрибутов.
    - Убедитесь, что MRO не становится слишком длинным (что может замедлить поиск).

8. **Тестирование динамических изменений**:
    - Если в проекте используются метаклассы, динамически изменяющие MRO, тестируйте создание классов и разрешение
      атрибутов.
    - Проверяйте, что динамические изменения не приводят к непредсказуемому поведению.

9. **Использование MRO в тестовых классах**:
    - При создании тестовых классов-хелперов с множественным наследованием убедитесь, что MRO не конфликтует с тестовыми
      фреймворками (например, наследование от `unittest.TestCase` и миксинов).

10. **Проверка корректности MRO**:
    - В тестах можно проверять атрибут `__mro__` на соответствие ожидаемому порядку.
    - Это особенно важно для библиотек, предоставляющих свои базовые классы для наследования.

11. **Тестирование с использованием `inspect`**:
    - Модуль `inspect` предоставляет функции для анализа иерархии классов. Используйте их в тестах для проверки MRO.

12. **Документирование ожидаемого MRO**:
    - Для сложных иерархий классов документируйте ожидаемый порядок разрешения методов.
    - В тестах можно проверять, что документация соответствует реальному поведению.

13. **Избегание проблем с MRO**:
    - При проектировании тестовых классов избегайте создания конфликтующих иерархий (которые могут привести к ошибкам
      C3).
    - Если возникает ошибка MRO, пересмотрите дизайн иерархии.

================================================================================================================================

### ABC (Abstract Base Classes)

#### **Определение**

ABC (Abstract Base Classes) — это абстрактные базовые классы в Python, которые позволяют определять интерфейсы и
контракты для классов. Они служат для декларативного описания того, какие методы и свойства должны быть реализованы в
наследующих классах, без предоставления (или с частичным предоставлением) их реализации. ABC используются для создания
иерархий типов, обеспечения полиморфизма и реализации паттерна проектирования "Интерфейс". Модуль `abc` предоставляет
метакласс `ABCMeta`, декоратор `@abstractmethod` и вспомогательный класс `ABC`.

#### **Внутренняя реализация (под капотом)**

1. **Метакласс `ABCMeta`**:
    - Все ABC используют метакласс `ABCMeta`, который наследуется от стандартного метакласса `type`.
    - Метакласс переопределяет процесс создания классов, добавляя специальную логику для работы с абстрактными методами.

2. **Абстрактные методы и `@abstractmethod`**:
    - Декоратор `@abstractmethod` помечает метод как абстрактный, устанавливая атрибут `__isabstractmethod__ = True`.
    - При создании класса метакласс собирает все методы с `__isabstractmethod__ == True` в атрибут
      `__abstractmethods__` (frozenset).
    - Если класс имеет непустой `__abstractmethods__`, он считается абстрактным и не может быть инстанциирован.

3. **Проверка при инстанцировании**:
    - При попытке создать экземпляр класса, `ABCMeta.__call__` проверяет `__abstractmethods__`.
    - Если есть нереализованные абстрактные методы, выбрасывается `TypeError` с сообщением о том, какие методы не
      реализованы.
    - Проверка происходит в момент вызова `__new__` и `__init__`.

4. **Виртуальные подклассы и `register()`**:
    - ABC поддерживают концепцию виртуальных подклассов через метод `register()`.
    - Зарегистрированный класс считается подклассом ABC для функций `issubclass()` и `isinstance()`, даже без явного
      наследования.
    - Внутренне ABC хранят зарегистрированные классы в `_abc_registry` (WeakSet).

5. **Метод `__subclasshook__`**:
    - `ABCMeta` использует метод `__subclasshook__` для кастомной логики проверки подклассов.
    - Это позволяет ABC определять, является ли класс подклассом на основе наличия определенных методов (структурная
      типизация).
    - Например, `collections.abc.Sized` считает класс подклассом, если у него есть метод `__len__`.

6. **Наследование абстрактных свойств**:
    - `@abstractmethod` можно комбинировать с `@property`, `@staticmethod`, `@classmethod`.
    - Для property декораторы должны применяться в правильном порядке: `@property` над `@abstractmethod`.

7. **Кэширование и оптимизации**:
    - `ABCMeta` кэширует результаты проверок `issubclass` и `isinstance` для производительности.
    - Атрибут `__abstractmethods__` вычисляется один раз при создании класса.

#### **Особенности**

1. **Неявное наследование от `object`**:
    - В Python 3 все классы неявно наследуют от `object`, и ABC не исключение.
    - Класс `ABC` из модуля `abc` — это просто удобная обертка с `metaclass=ABCMeta`.

2. **Множественное наследование**:
    - ABC могут участвовать в множественном наследовании.
    - При наследовании от нескольких ABC, все их абстрактные методы должны быть реализованы.
    - Порядок наследования влияет на MRO и разрешение методов.

3. **Частичная реализация**:
    - ABC могут предоставлять частичную реализацию методов (как обычные классы).
    - Абстрактными могут быть только некоторые методы, остальные могут иметь реализацию по умолчанию.

4. **Динамическое добавление абстрактных методов**:
    - Абстрактные методы можно добавлять динамически после создания класса, но это считается антипаттерном.
    - `ABCMeta` пересчитывает `__abstractmethods__` при изменениях.

5. **Совместимость с type hints**:
    - ABC из модуля `collections.abc` (`Iterable`, `Container`, `Sequence` и др.) используются в аннотациях типов.
    - В Python 3.9+ можно использовать `collections.abc` или `typing` для generic-типов.

6. **Отличие от интерфейсов в других языках**:
    - В Python нет отдельной конструкции "интерфейс", ABC служат этой цели.
    - ABC могут содержать состояние (атрибуты) и реализацию, в отличие от чистых интерфейсов.

#### **Лучшие практики для AQA**

1. **Тестирование контрактов ABC**:
    - При тестировании классов, наследующих от ABC, проверяйте, что все абстрактные методы реализованы.
    - Используйте статический анализ (mypy) для проверки соответствия интерфейсам.

2. **Тестирование самого ABC**:
    - Для тестирования абстрактных классов создавайте конкретные классы-заглушки, реализующие все абстрактные методы.
    - Проверяйте, что ABC не может быть инстанциирован напрямую (должен выбрасывать `TypeError`).

3. **Тестирование виртуальных подклассов**:
    - Если в проекте используется `register()`, тестируйте, что зарегистрированные классы проходят проверки `issubclass`
      и `isinstance`.
    - Убедитесь, что виртуальные подклассы действительно удовлетворяют контракту ABC.

4. **Интеграционное тестирование полиморфизма**:
    - Тестируйте код, который работает с объектами через интерфейс ABC, с разными реализациями.
    - Используйте dependency injection для подмены реализаций в тестах.

5. **Тестирование `__subclasshook__`**:
    - Если ABC определяет кастомный `__subclasshook__`, создайте тесты для проверки его логики.
    - Проверяйте как позитивные, так и негативные сценарии.

6. **Mocking ABC в тестах**:
    - При тестировании кода, зависящего от ABC, можно использовать `unittest.mock.Mock` или создавать конкретные
      mock-классы.
    - Убедитесь, что mock-объекты удовлетворяют интерфейсу ABC.

7. **Тестирование с `collections.abc`**:
    - Для встроенных ABC (`Sequence`, `Mapping`, `Iterable` и др.) проверяйте, что пользовательские классы корректно их
      реализуют.
    - Используйте `isinstance(obj, collections.abc.Sequence)` для проверки в тестах.

8. **Наследование тестовых классов от ABC**:
    - ABC можно использовать для создания базовых тестовых классов с общими методами, требующими реализации в конкретных
      тестах.
    - Например, абстрактный тестовый класс с абстрактным методом `create_fixture()`.

9. **Проверка исключительных ситуаций**:
    - Тестируйте, что попытка инстанцирования абстрактного класса вызывает понятное исключение с перечнем
      нереализованных методов.
    - Проверяйте, что частичные реализации работают корректно.

10. **Тестирование property в ABC**:
    - Для ABC с абстрактными property тестируйте корректность работы getter/setter/deleter в реализующих классах.
    - Проверяйте, что property действительно абстрактные.

11. **Использование ABC в фикстурах**:
    - ABC могут определять интерфейсы для тестовых фикстур, обеспечивая единообразие.
    - Например, абстрактная фикстура базы данных с конкретными реализациями для разных СУБД.

12. **Тестирование производительности**:
    - ABC добавляют небольшой оверхед на проверки. В нагрузочных тестах убедитесь, что это не становится bottleneck.
    - Рассмотрите возможность использования `__slots__` в ABC для экономии памяти.

13. **Документация и контракты**:
    - ABC служат документацией ожидаемого интерфейса. В тестах проверяйте, что документация соответствует реализации.
    - Используйте ABC для определения контрактов между компонентами системы.

14. **Тестирование миграций ABC**:
    - При изменении ABC (добавление/удаление абстрактных методов) тестируйте обратную совместимость.
    - Используйте versioning для ABC в публичных API.

15. **Интеграция с протоколами `typing`**:
    - В Python 3.8+ можно использовать `typing.Protocol` как альтернативу ABC для структурной типизации.
    - Тестируйте совместимость кода с обоими подходами.

================================================================================================================================

### Протокол (Protocol)

#### **Определение**

Протоколы (Protocol) — это механизм структурной типизации в Python, введённый PEP 544 и доступный в модуле `typing`
начиная с Python 3.8. Протоколы определяют неявные интерфейсы на основе наличия определённых методов и атрибутов (
структурная типизация), в отличие от явного наследования (номинативная типизация). Класс, реализующий все методы и
атрибуты протокола, считается его подтипом, даже без явного наследования. Протоколы используются для статической
проверки типов и документирования ожидаемых интерфейсов.

#### **Внутренняя реализация (под капотом)**

1. **Базовый класс `typing.Protocol`**:
    - `Protocol` является подклассом `typing.Generic` и использует метакласс `_ProtocolMeta` (внутренний класс в модуле
      `typing`).
    - Метакласс `_ProtocolMeta` наследуется от `_GenericAlias` и добавляет специальную логику для обработки протоколов.

2. **Атрибут `__protocol_attrs__`**:
    - При создании протокола метакласс собирает все атрибуты, определённые в теле протокола (кроме начинающихся с
      подчёркивания).
    - Эти атрибуты сохраняются в `__protocol_attrs__` и используются для проверки соответствия.

3. **Проверка соответствия (compatibility check)**:
    - При использовании статического анализатора (например, mypy) проверяется, что класс имеет все методы и атрибуты,
      определённые в протоколе.
    - В runtime проверка не выполняется автоматически, но можно использовать `isinstance()` с `runtime_checkable`.

4. **Декоратор `@runtime_checkable`**:
    - Протоколы, декорированные `@typing.runtime_checkable`, получают метод `__instancecheck__`, который позволяет
      использовать `isinstance()`.
    - Проверка в runtime осуществляется через проверку наличия всех методов и атрибутов протокола в классе объекта.
    - Однако она ограничена: проверяются только имена, но не сигнатуры методов или типы атрибутов.

5. **Интеграция с системой типов CPython**:
    - Протоколы не имеют специальной поддержки на уровне CPython — они реализованы как обычные классы Python.
    - Вся магия происходит в метаклассе и статических анализаторах.

6. **Generic-протоколы**:
    - Протоколы могут быть параметризованы, как и обычные Generic-типы.
    - Например, `Protocol[T]` определяет протокол с типовым параметром.

7. **Совместимость с `ABC`**:
    - Протоколы могут наследоваться от других протоколов и от ABC.
    - Однако `ABC` — это классы для номинативной типизации, а протоколы — для структурной.

#### **Особенности**

1. **Структурная vs номинативная типизация**:
    - Протоколы используют структурную типизацию: объект соответствует протоколу, если имеет нужные методы/атрибуты.
    - ABC используют номинативную типизацию: объект должен явно наследовать от ABC.

2. **Runtime проверка ограничена**:
    - `@runtime_checkable` проверяет только наличие атрибутов, но не их типы или сигнатуры методов.
    - Это может привести к ложным срабатываниям, если метод существует, но имеет другую сигнатуру.

3. **Производительность**:
    - Протоколы не добавляют накладных расходов в runtime, так как проверки выполняются статически.
    - `@runtime_checkable` добавляет небольшой overhead при использовании `isinstance()`.

4. **Совместимость с существующим кодом**:
    - Протоколы позволяют типизировать существующий код, который не использует ABC (например, встроенные типы или классы
      из сторонних библиотек).

5. **Поддержка в инструментах**:
    - mypy, pyright, PyCharm и другие статические анализаторы поддерживают протоколы.
    - В Python 3.11+ улучшена поддержка протоколов в `typing` модуле.

6. **Отличие от утиной типизации**:
    - Утиная типизация — это динамическая концепция Python ("если ходит как утка и крякает как утка, то это утка").
    - Протоколы добавляют статическую проверку утиной типизации.

#### **Лучшие практики для AQA**

1. **Тестирование соответствия протоколам**:
    - При тестировании классов, которые должны соответствовать протоколам, используйте статическую проверку типов (mypy
      в CI).
    - Создавайте тесты, которые проверяют наличие всех требуемых методов и атрибутов.
    - Для `@runtime_checkable` протоколов используйте `isinstance()` в тестах.

2. **Тестирование `@runtime_checkable`**:
    - Проверяйте, что `isinstance(obj, Protocol)` возвращает `True` для корректных объектов.
    - Убедитесь, что проверка не пропускает объекты с неправильными сигнатурами методов (это ограничение
      `@runtime_checkable`).

3. **Использование протоколов в тестовых двойниках (test doubles)**:
    - При создании mock-объектов для зависимостей, типизированных протоколами, убедитесь, что mock имеет все необходимые
      методы.
    - Используйте `unittest.mock.Mock` с автоматическим созданием методов через `spec` или `spec_set`.

4. **Интеграционное тестирование с протоколами**:
    - Тестируйте код, который работает с объектами через протоколы, с различными реализациями.
    - Используйте протоколы для определения интерфейсов в интеграционных тестах.

5. **Тестирование generic-протоколов**:
    - Для протоколов с типовыми параметрами тестируйте различные специализации.
    - Проверяйте совместимость generic-протоколов с конкретными типами.

6. **Сравнение с ABC**:
    - В тестах можно сравнивать поведение ABC и протоколов для одних и тех же интерфейсов.
    - Убедитесь, что выбор между ABC и протоколами обоснован в коде проекта.

7. **Документация интерфейсов**:
    - Протоколы служат документацией ожидаемых интерфейсов. В тестах проверяйте, что реализация соответствует
      документации.
    - Используйте протоколы для документирования интерфейсов в тестовых помощниках.

8. **Тестирование миграции с ABC на протоколы**:
    - Если в проекте происходит миграция с ABC на протоколы, создайте тесты, проверяющие обратную совместимость.
    - Убедитесь, что старый код, использующий ABC, работает с новым кодом, использующим протоколы.

9. **Использование протоколов в фикстурах**:
    - Протоколы могут определять интерфейсы для тестовых фикстур, обеспечивая единообразие.
    - Например, протокол для тестового клиента API.

10. **Проверка статическим анализатором**:
    - Включите проверку mypy в CI/CD pipeline для проверки соответствия протоколам.
    - Настройте строгие правила для протоколов в mypy (например, `--strict`).

11. **Тестирование сторонних библиотек**:
    - Если проект использует сторонние библиотеки, типизированные протоколами, убедитесь, что интеграция работает
      корректно.
    - Используйте stubs (файлы `.pyi`) для тестирования типов.

12. **Производительность в runtime**:
    - Если в коде используется много проверок `isinstance()` с `@runtime_checkable`, измерьте их влияние на
      производительность в нагрузочных тестах.

13. **Кастомная проверка соответствия**:
    - Для сложных протоколов можно создать кастомную функцию проверки, которая проверяет не только наличие, но и
      сигнатуры методов.
    - Используйте модуль `inspect` для проверки сигнатур в тестах.

14. **Образовательные тесты**:
    - Создайте тесты, демонстрирующие разницу между структурной и номинативной типизацией для команды.

================================================================================================================================

### Паттерны проектирования

#### **Определение**

Паттерны проектирования (Design Patterns) — это типизированные, проверенные решения часто возникающих проблем в
проектировании программного обеспечения. Они представляют собой не готовый код, а шаблоны, описывающие, как решать
определенные проблемы оптимальным способом. В Python, благодаря его динамической природе и высокоуровневым конструкциям,
многие классические паттерны реализуются иначе, чем в статически типизированных языках, а некоторые встроены в сам
язык (например, декоратор, итератор).

#### **Внутренняя реализация (под капотом)**

1. **Интеграция паттернов в язык**:
    - Некоторые паттерны настолько глубоко встроены в Python, что стали частью его синтаксиса:
        - **Декоратор**: синтаксис `@decorator` реализован через замыкания и переприсваивание имен.
        - **Итератор**: протокол `__iter__`/`__next__` встроен в цикл `for`.
        - **Менеджер контекста**: протокол `__enter__`/`__exit__` реализован в операторе `with`.
    - Эти паттерны компилируются в специальные инструкции байт-кода (например, `SETUP_WITH` для контекстных менеджеров).

2. **Объектная модель Python и паттерны**:
    - Динамическая типизация позволяет реализовывать паттерны более гибко:
        - **Стратегия**: функции как объекты первого класса можно передавать напрямую, без оберток.
        - **Фабрика**: классы можно создавать динамически с помощью `type()`.
    - Дескрипторы (протокол `__get__`, `__set__`) лежат в основе многих паттернов, таких как Property, Singleton через
      метаклассы.

3. **Метаклассы и паттерны**:
    - Метаклассы (`type` и его подклассы) позволяют реализовать такие паттерны, как Singleton, Registry, Factory на
      уровне создания классов.
    - Внутри метаклассы используют хук `__new__` для модификации создаваемого класса.

4. **Атрибуты и их поиск**:
    - Механизм поиска атрибутов (`__getattribute__`, `__getattr__`) позволяет реализовывать Proxy, Adapter, Facade
      динамически.
    - `__dict__` и `__slots__` влияют на реализацию паттернов, связанных с композицией.

5. **Модульная система**:
    - Модули в Python сами по себе являются синглтонами (загружаются один раз), что используется для реализации паттерна
      Module.
    - Импорт модулей кэшируется в `sys.modules`.

6. **Сборка мусора и паттерны**:
    - Циклические ссылки в Observer, Mediator могут приводить к утечкам памяти, если не используются слабые ссылки (
      `weakref`).
    - `__del__` имеет особенности при использовании в паттернах из-за порядка вызова финализаторов.

#### **Особенности**

1. **Упрощение классических паттернов**:
    - **Фабрика**: часто заменяется обычной функцией или lambda.
    - **Стратегия**: передача функций как аргументов устраняет необходимость в классах-стратегиях.
    - **Команда**: функции или callable-объекты делают ненужными отдельные классы команд.

2. **Динамическое создание и модификация**:
    - Классы и объекты можно изменять во время выполнения (monkey patching), что позволяет реализовывать паттерны
      динамически.
    - Это также может привести к трудностям в отладке и тестировании.

3. **Протоколы вместо интерфейсов**:
    - Вместо явных интерфейсов (как в Java) Python использует протоколы (duck typing), что влияет на применение
      паттернов Заместитель, Адаптер.

4. **Множественное наследование и миксины**:
    - Python поддерживает множественное наследование, что упрощает реализацию паттернов через миксины (Mixin).
    - MRO (Method Resolution Order) критически важен для таких паттернов.

5. **Встроенные паттерны в стандартной библиотеке**:
    - `collections.abc` предоставляет абстрактные базовые классы для многих паттернов (Итератор, Контейнер).
    - `contextlib` реализует менеджеры контекстов.
    - `functools` содержит инструменты для функциональных паттернов.

#### **Лучшие практики для AQA**

1. **Тестирование паттернов в изоляции**:
    - Для каждого компонента паттерна (например, отдельной стратегии в паттерне Стратегия) пишите юнит-тесты.
    - Используйте моки и стабы для изоляции тестируемого компонента от остальных частей паттерна.

2. **Интеграционное тестирование взаимодействия**:
    - Паттерны часто определяют взаимодействие объектов. Тестируйте это взаимодействие:
        - В Наблюдателе — что наблюдатели получают уведомления.
        - В Состоянии — что переходы между состояниями происходят корректно.
        - В Команде — что команды вызываются правильно и отменяются (undo).

3. **Тестирование с различными данными и состояниями**:
    - Для паттернов, зависящих от состояния (Стратегия, Состояние), тестируйте с разными начальными условиями.
    - Используйте property-based тестирование (Hypothesis) для генерации тестовых случаев.

4. **Мокирование в паттернах**:
    - При тестировании компонента, использующего паттерн Фасад или Заместитель, мокируйте внешние зависимости.
    - Для паттерна Адаптер тестируйте, что адаптер корректно преобразует вызовы к адаптируемому объекту.

5. **Тестирование производительности паттернов**:
    - Некоторые паттерны (например, Декоратор) добавляют накладные расходы. В нагрузочных тестах проверяйте, что эти
      расходы допустимы.
    - Для паттернов, которые могут кэшировать данные (Прокси, Фасад), проверяйте эффективность кэширования.

6. **Тестирование потокобезопасности**:
    - Паттерны, которые используются в многопоточных приложениях (Синглтон, Пул объектов), должны быть тестированы на
      race conditions.
    - Используйте `threading` или `asyncio` тесты для проверки корректности в конкурентных сценариях.

7. **Использование паттернов в тестовом коде**:
    - Применяйте паттерны для улучшения тестового кода:
        - **Фабрика**: для создания тестовых данных.
        - **Стратегия**: для выбора способа тестирования в зависимости от окружения.
        - **Декоратор**: для добавления дополнительной логики (логирование, повторные попытки) к тестам.
        - **Прокси**: для ленивой загрузки тестовых ресурсов.

8. **Тестирование утечек памяти**:
    - Паттерны, создающие долгоживущие ссылки (Наблюдатель, Медиатор), могут приводить к утечкам. Используйте `weakref`
      и тестируйте с помощью `gc` модуля.
    - В тестах проверяйте, что объекты удаляются сборщиком мусора после использования.

9. **Документирование паттернов в тестах**:
    - Если в проекте используется неочевидный паттерн, документируйте его в тестах, чтобы облегчить понимание.
    - Используйте тесты как живую документацию того, как паттерн должен использоваться.

10. **Регрессионное тестирование изменений паттернов**:
    - При рефакторинге паттерна (например, замена синглтона на dependency injection) создавайте регрессионные тесты.
    - Убедитесь, что изменения не ломают существующую функциональность.

11. **Тестирование с использованием статических анализаторов**:
    - Для паттернов, которые полагаются на типы (Фабрика, Строитель), используйте mypy для статической проверки
      корректности.
    - Интегрируйте проверки типов в CI/CD.

12. **Интеграция с фреймворками**:
    - Паттерны часто используются в тестовых фреймворках (например, паттерн Стратегия в `pytest` для выбора тестов).
      Изучите, как фреймворк использует паттерны, чтобы писать более эффективные тесты.

13. **Избегание антипаттернов в тестах**:
    - Не используйте паттерны там, где они не нужны (например, не создавайте сложную иерархию классов для простых
      тестов).
    - Избегайте синглтонов в тестах, так как они затрудняют изоляцию тестов.

14. **Образовательные тесты**:
    - Создавайте тесты, которые демонстрируют, как работают паттерны, для обучения новых членов команды.

================================================================================================================================

### SOLID

#### **Определение**

SOLID — это акроним пяти основных принципов объектно-ориентированного программирования и проектирования, призванных
сделать программное обеспечение более понятным, гибким и поддерживаемым:

1. **S** — Single Responsibility Principle (Принцип единственной ответственности): класс должен иметь только одну
   причину для изменения, то есть отвечать за одну задачу или функциональность.
2. **O** — Open/Closed Principle (Принцип открытости/закрытости): классы должны быть открыты для расширения, но закрыты
   для модификации.
3. **L** — Liskov Substitution Principle (Принцип подстановки Лисков): объекты подклассов должны быть заменяемы на
   объекты родительских классов без нарушения корректности программы.
4. **I** — Interface Segregation Principle (Принцип разделения интерфейсов): клиенты не должны зависеть от методов,
   которые они не используют; следует создавать узкоспециализированные интерфейсы.
5. **D** — Dependency Inversion Principle (Принцип инверсии зависимостей): модули верхнего уровня не должны зависеть от
   модулей нижнего уровня; оба должны зависеть от абстракций.

В Python эти принципы реализуются с учётом особенностей языка: динамической типизации, duck typing, декораторов,
метаклассов и протоколов.

#### **Внутренняя реализация (под капотом)**

1. **Single Responsibility в Python**:
    - В Python ответственность часто выносится в функции или модули благодаря первоклассным функциям и модульной
      системе.
    - Модули (`import`) являются естественными единицами разделения ответственности, так как каждый модуль имеет своё
      пространство имён.
    - Классы могут быть динамически изменены, но это противоречит SRP: Python не предотвращает добавление несвязанных
      методов, но линтеры (pylint, flake8) могут обнаруживать нарушения.

2. **Open/Closed через механизмы расширения**:
    - **Декораторы**: позволяют добавлять поведение функциям и классам без изменения их исходного кода (расширение).
    - **Монки-патчинг (monkey patching)**: динамическое изменение классов и модулей в runtime, но это опасный приём,
      который может нарушить стабильность.
    - **Наследование и композиция**: Python поддерживает множественное наследование и миксины для расширения
      функциональности.
    - **Абстрактные базовые классы (ABC)** и **протоколы** (`typing.Protocol`): позволяют определять интерфейсы, которые
      можно реализовать, не изменяя существующий код.

3. **Liskov Substitution и система типов Python**:
    - Python использует утиную типизацию (duck typing): объект считается подходящим, если он имеет необходимые методы и
      атрибуты, а не потому что он принадлежит определённому классу.
    - `isinstance()` и `issubclass()` используют MRO (Method Resolution Order) для проверки иерархии наследования.
    - Абстрактные базовые классы из модуля `abc` позволяют формализовать контракты, но проверка подстановки остаётся
      динамической.

4. **Interface Segregation в Python**:
    - В Python нет явных интерфейсов (как в Java), но их роль выполняют:
        - **Абстрактные базовые классы (ABC)** с `@abstractmethod`.
        - **Протоколы** (PEP 544) — структурная типизация через `typing.Protocol`.
        - **Неявные интерфейсы** (duck typing): клиенты зависят только от тех методов, которые они фактически вызывают.
    - Множественное наследование позволяет классу реализовывать несколько интерфейсов (ABC или протоколов).

5. **Dependency Inversion и внедрение зависимостей**:
    - Зависимости могут быть внедрены через аргументы функций/конструкторов (Dependency Injection).
    - Модуль `injector` или фреймворки (FastAPI, Django) предоставляют встроенные механизмы для DI.
    - Абстракции могут быть представлены как ABC, протоколы или просто callable-объекты (функции, классы).

#### **Особенности**

1. **Динамическая природа Python**:
    - Принципы SOLID в Python носят рекомендательный характер, так как язык не обеспечивает их статической проверкой (
      кроме использования аннотаций типов и mypy).
    - Возможность динамического изменения классов (добавление методов, изменение иерархии) может как помогать, так и
      нарушать SOLID.

2. **Утиная типизация vs. явные интерфейсы**:
    - В Python чаще полагаются на утиную типизацию, что упрощает соблюдение LSP и ISP: объект используется по его
      возможностям, а не по типу.
    - Однако это может привести к ошибкам в runtime, если объект не соответствует ожидаемому протоколу.

3. **Множественное наследование и миксины**:
    - Позволяют более гибко разделять ответственность (SRP) и segregating interfaces (ISP), но могут усложнять иерархию
      классов.

4. **Декораторы и контекстные менеджеры**:
    - Широко используются для расширения функциональности без изменения кода (OCP), например, добавление логирования,
      кэширования, аутентификации.

5. **Влияние на производительность**:
    - Использование абстракций (ABC, протоколы) и внедрение зависимостей добавляет небольшие накладные расходы, но в
      Python они обычно не критичны.
    - Динамические проверки (`isinstance`, `hasattr`) также влияют на производительность.

#### **Лучшие практики для AQA**

1. **Тестирование Single Responsibility**:
    - **Модульное тестирование**: каждый класс или функция должны иметь узкоспециализированные тесты.
    - **Анализ покрытия**: инструменты вроде `coverage.py` помогают обнаружить не связанную логику в классе.
    - **Статический анализ**: линтеры (pylint) могут обнаруживать классы с слишком большим количеством методов или
      несвязанными методами.

2. **Тестирование Open/Closed Principle**:
    - **Тестирование декораторов**: убедитесь, что декоратор корректно расширяет функциональность, не ломая исходное
      поведение.
    - **Наследование**: при расширении класса через наследование, тесты родительского класса должны проходить и для
      дочернего (LSP).
    - **Монки-патчинг**: избегайте в тестах, так как это усложняет поддержку; если используется, тестируйте его эффекты
      изолированно.

3. **Тестирование Liskov Substitution Principle**:
    - **Тесты для иерархии классов**: тесты, написанные для базового класса, должны выполняться для всех подклассов без
      изменений.
    - **Проверка контрактов**: используйте ABC или протоколы для определения контрактов и тестируйте, что подклассы их
      соблюдают.
    - **Интеграционные тесты**: подставляйте объекты подклассов в код, ожидающий базовый класс, и проверяйте
      корректность работы.

4. **Тестирование Interface Segregation Principle**:
    - **Тестирование узких интерфейсов**: если класс реализует несколько интерфейсов (ABC или протоколов), тестируйте
      каждый интерфейс отдельно.
    - **Mocking**: при тестировании клиента, который использует только часть методов интерфейса, мокируйте только эти
      методы.
    - **Статическая типизация**: используйте mypy для проверки, что клиенты не вызывают несуществующие методы.

5. **Тестирование Dependency Inversion Principle**:
    - **Внедрение зависимостей в тестах**: используйте mock-объекты для абстракций, чтобы изолировать тестируемый
      модуль.
    - **Интеграционные тесты с реальными реализациями**: проверяйте, что модуль корректно работает с различными
      реализациями абстракций.
    - **Контейнеры зависимостей**: если используется DI-контейнер (например, `injector`), тестируйте конфигурацию
      контейнера.

6. **Общие практики**:
    - **Property-based тестирование** (Hypothesis): помогает проверить соблюдение контрактов (LSP) для широкого
      диапазона входных данных.
    - **Тестирование исключений**: убедитесь, что подклассы не нарушают ожидаемое поведение в ошибочных ситуациях (LSP).
    - **Регрессионное тестирование**: при рефакторинге с целью улучшения SOLID, убедитесь, что существующая
      функциональность не сломана.

7. **Использование SOLID в тестовом коде**:
    - **SRP**: каждый тест должен проверять одну конкретную вещь; используйте отдельные фикстуры для setup/teardown.
    - **OCP**: тестовые фреймворки (pytest) позволяют расширять тесты через плагины и декораторы, не изменяя исходный
      код тестов.
    - **LSP**: тестовые классы-наследники должны быть заменяемы в тестовых сьютах.
    - **ISP**: используйте узкоспециализированные фикстуры и вспомогательные классы.
    - **DIP**: тесты не должны зависеть от конкретных реализаций; используйте абстракции (например, `unittest.mock`).

8. **Инструменты**:
    - **pytest**: поддерживает фикстуры, параметризацию, плагины, что помогает соблюдать SOLID в тестах.
    - **mypy**: статическая проверка типов помогает выявлять нарушения LSP и DIP.
    - **pylint, flake8**: обнаружение слишком больших классов (нарушение SRP) и сложных иерархий.

================================================================================================================================




