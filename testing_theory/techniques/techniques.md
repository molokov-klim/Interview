# **Техники тест-дизайна**

## **Junior Level**

Техники проектирования тестов (Test Design Techniques) — это структурированные методы создания тестовых случаев, которые
помогают эффективно и полно проверить систему. Они отвечают на вопрос: "Как придумать хорошие тесты?" и заменяют
случайный перебор данных системным подходом.

Основные техники:

1. **Эквивалентное разделение (Equivalence Partitioning):** Входные данные делятся на группы (классы эквивалентности),
   где поведение системы ожидается одинаковым. Например, для поля "возраст" группы: отрицательные числа (невалидные),
   0-17 (несовершеннолетние), 18-65 (взрослые), больше 65 (пенсионеры). Достаточно протестировать по одному значению из
   каждого класса.
2. **Анализ граничных значений (Boundary Value Analysis):** Фокусируется на тестировании значений на границах этих
   классов, так как именно там чаще всего возникают ошибки. Для диапазона 18-65 проверяются значения: 17, 18, 19 и 64,
   65, 66.
3. **Таблица принятия решений (Decision Table Testing):** Применяется для логики, зависящей от комбинаций условий.
   Создается таблица, где столбцы — это условия и действия, а строки — тестовые сценарии для всех значимых комбинаций.
4. **Тестирование состояний и переходов (State Transition Testing):** Используется для систем с конечным числом
   состояний (например, банкомат: "Ожидание карты" -> "Ввод PIN" -> "Выбор операции"). Тестируются как корректные
   переходы, так и ошибочные (например, ввод неверного PIN-кода).
5. **Тестирование сценариев использования (Use Case Testing):** Система проверяется через призму реальных
   пользовательских сценариев, описывающих, как пользователь взаимодействует с системой для достижения конкретной цели (
   например, "Оформление заказа").
6. **Попарное тестирование (Pairwise Testing):** Метод оптимизации, который позволяет покрыть все возможные пары
   значений входных параметров, сокращая количество тестовых комбинаций до приемлемого уровня.
7. **Предугадывание ошибок (Error Guessing):** Опытный тестировщик на основе знаний о системе, предыдущих дефектах и
   типичных проблемах в подобных продуктах выдвигает гипотезы о возможных ошибках и создает целевые тесты для их
   проверки.

## **Middle Level**

На среднем уровне важно не только знать техники, но и понимать, как эффективно применять их в рамках автоматизации,
управлять тестовыми данными и интегрировать подходы в процесс разработки.

### Особенности применения и автоматизации

1. **Эквивалентное разделение и анализ граничных значений:**
    * **Параметризация тестов:** В pytest с помощью декоратора `@pytest.mark.parametrize` один тест превращается в набор
      проверок для данных из разных классов эквивалентности и граничных значений.
    * **Генерация данных:** Значения можно генерировать динамически или выносить в отдельные фикстуры для повторного
      использования.
    * **Ключевой момент:** Автоматизация позволяет легко и полно покрыть все границы и классы, что сложно сделать
      вручную.

2. **Таблица принятия решений:**
    * **Data-Driven Testing (DDT):** Саму таблицу (например, в формате CSV, JSON или Excel) можно использовать как
      источник данных для тестов. Это делает логику прозрачной и легко обновляемой.
    * **Интеграция:** Инструменты вроде `pandas` упрощают загрузку и обработку табличных данных в тестах.
    * **Преимущество:** Четкое разделение тестовой логики (код) и тестовых данных (таблица).

3. **Тестирование состояний и переходов:**
    * **Паттерн "Конечный автомат" (State Machine):** Логику системы можно смоделировать в коде, что облегчает создание
      тестов, проверяющих корректность переходов.
    * **Последовательности шагов:** Тесты организуются как цепочки действий (например, через фикстуры в `pytest`),
      которые переводят систему из одного состояния в другое с последующей проверкой.
    * **Фокус:** Автоматизация помогает проверить длинные и сложные цепочки переходов, включая обработку нестандартных
      сценариев.

4. **Тестирование сценариев использования:**
    * **BDD-фреймворки:** Инструменты вроде `behave` или `pytest-bdd` позволяют описывать сценарии на языке Gherkin (
      Given-When-Then), что улучшает взаимодействие между разработчиками, тестировщиками и аналитиками.
    * **Паттерн Page Object:** Для UI-автоматизации этот паттерн идеально ложится на сценарии, инкапсулируя логику
      работы с элементами страницы и делая тесты устойчивее к изменениям в верстке.

5. **Попарное тестирование (Pairwise):**
    * **Автоматизация генерации:** Инструменты (`allpairspy`, `pict`) интегрируются в процесс подготовки тестовых
      данных, генерируя минимальный набор комбинаций для покрытия всех пар.
    * **Применение:** Особенно полезно при тестировании конфигураций (ОС x браузер x разрешение экрана) или
      функциональности с множеством независимых параметров.

6. **Предугадывание ошибок:**
    * **Систематизация:** Хотя техника основана на опыте, найденные дефекты и гипотезы можно фиксировать в виде
      автоматизированных проверок и добавлять их в регрессионную тестовую базу.
    * **Анализ рисков:** Метод тесно связан с анализом областей повышенного риска в приложении, что помогает расставлять
      приоритеты при написании автоматизированных тестов.

## **Senior Level**

# Техника: Эквивалентное разделение и Анализ граничных значений

Это не просто «правила хорошего тона», а математически обоснованные методы сокращения бесконечного числа тестов до
конечного набора. В основе лежат теория множеств и эмпирические исследования распределения ошибок в коде.

***

## 1. Научное обоснование (The Science Behind It)

С точки зрения Computer Science, программа — это математическая функция $f(x)$, которая отображает входные данные на
выходные. Тестирование — это попытка найти такие $x$, где $f(x)$ работает некорректно.

### Гипотеза однородности (Basis for Equivalence Partitioning)

Фундамент метода эквивалентных классов — **гипотеза однородности (Homogeneity Hypothesis)**. Она утверждает, что если
один тест из класса эквивалентности выявляет ошибку, то с высокой вероятностью её выявят и все остальные тесты этого
класса. И наоборот: если один тест проходит успешно, остальные тоже пройдут.

> **Суть:** Мы предполагаем, что программа обрабатывает все числа от 1 до 100 *одним и тем же куском кода* (одним путем
> в графе потока управления — Control Flow Graph).

### Гипотеза сгущения ошибок (Basis for BVA)

Анализ граничных значений опирается на **гипотезу граничных значений**. Эмпирически доказано, что вероятность
отказа $P(failure)$ не распределена равномерно. Она имеет резкие пики (спайки) в точках, где меняется логика программы.

**Почему это происходит? Причины кроются в психологии программирования:**

1. **Ошибки на единицу (Off-by-one errors):** Разработчики путают `>` и `>=`, `<` и `<=`.
2. **Инициализация циклов:** Ошибки в `for (i=0; i < N; i++)` часто приводят к пропуску последнего элемента или выходу
   за массив.
3. **Переполнение типов:** Границы часто совпадают с предельными значениями типов данных (`int`, `short`).

## 2. Результаты ключевых исследований

Научные работы последовательно подтверждают эффективность этих методов по сравнению со случайным тестированием (Random
Testing).

### 1. Reid (1997): «Empirical Analysis of EP, BVA and Random Testing»

Стюарт Рейд провел фундаментальное исследование на реальной системе авионики (20 000 строк кода Ada).

* **Результат:** BVA (граничные значения) оказалось **самым эффективным** методом, выявляя ошибки, которые пропускали
  другие методы.
* **Сравнение:** BVA находил почти в 2 раза больше дефектов, чем EP (классы эквивалентности), но требовал кратно больше
  тест-кейсов.
* **Вывод:** EP — дешевле (меньше тестов), но пропускает граничные баги. BVA — дороже, но надежнее.

### 2. Basili & Selby (1987): «Comparing the Effectiveness of Software Testing Strategies»

Классическое исследование, сравнивавшее функциональное тестирование (EP+BVA) со структурным (покрытие кода) и
рецензированием кода (Code Reading).

* **Результат:** Функциональное тестирование (Black-box) показало отличные результаты в обнаружении ошибок инициализации
  и управления, часто превосходя структурные тесты.

### 3. Современные данные (Dobslaw 2023, Hubner 2019)

В эпоху AI и автоматизации исследования показывают, что стратегии генерации тестов, которые "целятся" в границы (
Boundary-guided testing), находят на 30-50% больше мутационных ошибок, чем слепой фаззинг (fuzzing).

# Техника: Таблица принятия решений (Decision Table Testing)

В отличие от граничных значений, которые исследуют *диапазоны*, таблицы решений исследуют *логику* и *комбинаторику*.
Это метод для борьбы с комбинаторным взрывом и цикломатической сложностью.

***

## 1. Научное обоснование

Фундаментом для таблиц решений служат **Булева алгебра** и **Пропозициональная логика**. Любая программа, принимающая
решения, может быть представлена как функция от набора бинарных (или конечных) переменных.

### Проблема, которую решает метод

Человеческий мозг плохо удерживает в оперативной памяти более 3-4 условий одновременно (следствие закона
Миллера $7 \pm 2$). Когда в коде встречаются вложенные `if-else` или зависимые условия, вероятность ошибки (пропущенной
ветки) стремится к 100%.

### Математические свойства (Completeness & Consistency)

Таблицы решений опираются на два строгих математических свойства:

1. **Полнота (Completeness):** Гарантия того, что рассмотрены *все возможные* комбинации входных условий. Для $N$
   бинарных условий существует ровно $2^N$ возможных комбинаций. Если таблица содержит меньше правил, она либо неполна,
   либо сжата (collapsed).
2. **Непротиворечивость (Consistency):** Гарантия того, что одна и та же комбинация условий не ведет к взаимоисключающим
   действиям.

***

## 2. Результаты исследований

Научные работы подтверждают, что таблицы решений (DT) превосходят другие методы в выявлении логических ошибок, но могут
быть избыточны.

### 1. Subramanian (1992): «A comparison of the decision table and tree»

Исследование эффективности представления логики.

* **Результат:** Тестировщики и аналитики, использующие табличное представление (Decision Tables), совершали
  статистически значимо **меньше ошибок** при анализе сложной логики по сравнению с теми, кто использовал деревья
  решений (Decision Trees) или текстовые спецификации.
* **Вывод:** Табличная структура снижает когнитивную нагрузку и позволяет быстрее замечать пропущенные сценарии (gaps).

### 2. Сравнение с Boundary Value Analysis (Ferriday, 2007)

* **Результат:** BVA генерирует примерно в 5 раз больше тест-кейсов, чем Decision Tables, но DT находит специфический
  класс ошибок — **ошибки взаимодействия условий** (interaction faults), которые BVA пропускает полностью.
* **Эффективность:** DT выявляет "логические дыры" (ситуации, когда спецификация молчит о поведении системы), в то время
  как другие методы проверяют только написанное.

### 3. Shiffman (1997): «Representation of Clinical Practice Guidelines»

Исследование на критических системах (медицина).

* **Результат:** Применение таблиц решений к медицинским алгоритмам позволило выявить логическую неполноту (missing
  rules) и противоречия в клинических рекомендациях, которые не были замечены экспертами-людьми при обычном чтении
  текста.

# Техника: Тестирование состояний и переходов (State Transition Testing)

Этот вид тестирования радикально отличается от предыдущих. Если *Эквивалентное разделение* работает с «моментальными»
данными (stateless), то *State Transition Testing* проверяет «память» системы.

Это метод для проверки сложной бизнес-логики, где ответ системы зависит не только от того, **что** вы нажали, но и от
того, **в каком состоянии** система находилась до этого.

***

## 1. Научное обоснование (Scientific Basis)

В основе метода лежит раздел дискретной математики — **Теория конечных автоматов (Automata Theory)**.

### Формальная модель

Любую систему с состояниями можно описать как кортеж $(S, I, \delta)$, где:

* $S$ — конечное множество состояний (States).
* $I$ — множество входных сигналов (Inputs/Events).
* $\delta$ — функция перехода: $S_{current} \times I \rightarrow S_{new}$.

Это означает, что **реакция системы является функцией от её истории**. В отличие от простых функций $y=f(x)$,
здесь $y=f(x, state)$.

### Почему это необходимо?

Классические методы (EP, BVA) бессильны против ошибок последовательности.

* *Пример:* Нажатие кнопки «Оплатить» с валидной картой (EP/BVA говорят "ОК") должно приводить к успеху *только* в
  состоянии «Заказ создан», но должно вызывать ошибку в состоянии «Заказ уже оплачен». Без учета состояния мы пропустим
  этот баг.

***

## 2. Результаты исследований

Эффективность метода подтверждена десятилетиями исследований в области надежности ПО, особенно в embedded-системах и
телекоме.

### 1. Фундаментальная работа T.S. Chow (1978)

Статья «Testing Software Design Modeled by Finite-State Machines» является библией этого метода.

* **Результат:** Чоу доказал, что тестирование на основе автоматов гарантированно обнаруживает определенные классы
  ошибок, которые невозможно найти другими способами:
    * **Operation errors:** Неверный выходной результат при переходе.
    * **Transfer errors:** Переход не в то состояние.
    * **Extra/Missing states:** Лишние или недостижимые состояния.
* **Вклад:** Он ввел понятие **N-switch coverage** (покрытие последовательностей длины N), показав, что проверки
  одиночных переходов (0-switch) недостаточно для выявления сложных багов.

### 2. Offutt et al. (2003) — State-based Specification Testing

Джефф Оффат исследовал генерацию тестов из UML-диаграмм состояний.

* **Результат:** Автоматическая генерация тестов на основе состояний (State-based) находит глубокие логические ошибки,
  которые пропускают люди при написании тестов вручную, так как люди склонны проверять только «счастливые пути» (Happy
  Path) переходов.

### 3. Сравнение эффективности (Holt, 2014)

Исследование на промышленном ПО:

* **Результат:** State-Based Testing (SBT) с использованием строгих оракулов (проверок) позволяет обнаруживать дефекты
  управления потоком эффективнее, чем покрытие кода (Code Coverage). Удаление деталей из модели состояния (упрощение)
  снижает стоимость тестирования на 85%, но снижает эффективность обнаружения багов всего на ~30%, что делает метод
  рентабельным даже в упрощенном виде.

# Техника: Тестирование сценариев использования (Use Case Testing)

Если предыдущие техники (EP, BVA, Decision Table) были атомарными проверками «вход-выход», то **Use Case Testing** — это
тестирование *потоков* и *целей* пользователя. Это переход от проверки «как работает код» к проверке «как работает
бизнес-процесс».

***

## 1. Научное обоснование

В основе метода лежит **ориентированный на пользователя подход (User-Centered Design)** и **акторно-сетевая теория**.

### Концептуальная модель

Система рассматривается не как набор функций, а как "черный ящик", с которым взаимодействуют внешние сущности — **Акторы
** (пользователи, другие системы, таймеры), чтобы достичь определенной **Цели**.

* **Целеполагание:** Научно доказано, что пользователи не используют ПО ради функций (нажать кнопку). Они используют его
  для решения задач (купить билет, отправить отчет). Тестирование Use Case валидирует именно достижение целей.
* **Эвристика Парето (80/20):** Исследования показывают, что 80% времени пользователи используют 20% функционала (
  основные сценарии). Use Case Testing гарантирует, что именно эти критические 20% работают безупречно.

***

## 2. Результаты исследований

Научные данные подтверждают, что этот метод критически важен для нахождения дефектов *интеграции* и *требований*,
которые пропускают unit-тесты.

### 1. Ivar Jacobson (1992): «Object-Oriented Software Engineering»

Ивар Якобсон, создатель термина "Use Case" (изначально *Användningsfall* на шведском), доказал в своих работах, что
построение разработки и тестирования вокруг сценариев использования ("Use Case Driven") снижает количество архитектурных
ошибок на ранних стадиях.

### 2. Sophocleous et al. (2020): «Examining the Current State of System Testing»

Исследование 252 QA-инженеров и промышленных кейсов показало:

* **Результат:** Тестирование на основе реальных пользовательских сценариев (в комбинации с smoke/regression)
  статистически значимо ($p = 0.000$) снижает количество дефектов, обнаруженных конечными пользователями после
  релиза.[3]
* **Вывод:** Чем ближе тесты к реальным сценариям использования, тем выше удовлетворенность заказчика (User Acceptance).

### 3. Gutierrez et al.: «A Case Study for Generating Test Cases from Use Cases»

Исследование автоматической генерации тестов:

* **Результат:** Метод анализа сценариев (Scenario Analysis) позволяет выявить пропущенные пути в требованиях (gaps),
  которые не очевидны при просмотре списка требований списком. Тесты, сгенерированные из Use Case, имеют более высокое
  покрытие *бизнес-логики* по сравнению с тестами, основанными на структуре кода.[4]

# Техника: Попарное тестирование (Pairwise Testing)

Это метод-скальпель: он отсекает 99% тестов, сохраняя 95% эффективности. Это не магия, а прикладная комбинаторика.

***

## 1. Научное обоснование

**Проблема:** Комбинаторный взрыв. Если у вас 10 параметров по 10 значений в каждом, вам нужно $10^{10}$ тестов (10
миллиардов). Это невозможно выполнить.

**Решение (Эмпирический закон):** Ошибки в ПО крайне редко вызываются сложным взаимодействием 3-х и более параметров
одновременно.

* **Single-mode faults:** 20-30% багов вызываются одним параметром (ловится BVA/EP).
* **Double-mode faults:** 50-70% багов возникают на стыке **ДВУХ** параметров (например, "Шрифт=Arial" + "Принтер=HP").
* **Multi-mode faults:** Баги, требующие 3+ условий, составляют менее 5-10% (для некритических систем).[1]

**Математическая база:** Метод основан на **Ортогональных массивах (Orthogonal Arrays)** и **Covering Arrays**.
Ортогональный массив $L_N(S^k)$ гарантирует, что для любых двух колонок (параметров) *каждая возможная пара значений*
встречается ровно один раз (или как минимум один раз для Covering Arrays).[2][3]

Это позволяет сократить $10^{10}$ тестов до $\approx 100-200$, сохранив покрытие всех парных взаимодействий.

***

## 2. Результаты исследований

### 1. NIST (Wallace & Kuhn, 2004) — Исследование "магического числа"

Национальный институт стандартов и технологий США (NIST) проанализировал базы багов NASA (космические аппараты),
медицинских устройств и браузеров.

* **Результат:**
    * **98%** всех дефектов в медицинском ПО выявляются тестированием **пар** (2-way testing).[4]
    * В сложных системах (NASA) для выявления 100% багов требовалось тестирование взаимодействия до 6 параметров (
      6-way).
    * Кривая насыщения: 2-way ловит ~80-90% багов, 3-way ~95%, 4-way ~99%.[1]
* **Вывод:** Pairwise (2-way) — это "золотой стандарт" по соотношению цена/качество. Для критических модулей стоит
  использовать 3-way или 4-way.

### 2. Charbachi (2017) — Сравнение с ручным тестированием

* **Результат:** Pairwise-тесты находили примерно столько же багов, сколько тесты, написанные опытными инженерами
  вручную, но обеспечивали **более высокое покрытие кода (Code Coverage)** за счет неочевидных комбинаций, о которых
  люди часто не задумываются.[5]

### 3. Wood (2016) — Применение в фармакологии

Любопытный факт: принцип работает не только в IT. В биологии 80% реакций на "коктейль" из лекарств также предсказываются
попарным взаимодействием компонентов, что подтверждает универсальность закона "малых взаимодействий".[6]

# Техника: Предугадывание ошибок (Error Guessing)

Этот метод часто недооценивают, называя «интуицией», но в инженерной психологии он имеет строгое обоснование. Это не
гадание, а **применение неявного знания (Implicit Knowledge)** и распознавание паттернов.

***

## 1. Научное обоснование

### Когнитивная психология: Модель RPD

С точки зрения когнитивистики (Gary Klein), эксперт использует **модель принятия решений по распознаванию (
Recognition-Primed Decision, RPD)**. Мозг опытного инженера хранит тысячи паттернов «ситуация -> ошибка» и при виде
знакомого кода подсознательно «подсвечивает» опасные места.

* **Гипотеза кластеризации дефектов (Pareto Principle):** Принцип Парето работает и здесь: 80% ошибок содержатся в 20%
  модулей. Error Guessing — это эвристический поиск этих кластеров.
* **Таксономия дефектов (Defect Taxonomy):** Метод опирается на классификацию типичных ошибок (например, Boris Beizer’s
  Taxonomy). Ошибки не уникальны; программисты совершают одни и те же ляпы десятилетиями (деление на ноль, race
  condition, null pointer).

***

## 2. Результаты исследований

Наука подтверждает: опыт бьет формализм в поиске специфических багов, но проигрывает в полноте покрытия.

### 1. Basili & Selby (1987) — Роль экспертизы

В том же исследовании, где сравнивали EP/BVA, было замечено:

* **Результат:** Тестировщики-эксперты, использовавшие «свободный поиск» (фактически Error Guessing), находили самые
  сложные логические ошибки, которые пропускали формальные методы.
* **Нюанс:** Эффективность метода линейно зависит от опыта. Junior QA с этим методом находит близкое к нулю количество
  критических багов.[1]

### 2. Исследования Exploratory Testing (Bhatti, 2010)

Error Guessing является частью исследовательского тестирования.

* **Результат:** Исследовательский подход (основанный на догадках) позволил найти статистически значимо **больше
  дефектов** за единицу времени, чем сценарное тестирование, особенно в категориях UI и Usability.[2]

### 3. MITRE — Seven Pernicious Kingdoms

Исследование CWE (Common Weakness Enumeration)  — это, по сути, глобальная база для Error Guessing в области
безопасности. Она доказывает, что 90% уязвимостей (SQLi, XSS, Buffer Overflow) предсказуемы.[3]

[Содержание](/CONTENTS.md#содержание)